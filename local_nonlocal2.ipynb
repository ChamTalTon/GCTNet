{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = False  # 禁止矩阵乘法使用tf32\n",
    "torch.backends.cudnn.allow_tf32 = False        # 禁止卷积使用tf32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#视频数据处理\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Path(object):\n",
    "    @staticmethod\n",
    "    def db_dir(database):\n",
    "        if database == 'ucf101':\n",
    "            #路径包含视频类标签\n",
    "            \n",
    "            root_dir = '/root/autodl-tmp/UCF-101'\n",
    "            #保存结果的输出路径\n",
    "            output_dir = '/root/autodl-tmp/data_test/ucf101'\n",
    "            return root_dir,output_dir\n",
    "\n",
    "        elif database == 'hmdb51':\n",
    "            root_dir = 'Path/to/hmdb-51'\n",
    "            #保存结果的输出路径\n",
    "            output_dir = 'Path/to/VAR/hmdb51'\n",
    "            return root_dir,output_dir\n",
    "        else:\n",
    "            print('Database {} not available.'.format(database))\n",
    "            raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def model_dir():\n",
    "        return './model/c3d-pretrained.pth'\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    r\"\"\"A Dataset for a folder of videos. Expects the directory structure to be\n",
    "    directory->[train/val/test]->[class labels]->[videos]. Initializes with a list\n",
    "    of all file names, along with an array of labels, with label being automatically\n",
    "    inferred from the respective folder names.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): Name of dataset. Defaults to 'ucf101'.\n",
    "            split (str): Determines which folder of the directory the dataset will read from. Defaults to 'train'.\n",
    "            clip_len (int): Determines how many frames are there in each clip. Defaults to 16.\n",
    "            preprocess (bool): Determines whether to preprocess dataset. Default is False.\n",
    "    \"\"\"\n",
    "    # 注意第一次要预处理数据的\n",
    "    def __init__(self, dataset='ucf101', split='train', clip_len=16, preprocess=True):\n",
    "        self.root_dir, self.output_dir = Path.db_dir(dataset)\n",
    "        folder = os.path.join(self.output_dir, split)\n",
    "        self.clip_len = clip_len\n",
    "        self.split = split\n",
    "\n",
    "        # The following three parameters are chosen as described in the paper section 4.1\n",
    "        self.resize_height = 340\n",
    "        self.resize_width = 256\n",
    "        self.crop_size = 224\n",
    "\n",
    "        if not self.check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You need to download it from official website.')\n",
    "\n",
    "        if (not self.check_preprocess()) or preprocess:\n",
    "            print('Preprocessing of {} dataset, this will take long, but it will be done only once.'.format(dataset))\n",
    "            self.preprocess()\n",
    "\n",
    "        # Obtain all the filenames of files inside all the class folders\n",
    "        # Going through each class folder one at a time\n",
    "        self.fnames, labels = [], []\n",
    "        for label in sorted(os.listdir(folder)):\n",
    "            for fname in os.listdir(os.path.join(folder, label)):\n",
    "                self.fnames.append(os.path.join(folder, label, fname))\n",
    "                labels.append(label)\n",
    "\n",
    "        assert len(labels) == len(self.fnames)\n",
    "        print('Number of {} videos: {:d}'.format(split, len(self.fnames)))\n",
    "\n",
    "        # Prepare a mapping between the label names (strings) and indices (ints)\n",
    "        self.label2index = {label: index for index, label in enumerate(sorted(set(labels)))}\n",
    "        # Convert the list of label names into an array of label indices\n",
    "        self.label_array = np.array([self.label2index[label] for label in labels], dtype=int)\n",
    "\n",
    "        if dataset == \"ucf101\":\n",
    "            if not os.path.exists('ucf_labels.txt'):\n",
    "                with open('ucf_labels.txt', 'w') as f:\n",
    "                    for id, label in enumerate(sorted(self.label2index)):\n",
    "                        f.writelines(str(id+1) + ' ' + label + '\\n')\n",
    "\n",
    "        elif dataset == 'hmdb51':\n",
    "            if not os.path.exists('dataloader/hmdb_labels.txt'):\n",
    "                with open('dataloaders/hmdb_labels.txt', 'w') as f:\n",
    "                    for id, label in enumerate(sorted(self.label2index)):\n",
    "                        f.writelines(str(id+1) + ' ' + label + '\\n')\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "    #需要重写__getitem__方法\n",
    "    def __getitem__(self, index):\n",
    "        # Loading and preprocessing.\n",
    "        buffer = self.load_frames(self.fnames[index]) #一共有8460个文件夹\n",
    "        buffer = self.crop(buffer, self.clip_len, self.crop_size)\n",
    "        labels = np.array(self.label_array[index])\n",
    "\n",
    "        if self.split == 'test':\n",
    "            # Perform data augmentation\n",
    "            buffer = self.randomflip(buffer)\n",
    "        buffer = self.normalize(buffer)\n",
    "        buffer = self.to_tensor(buffer)\n",
    "        return torch.from_numpy(buffer), torch.from_numpy(labels)\n",
    "\n",
    "    def check_integrity(self):\n",
    "        if not os.path.exists(self.root_dir):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def check_preprocess(self):\n",
    "        # TODO: Check image size in output_dir\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            return False\n",
    "        elif not os.path.exists(os.path.join(self.output_dir, 'train')):\n",
    "            return False\n",
    "\n",
    "        for ii, video_class in enumerate(os.listdir(os.path.join(self.output_dir, 'train'))):\n",
    "            for video in os.listdir(os.path.join(self.output_dir, 'train', video_class)):\n",
    "                video_name = os.path.join(os.path.join(self.output_dir, 'train', video_class, video),\n",
    "                                    sorted(os.listdir(os.path.join(self.output_dir, 'train', video_class, video)))[0])\n",
    "                image = cv2.imread(video_name)\n",
    "                if np.shape(image)[0] != 340 or np.shape(image)[1] != 256:\n",
    "                    return False\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if ii == 10:\n",
    "                break\n",
    "\n",
    "        return True\n",
    "\n",
    "    def preprocess(self):\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            os.makedirs(os.path.join(self.output_dir, 'train'))\n",
    "            os.makedirs(os.path.join(self.output_dir, 'val'))\n",
    "            #os.makedirs(os.path.join(self.output_dir, 'test'))\n",
    "\n",
    "        # Split train/val sets\n",
    "        for file in os.listdir(self.root_dir):\n",
    "            file_path = os.path.join(self.root_dir, file)\n",
    "            video_files = [name for name in os.listdir(file_path)]\n",
    "\n",
    "            train, val = train_test_split(video_files, test_size=0.3, random_state=42)#将视频数据划分为70%的训练集和30%的验证集\n",
    "            #train, val = train_test_split(train_and_valid, test_size=0.2, random_state=42)\n",
    "\n",
    "            train_dir = os.path.join(self.output_dir, 'train', file)\n",
    "            val_dir = os.path.join(self.output_dir, 'val', file)\n",
    "            #test_dir = os.path.join(self.output_dir, 'test', file)\n",
    "\n",
    "            if not os.path.exists(train_dir):\n",
    "                os.mkdir(train_dir)\n",
    "            if not os.path.exists(val_dir):\n",
    "                os.mkdir(val_dir)\n",
    "            #if not os.path.exists(test_dir):\n",
    "                #os.mkdir(test_dir)\n",
    "\n",
    "            for video in train:\n",
    "                self.process_video(video, file, train_dir)\n",
    "\n",
    "            for video in val:\n",
    "                self.process_video(video, file, val_dir)\n",
    "\n",
    "            #for video in test:\n",
    "                #self.process_video(video, file, test_dir)\n",
    "\n",
    "        print('Preprocessing finished.')\n",
    "\n",
    "    def process_video(self, video, action_name, save_dir):\n",
    "        # Initialize a VideoCapture object to read video data into a numpy array\n",
    "        video_filename = video.split('.')[0]\n",
    "        if not os.path.exists(os.path.join(save_dir, video_filename)):\n",
    "            os.mkdir(os.path.join(save_dir, video_filename))\n",
    "\n",
    "        capture = cv2.VideoCapture(os.path.join(self.root_dir, action_name, video))\n",
    "\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Make sure splited video has at least 16 frames\n",
    "        EXTRACT_FREQUENCY = 4\n",
    "        if frame_count // EXTRACT_FREQUENCY <= 16:\n",
    "            EXTRACT_FREQUENCY -= 1\n",
    "            if frame_count // EXTRACT_FREQUENCY <= 16:\n",
    "                EXTRACT_FREQUENCY -= 1\n",
    "                if frame_count // EXTRACT_FREQUENCY <= 16:\n",
    "                    EXTRACT_FREQUENCY -= 1\n",
    "\n",
    "        count = 0\n",
    "        i = 0\n",
    "        retaining = True\n",
    "\n",
    "        while (count < frame_count and retaining):\n",
    "            retaining, frame = capture.read()\n",
    "            if frame is None:\n",
    "                continue\n",
    "\n",
    "            if count % EXTRACT_FREQUENCY == 0:\n",
    "                if (frame_height != self.resize_height) or (frame_width != self.resize_width):\n",
    "                    frame = cv2.resize(frame, (self.resize_width, self.resize_height))\n",
    "                cv2.imwrite(filename=os.path.join(save_dir, video_filename, '0000{}.jpg'.format(str(i))), img=frame)\n",
    "                i += 1\n",
    "            count += 1\n",
    "\n",
    "        # Release the VideoCapture once it is no longer needed\n",
    "        capture.release()\n",
    "\n",
    "    def randomflip(self, buffer):\n",
    "        \"\"\"Horizontally flip the given image and ground truth randomly with a probability of 0.5.\"\"\"\n",
    "\n",
    "        if np.random.random() < 0.5:\n",
    "            for i, frame in enumerate(buffer):\n",
    "                frame = cv2.flip(buffer[i], flipCode=1)\n",
    "                buffer[i] = cv2.flip(frame, flipCode=1)\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    def normalize(self, buffer):\n",
    "        for i, frame in enumerate(buffer):\n",
    "            frame -= np.array([[[90.0, 98.0, 102.0]]])\n",
    "            buffer[i] = frame\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    def to_tensor(self, buffer):\n",
    "        return buffer.transpose((3, 0, 1, 2))\n",
    "\n",
    "    def load_frames(self, file_dir):\n",
    "        frames = sorted([os.path.join(file_dir, img) for img in os.listdir(file_dir)])\n",
    "        frame_count = len(frames)\n",
    "        buffer = np.empty((frame_count,self.resize_height, self.resize_width,3), np.dtype('float32'))\n",
    "        for i, frame_name in enumerate(frames):\n",
    "            frame = np.array(cv2.imread(frame_name)).astype(np.float64)\n",
    "            buffer[i] = frame\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    def crop(self, buffer, clip_len, crop_size):\n",
    "        # randomly select time index for temporal jittering\n",
    "        time_index = np.random.randint(buffer.shape[0] - clip_len)\n",
    "\n",
    "        # Randomly select start indices in order to crop the video\n",
    "        height_index = np.random.randint(buffer.shape[1] - crop_size)\n",
    "        width_index = np.random.randint(buffer.shape[2] - crop_size)\n",
    "\n",
    "        # Crop and jitter the video using indexing. The spatial crop is performed on\n",
    "        # the entire array, so each frame is cropped in the same location. The temporal\n",
    "        # jitter takes place via the selection of consecutive frames\n",
    "        buffer = buffer[time_index:time_index + clip_len,\n",
    "                 height_index:height_index + crop_size,\n",
    "                 width_index:width_index + crop_size,:]\n",
    "\n",
    "        return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import socket\n",
    "from datetime import datetime\n",
    "#from tracemalloc import start\n",
    "#from tqdm import tqdm#可视化进度条\n",
    "\n",
    "#from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.autograd import Variable\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#超参数\n",
    "num_epochs = 30\n",
    "#resume_epoch = 0#默认为零，从头开始训练\n",
    "#useTest = True#是否进行测试\n",
    "#原实验中是20和25，这里实验设备达不到原实验要求，所以等比例缩小\n",
    "#nTestInterval = 2#2个时期做一个测试\n",
    "#snapshot = 3#每5个时期保存一个模型\n",
    "lr = 0.01\n",
    "batch_size = 8\n",
    "dataset = 'ucf101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample, label = VideoDataset(dataset = dataset,split = 'train',preprocess = False)[30]\n",
    "\n",
    "# 将图像的通道维度移到最后一个维度上\n",
    "sample = sample.permute(1, 2, 3, 0)\n",
    "\n",
    "# 可视化显示16帧图像\n",
    "fig, axes = plt.subplots(nrows=2, ncols=8, figsize=(8, 8))\n",
    "for i in range(2):\n",
    "    for j in range(8):\n",
    "        idx = i * 2 + j\n",
    "        axes[i][j].imshow(sample[idx].numpy())\n",
    "        axes[i][j].axis('off')\n",
    "        axes[i][j].set_title(f\"Frame {idx+1}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import logging\n",
    "import math\n",
    "import shutil\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import torch.distributed as dist\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def is_dist_avail_and_initialized():\n",
    "    if not dist.is_available():\n",
    "        return False\n",
    "    if not dist.is_initialized():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_world_size():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 1\n",
    "    return dist.get_world_size()\n",
    "\n",
    "def get_rank():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 0\n",
    "    return dist.get_rank()    \n",
    "\n",
    "def is_main_process():\n",
    "    return get_rank() == 0\n",
    "\n",
    "\n",
    "def makedirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, 0o777)\n",
    "\n",
    "def load_value_file(file_path):\n",
    "    with open(file_path, 'r') as input_file:\n",
    "        value = float(input_file.read().rstrip('\\n\\r'))\n",
    "\n",
    "    return value\n",
    "\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    _, pred = outputs.topk(1, 1, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1))\n",
    "    n_correct_elems = correct.float().sum().item()\n",
    "\n",
    "    return n_correct_elems / batch_size\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    \n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.contiguous().t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred)).contiguous()\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].contiguous().view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def adjust_learning_rate1(optimizer, base_lr, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "\n",
    "    alpha = (epoch + 2000) / 2000\n",
    "    warm = (1. / 10) * (1 - alpha) + alpha\n",
    "    lr = base_lr * warm\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr \n",
    "\n",
    "def adjust_learning_rate(optimizer, base_lr, epoch, lr_steps):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    decay = 0.1 ** (sum(epoch >= np.array(lr_steps)))\n",
    "    lr = base_lr * decay\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def part_state_dict(state_dict, model_dict):\n",
    "    pretrained_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k in model_dict:\n",
    "            pretrained_dict[k] = v\n",
    "        else:\n",
    "            print(k)\n",
    "    pretrained_dict = inflate_state_dict(pretrained_dict, model_dict)\n",
    "    #model_dict.update(pretrained_dict)\n",
    "    return pretrained_dict\n",
    "\n",
    "def inflate_state_dict(pretrained_dict, model_dict):\n",
    "    for k in pretrained_dict.keys():\n",
    "        if k in model_dict.keys() and 'fc' not in k:\n",
    "            if pretrained_dict[k].size() != model_dict[k].size():\n",
    "                assert(\n",
    "                    pretrained_dict[k].size()[:2] == model_dict[k].size()[:2]), \"To inflate, channel number should match.\"\n",
    "                assert(pretrained_dict[k].size()[-2:] == model_dict[k].size()[-2:]), \"To inflate, spatial kernel size should match.\"\n",
    "                #print(\"Layer {} needs inflation.\".format(k))\n",
    "                shape = list(pretrained_dict[k].shape)\n",
    "                shape.insert(2, 1)\n",
    "                t_length = model_dict[k].shape[2]\n",
    "                pretrained_dict[k] = pretrained_dict[k].reshape(shape)\n",
    "                if t_length != 1:\n",
    "                    pretrained_dict[k] = pretrained_dict[k].expand_as(\n",
    "                        model_dict[k]) / t_length\n",
    "                assert(pretrained_dict[k].size() == model_dict[k].size()), \\\n",
    "                    \"After inflation, model shape should match.\"\n",
    "\n",
    "    return pretrained_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        \"\"\"\n",
    "        Warning: does not synchronize the deque!\n",
    "        \"\"\"\n",
    "        if not is_dist_avail_and_initialized():\n",
    "            return\n",
    "        t = torch.tensor([self.count, self.sum],\n",
    "                         dtype=torch.float64, device='cuda')\n",
    "        dist.barrier()\n",
    "        dist.all_reduce(t)\n",
    "        t = t.tolist()\n",
    "        self.count = int(t[0])\n",
    "        self.sum = t[1]\n",
    "        self.avg = self.sum / (self.count + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NL_block(nn.Module):\n",
    "    def __init__(self,in_channels,reduction=2,use_scale=True):\n",
    "        super(NL_block,self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.reduction=reduction\n",
    "        self.use_scale=use_scale\n",
    "        self.inter_channels=max(in_channels//reduction,1)#原文中inter_channels减半\n",
    "        #使用embed高斯模式\n",
    "        #定义g函数和输出函数\n",
    "        self.g = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        self.conv_out = nn.Conv3d(self.inter_channels,self.in_channels,kernel_size=1,)\n",
    "        #定义theta和phi函数\n",
    "        self.theta = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        self.phi = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "\n",
    "    def embedded_gaussian(self,theta_x,phi_x):\n",
    "        pairwise_weight = torch.matmul(theta_x,phi_x)\n",
    "        if self.use_scale:\n",
    "            pairwise_weight /= theta_x.shape[-1]**0.5       \n",
    "        pairwise_weight /= pairwise_weight.softmax(dim=-1)\n",
    "        return pairwise_weight\n",
    "\n",
    "    def forward(self,x):\n",
    "        n = x.size(0)\n",
    "        g_x = self.g(x).view(n,self.inter_channels,-1)\n",
    "        g_x = g_x.permute(0,2,1)\n",
    "        \n",
    "        theta_x = self.theta(x).view(n,self.inter_channels,-1)\n",
    "        theta_x = theta_x.permute(0,2,1)\n",
    "        phi_x = self.phi(x).view(n,self.inter_channels,-1)\n",
    "\n",
    "        pairwise_weight = self.embedded_gaussian(theta_x,phi_x)\n",
    "        y  = torch.matmul(pairwise_weight,g_x)\n",
    "        out = y.permute(0, 2, 1).contiguous().reshape(n, self.inter_channels,*x.size()[2:])\n",
    "        \n",
    "        out = self.conv_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSElayer(nn.Module):\n",
    "    reduction = 2\n",
    "    def __init__(self,inplane):\n",
    "        super(TSElayer,self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(nn.Linear(inplane,inplane // self.reduction,bias=False),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(inplane // self.reduction,inplane,bias=False),\n",
    "                                nn.Sigmoid())\n",
    "        \n",
    "        #初始化fc层的线性层参数\n",
    "        for i in range(2):\n",
    "            if i == 1:\n",
    "                nn.init.constant(self.fc[i+1].weight,1)\n",
    "                nn.init.constant(self.fc[i+1].bias,0)\n",
    "            else:\n",
    "                nn.init.constant(self.fc[i].weight,1)\n",
    "                nn.init.constant(self.fc[i].bias,0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        n,c,t,_,_ = x.size()\n",
    "        x = x.transpose(1,2)#只交换维度，不改变数组\n",
    "        x = x.view(n,t,c,-1)\n",
    "        out = self.pool(x).view(n,t)\n",
    "        out = self.fc(out).view(n,1,t,1,1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SElayer(nn.Module):\n",
    "    reduction = 16\n",
    "    def __init__(self,inplane):\n",
    "        super(SElayer,self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(nn.Linear(inplane,inplane // self.reduction,bias=False),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(inplane // self.reduction,inplane,bias=False),\n",
    "                                nn.Sigmoid())\n",
    "\n",
    "    def forward(self,x):\n",
    "        n,c,_,_,_ = x.size()\n",
    "        #x = x.transpose(1,2)#只交换维度，不改变数组\n",
    "        y = self.pool(x).view(n,c)\n",
    "        #out = self.pool(x).view(n,t)\n",
    "        out = self.fc(y).view(n,c,1,1,1)\n",
    "\n",
    "        return x * out.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLC_block(nn.Module):\n",
    "    def __init__(self,in_channels,reduction=16):\n",
    "        super(NLC_block,self).__init__()\n",
    "        #self.big = nn.MaxPool3d(kernel_size=3,padding=1,stride=1)\n",
    "        #self.bn1 = nn.BatchNorm3d(in_channels)\n",
    "        self.in_channels=in_channels\n",
    "        self.reduction=reduction\n",
    "        #self.use_scale=use_scale\n",
    "        self.avg = nn.AdaptiveAvgPool3d((None,1,1))\n",
    "        self.bn2 = nn.BatchNorm1d(in_channels)\n",
    "        self.inter_channels=max(in_channels//reduction,1)#原文中inter_channels减半\n",
    "        #使用embed高斯模式\n",
    "        #定义g函数和输出函数\n",
    "        #self.g = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        #self.conv_out = nn.Conv3d(self.inter_channels,self.in_channels,kernel_size=1,)\n",
    "        self.g = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=3,padding=1,groups=self.inter_channels)\n",
    "        self.conv_out = nn.Conv1d(self.inter_channels,self.in_channels,kernel_size=3,padding=1,groups=self.inter_channels)\n",
    "        #定义theta和phi函数\n",
    "        #self.theta = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        #self.phi = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        self.theta = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=3,padding=1,groups=self.inter_channels)\n",
    "        self.phi = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=3,padding=1,groups=self.inter_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def embedded_gaussian(self,theta_x,phi_x):\n",
    "        pairwise_weight = torch.matmul(theta_x,phi_x)\n",
    "        #if self.use_scale:\n",
    "            #pairwise_weight /= theta_x.shape[-1]**0.5       \n",
    "        #pairwise_weight /= pairwise_weight.softmax(dim=-1)\n",
    "        pairwise_weight = F.softmax(pairwise_weight,dim=-1)\n",
    "\n",
    "        return pairwise_weight\n",
    "\n",
    "    def forward(self,x):\n",
    "        n,b,t,_,_ = x.size()\n",
    "        #resduial = x\n",
    "        #x = self.big(x)\n",
    "        #x = self.bn1(x)\n",
    "        x = self.avg(x)\n",
    "        x = x.view(n,self.in_channels,-1)\n",
    "        x = self.bn2(x)\n",
    "        g_x = self.g(x)\n",
    "        g_x = g_x.permute(0,2,1)\n",
    "        \n",
    "        theta_x = self.theta(x)\n",
    "        theta_x = theta_x.permute(0,2,1)\n",
    "        phi_x = self.phi(x)\n",
    "\n",
    "        pairwise_weight = self.embedded_gaussian(theta_x,phi_x)\n",
    "        y  = torch.matmul(pairwise_weight,g_x)\n",
    "        y = y.permute(0,2,1)\n",
    "        \n",
    "        out = self.conv_out(y)\n",
    "        out = out.reshape(n,b,t,1,1)\n",
    "        out = self.sigmoid(out)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTC_block(nn.Module):\n",
    "    def __init__(self,in_channels,reduction=2):\n",
    "        super(GTC_block,self).__init__()\n",
    "        #self.big = nn.MaxPool3d(kernel_size=3,padding=1,stride=1)\n",
    "        #self.bn1 = nn.BatchNorm3d(in_channels)\n",
    "        self.in_channels=in_channels\n",
    "        #self.num_segment = num_segment\n",
    "        self.reduction=reduction\n",
    "        #self.use_scale=use_scale\n",
    "        self.avg = nn.AdaptiveAvgPool3d((None,1,1))\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        #self.bn2 = nn.BatchNorm1d(in_channels)\n",
    "        self.inter_channels=max(in_channels//reduction,1)#原文中inter_channels减半\n",
    "        #使用embed高斯模式\n",
    "        #定义g函数和输出函数\n",
    "        #self.g = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        #self.conv_out = nn.Conv3d(self.inter_channels,self.in_channels,kernel_size=1,)\n",
    "        self.g = nn.Conv1d(self.in_channels,self.in_channels,kernel_size=3,padding=1,groups=self.in_channels)\n",
    "        #self.conv_out = nn.Conv1d(self.inter_channels,self.in_channels,kernel_size=1,padding=0,groups=1)\n",
    "        #定义theta和phi函数\n",
    "        #self.theta = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        #self.phi = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        self.theta = nn.Conv1d(self.in_channels,self.in_channels,kernel_size=3,padding = 1,groups=self.in_channels)\n",
    "        self.phi = nn.Conv1d(self.in_channels,self.in_channels,kernel_size=3,padding = 1,groups=self.in_channels)\n",
    "        \n",
    "        ## init seprabale conv as init\n",
    "        self.g.weight.data.zero_()\n",
    "        self.g.weight[:, :, 3 // 2].data.fill_(1)\n",
    "        ## init seprabale conv as init\n",
    "        self.theta.weight.data.zero_()\n",
    "        self.theta.weight[:, :, 3 // 2].data.fill_(1)\n",
    "        ## init seprabale conv as init\n",
    "        self.phi.weight.data.zero_()\n",
    "        self.phi.weight[:, :, 3 // 2].data.fill_(1)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d) or isinstance(m, nn.Conv1d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            if isinstance(m, nn.BatchNorm3d) or isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "        \n",
    "    def embedded_gaussian(self,theta_x,phi_x):\n",
    "        pairwise_weight = torch.matmul(theta_x,phi_x)\n",
    "        #if self.use_scale:\n",
    "            #pairwise_weight /= theta_x.shape[-1]**0.5       \n",
    "        #pairwise_weight /= pairwise_weight.softmax(dim=-1)\n",
    "        pairwise_weight = F.softmax(pairwise_weight,dim=-1)\n",
    "\n",
    "        return pairwise_weight\n",
    "\n",
    "    def forward(self,x):\n",
    "        n,c,t,h,w = x.size()\n",
    "        #n = nt // self.num_segment\n",
    "        resduial = x\n",
    "        #x = self.big(x)\n",
    "        #x = self.bn1(x)\n",
    "        #时间通道注意力分支\n",
    "        x = self.avg(x)\n",
    "        #x = x.view((-1,self.num_segment)+(x.size()[1:]))#n,t,c,1,1\n",
    "        x = x.contiguous().view(n,c,-1)#合并为通道维度\n",
    "        #x = x.permute(0,2,1)#shape:n,c,t\n",
    "        x = self.bn1(x)#按照通道进行批归一化\n",
    "        #g_x = self.g(x)\n",
    "        #g_x = g_x.permute(0,2,1)#交换两个维度\n",
    "        \n",
    "        theta_x = self.theta(x).permute(0,2,1)#n,t,c\n",
    "        phi_x = self.phi(x)\n",
    "            \n",
    "        pairwise_weight = self.embedded_gaussian(theta_x,phi_x)#通道自注意力分数(shape:t*t)\n",
    "        #1d卷积分支\n",
    "        new_r = resduial.permute(0,3,4,1,2)#n,h,w,c,t\n",
    "        new_r = resduial.view(-1,c,t)#nhw,c,t\n",
    "        new_r = self.g(new_r)\n",
    "        new_r = new_r.reshape(n,c*h*w,t)#n,chw,t\n",
    "        #new_r = new_r.permute(0,2,1)\n",
    "        new_r = torch.matmul(new_r,pairwise_weight)#n,chw,t\n",
    "        new_r = new_r.reshape(n,c,t,h,w)#n,t,c,h,w\n",
    "        #new_r = new_r.permute(0,4,1,2,3)\n",
    "        #new_r = new_r.contiguous().view((-1,) + new_r.size()[2:])\n",
    "        x_out = resduial + new_r\n",
    "        \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLC5_block(nn.Module):\n",
    "    def __init__(self,in_channels,reduction=16):\n",
    "        super(NLC5_block,self).__init__()\n",
    "        #self.big = nn.MaxPool3d(kernel_size=3,padding=1,stride=1)\n",
    "        #self.bn1 = nn.BatchNorm3d(in_channels)\n",
    "        self.in_channels=in_channels\n",
    "        self.reduction=reduction\n",
    "        #self.use_scale=use_scale\n",
    "        self.avg = nn.AdaptiveAvgPool3d((None,1,1))\n",
    "        self.bn2 = nn.BatchNorm1d(in_channels)\n",
    "        self.inter_channels=max(in_channels//reduction,1)#原文中inter_channels减半\n",
    "        #使用embed高斯模式\n",
    "        #定义g函数和输出函数\n",
    "        #self.g = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        #self.conv_out = nn.Conv3d(self.inter_channels,self.in_channels,kernel_size=1,)\n",
    "        self.g = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=5,padding=2,groups=self.inter_channels)\n",
    "        self.conv_out = nn.Conv1d(self.inter_channels,self.in_channels,kernel_size=5,padding=2,groups=self.inter_channels)\n",
    "        #定义theta和phi函数\n",
    "        #self.theta = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        #self.phi = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        self.theta = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=5,padding=2,groups=self.inter_channels)\n",
    "        self.phi = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=5,padding=2,groups=self.inter_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def embedded_gaussian(self,theta_x,phi_x):\n",
    "        pairwise_weight = torch.matmul(theta_x,phi_x)\n",
    "        #if self.use_scale:\n",
    "            #pairwise_weight /= theta_x.shape[-1]**0.5       \n",
    "        #pairwise_weight /= pairwise_weight.softmax(dim=-1)\n",
    "        pairwise_weight = F.softmax(pairwise_weight,dim=-1)\n",
    "\n",
    "        return pairwise_weight\n",
    "\n",
    "    def forward(self,x):\n",
    "        n,b,t,_,_ = x.size()\n",
    "        #resduial = x\n",
    "        #x = self.big(x)\n",
    "        #x = self.bn1(x)\n",
    "        x = self.avg(x)\n",
    "        x = x.view(n,self.in_channels,-1)\n",
    "        x = self.bn2(x)\n",
    "        g_x = self.g(x)\n",
    "        g_x = g_x.permute(0,2,1)\n",
    "        \n",
    "        theta_x = self.theta(x)\n",
    "        theta_x = theta_x.permute(0,2,1)\n",
    "        phi_x = self.phi(x)\n",
    "\n",
    "        pairwise_weight = self.embedded_gaussian(theta_x,phi_x)\n",
    "        y  = torch.matmul(pairwise_weight,g_x)\n",
    "        y = y.permute(0,2,1)\n",
    "        \n",
    "        out = self.conv_out(y)\n",
    "        out = out.reshape(n,b,t,1,1)\n",
    "        out = self.sigmoid(out)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLC7_block(nn.Module):\n",
    "    def __init__(self,in_channels,reduction=16):\n",
    "        super(NLC7_block,self).__init__()\n",
    "        #self.big = nn.MaxPool3d(kernel_size=3,padding=1,stride=1)\n",
    "        #self.bn1 = nn.BatchNorm3d(in_channels)\n",
    "        self.in_channels=in_channels\n",
    "        self.reduction=reduction\n",
    "        #self.use_scale=use_scale\n",
    "        self.avg = nn.AdaptiveAvgPool3d((None,1,1))\n",
    "        self.bn2 = nn.BatchNorm1d(in_channels)\n",
    "        self.inter_channels=max(in_channels//reduction,1)#原文中inter_channels减半\n",
    "        #使用embed高斯模式\n",
    "        #定义g函数和输出函数\n",
    "        #self.g = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        #self.conv_out = nn.Conv3d(self.inter_channels,self.in_channels,kernel_size=1,)\n",
    "        self.g = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=7,padding=3,groups=self.inter_channels)\n",
    "        self.conv_out = nn.Conv1d(self.inter_channels,self.in_channels,kernel_size=7,padding=3,groups=self.inter_channels)\n",
    "        #定义theta和phi函数\n",
    "        #self.theta = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        #self.phi = nn.Conv3d(self.in_channels,self.inter_channels,kernel_size=1,)\n",
    "        self.theta = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=7,padding=3,groups=self.inter_channels)\n",
    "        self.phi = nn.Conv1d(self.in_channels,self.inter_channels,kernel_size=7,padding=3,groups=self.inter_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def embedded_gaussian(self,theta_x,phi_x):\n",
    "        pairwise_weight = torch.matmul(theta_x,phi_x)\n",
    "        #if self.use_scale:\n",
    "            #pairwise_weight /= theta_x.shape[-1]**0.5       \n",
    "        #pairwise_weight /= pairwise_weight.softmax(dim=-1)\n",
    "        pairwise_weight = F.softmax(pairwise_weight,dim=-1)\n",
    "\n",
    "        return pairwise_weight\n",
    "\n",
    "    def forward(self,x):\n",
    "        n,b,t,_,_ = x.size()\n",
    "        #resduial = x\n",
    "        #x = self.big(x)\n",
    "        #x = self.bn1(x)\n",
    "        x = self.avg(x)\n",
    "        x = x.view(n,self.in_channels,-1)\n",
    "        x = self.bn2(x)\n",
    "        g_x = self.g(x)\n",
    "        g_x = g_x.permute(0,2,1)\n",
    "        \n",
    "        theta_x = self.theta(x)\n",
    "        theta_x = theta_x.permute(0,2,1)\n",
    "        phi_x = self.phi(x)\n",
    "\n",
    "        pairwise_weight = self.embedded_gaussian(theta_x,phi_x)\n",
    "        y  = torch.matmul(pairwise_weight,g_x)\n",
    "        y = y.permute(0,2,1)\n",
    "        \n",
    "        out = self.conv_out(y)\n",
    "        out = out.reshape(n,b,t,1,1)\n",
    "        out = self.sigmoid(out)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck2D(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(Bottleneck2D,self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes,planes,kernel_size=1,stride=[t_stride,1,1],bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes,planes,kernel_size=(1,3,3),stride=[1,stride,stride],padding=(0,1,1),bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes,planes,kernel_size=1,stride=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes,planes,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入nlc块的res块\n",
    "class Bottleneck_NLC(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(Bottleneck_NLC,self).__init__()\n",
    "        self.nlc = NLC_block(inplanes)\n",
    "        self.conv1 = nn.Conv3d(inplanes,planes,kernel_size=1,stride=[t_stride,1,1],bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes,planes,kernel_size=(1,3,3),stride=(1,stride,stride),padding=(0,1,1),bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = x * self.nlc(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入nlc块的res块\n",
    "class Bottleneck_GTC(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(Bottleneck_GTC,self).__init__()\n",
    "        self.gtc = GTC_block(inplanes)\n",
    "        self.conv1 = nn.Conv3d(inplanes,planes,kernel_size=1,stride=[t_stride,1,1],bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes,planes,kernel_size=(1,3,3),stride=(1,stride,stride),padding=(0,1,1),bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = self.gtc(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckSE(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(BottleneckSE,self).__init__()\n",
    "        self.se = SElayer(inplane=inplanes)\n",
    "        self.conv1 = nn.Conv3d(inplanes,planes,kernel_size=1,stride=[t_stride,1,1],bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes,planes,kernel_size=(1,3,3),stride=[1,stride,stride],padding=(0,1,1),bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = self.se(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入nlc块的res块\n",
    "class Bottleneck_NLC5(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(Bottleneck_NLC5,self).__init__()\n",
    "        self.nlc = NLC5_block(inplanes)\n",
    "        self.conv1 = nn.Conv3d(inplanes,planes,kernel_size=1,stride=[t_stride,1,1],bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes,planes,kernel_size=(1,3,3),stride=(1,stride,stride),padding=(0,1,1),bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = x * self.nlc(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入nlc7块的res块\n",
    "class Bottleneck_NLC7(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(Bottleneck_NLC7,self).__init__()\n",
    "        self.nlc = NLC7_block(inplanes)\n",
    "        self.conv1 = nn.Conv3d(inplanes,planes,kernel_size=1,stride=[t_stride,1,1],bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes,planes,kernel_size=(1,3,3),stride=(1,stride,stride),padding=(0,1,1),bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = x * self.nlc(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck_T(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(Bottleneck_T,self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes,planes,kernel_size=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.big1 = nn.MaxPool3d(kernel_size=3,padding=1,stride=1)\n",
    "        self.tse1 = TSElayer(16)#16帧\n",
    "        self.conv2 = nn.Conv3d(planes,planes,kernel_size=(1,3,3),stride=(1,stride,stride),padding=(0,1,1),bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out1 = out + out * self.tse1(self.big1(out))\n",
    "\n",
    "        out2 = self.conv2(out1)\n",
    "        out2 = self.bn2(out2)\n",
    "        out2 = self.relu(out2)\n",
    "        \n",
    "        out3 = self.conv3(out2)\n",
    "        out3 = self.bn3(out3)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out3 += residual\n",
    "        out3 = self.relu(out3)\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用3D卷积，并且只对空间进行提取最大视图\n",
    "class Bottleneck100_T1(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,inplanes,planes,stride = 1,t_stride = 1,downsample = None,t_length = None):\n",
    "        super(Bottleneck_T,self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes,planes,kernel_size=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.big1 = nn.MaxPool3d(kernel_size = (1,3,3),padding = (0,1,1),stride=1)\n",
    "        self.tse1 = TSElayer(16)\n",
    "        self.conv2 = nn.Conv3d(planes,planes,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out1 = out + self.tse1(self.big1(out))\n",
    "\n",
    "        out2 = self.conv2(out1)\n",
    "        out2 = self.bn2(out2)\n",
    "        out2 = self.relu(out2)\n",
    "        \n",
    "        out3 = self.conv3(out2)\n",
    "        out3 = self.bn3(out3)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out3 += residual\n",
    "        out3 = self.relu(out3)\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class local_NolocalNet(nn.Module):\n",
    "    def __init__(self,Test,block,layers,imagenet_pre,num_channels,num_classes=1000,feat=False,t_length=8,**kwargs):\n",
    "        if not isinstance(block,list):\n",
    "            block = [block]*4\n",
    "        self.inplanes = 64\n",
    "        super(local_NolocalNet,self).__init__()\n",
    "\n",
    "        self.feat = feat\n",
    "        self.conv1 = nn.Conv3d(3,64,kernel_size=(1,7,7),stride=[1,2,2],padding=(0,3,3),bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool3d(kernel_size=3,stride=2,padding=1)\n",
    "        self.layer1 = self._make_layer(block[0],num_channels[0],layers[0])\n",
    "        #self.NL1 = nn.Sequential(nn.MaxPool3d(kernel_size = 3,padding = 1,stride=1),\n",
    "                                #nn.BatchNorm3d(num_channels[0]*4),\n",
    "                                #NL_block(num_channels[0]*4))    \n",
    "        self.layer2 = self._make_layer(block[1],num_channels[1],layers[1],stride=2,t_stride=1,t_length=t_length)\n",
    "        #self.NL2 = nn.Sequential(nn.MaxPool3d(kernel_size = 3,padding = 1,stride=[2,1,1]),\n",
    "                                #nn.BatchNorm3d(num_channels[1]*4),\n",
    "                                #NL_block(num_channels[1]*4))  \n",
    "        self.layer3 = self._make_layer(block[2],num_channels[2],layers[2],stride=2,t_stride=1,t_length=t_length)\n",
    "        #self.NL3 = nn.Sequential(nn.MaxPool3d(kernel_size = 3,padding = 1,stride=1),\n",
    "                                #nn.BatchNorm3d(num_channels[2]*4),\n",
    "                                #NL_block(num_channels[2]*4))  \n",
    "        self.layer4 = self._make_layer(block[3],num_channels[3],layers[3],stride = 2,t_stride = 1,t_length=t_length)\n",
    "        #self.NL4 = nn.Sequential(nn.MaxPool3d(kernel_size = 3,padding = 1,stride=1),\n",
    "                                #nn.BatchNorm3d(num_channels[3]*4),\n",
    "                                #NL_block(num_channels[3]*4))  \n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "        self.feat_dim = 512 * block[0].expansion\n",
    "        self.test = Test\n",
    "        if imagenet_pre and is_main_process():\n",
    "            print('using imagenet pretraining weight set the BN as zero')\n",
    "\n",
    "        if not feat:\n",
    "            self.fc = nn.Linear(self.feat_dim,num_classes)\n",
    "            \n",
    "        for n,m in self.named_modules():\n",
    "            if isinstance(m,nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')#kaiming初始化\n",
    "            if 'big' in n:\n",
    "                if isinstance(m,nn.BatchNorm3d):\n",
    "                    nn.init.constant_(m.weight,0)\n",
    "                    nn.init.constant_(m.bias,0)        \n",
    "\n",
    "    def _make_layer(self,block,planes,blocks,stride=1,t_stride=1,t_length=8):\n",
    "        downsample = None\n",
    "        #步长为1，视频帧大小不会发生变化\n",
    "        if stride != 1 or self.inplanes != planes*block.expansion:\n",
    "            downsample = nn.Sequential(nn.Conv3d(self.inplanes,planes*block.expansion,kernel_size=1,stride=(1,stride,stride),bias=False),\n",
    "                                    nn.BatchNorm3d(planes*block.expansion),)\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(block(self.inplanes,planes,t_length=t_length))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.maxpool1(self.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        #out = self.NL1(out)\n",
    "        out = self.layer2(out)\n",
    "        #out = self.NL2(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.NL3(out)\n",
    "        out = self.layer4(out)\n",
    "        #out = self.NL4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        if not self.test:\n",
    "            out = out.view(out.size(0),-1)#按列展开\n",
    "        if not self.feat:\n",
    "            out = self.fc(out)\n",
    "            \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TseBigNet(nn.Module):\n",
    "    def __init__(self,Test,block,layers,imagenet_pre,num_classes=1000,feat=False,t_length=8,**kwargs):\n",
    "        if not isinstance(block,list):\n",
    "            block = [block]*4\n",
    "        self.inplanes = 64\n",
    "        super(TseBigNet,self).__init__()\n",
    "\n",
    "        self.feat = feat\n",
    "        self.conv1 = nn.Conv3d(3,64,kernel_size=(1,7,7),stride=[1,2,2],padding=(0,3,3),bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(1,3,3),stride=[1,2,2],padding=(0,1,1))\n",
    "        self.layer1 = self._make_layer(block[0],64,layers[0])    \n",
    "        self.layer2 = self._make_layer(block[1],128,layers[1],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer3 = self._make_layer(block[2],256,layers[2],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer4 = self._make_layer(block[3],512,layers[3],stride = 2,t_stride = 1,t_length=t_length)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "        self.feat_dim = 512 * block[0].expansion\n",
    "        self.test = Test\n",
    "        if imagenet_pre and is_main_process():\n",
    "            print('using imagenet pretraining weight set the BN as zero')\n",
    "\n",
    "        if not feat:\n",
    "            self.fc = nn.Linear(self.feat_dim,num_classes)\n",
    "        \n",
    "        #初始化权重\n",
    "        for n,m in self.named_modules():\n",
    "            if isinstance(m,nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
    "            elif isinstance(m,nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "\n",
    "    def _make_layer(self,block,planes,blocks,stride=1,t_stride=1,t_length=8):\n",
    "        downsample = None\n",
    "        #步长为1，视频帧大小不会发生变化\n",
    "        if stride != 1 or self.inplanes != planes*block.expansion:\n",
    "            downsample = nn.Sequential(nn.Conv3d(self.inplanes,planes*block.expansion,kernel_size=1,stride=(1,stride,stride),bias=False),\n",
    "                                    nn.BatchNorm3d(planes*block.expansion),)\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(block(self.inplanes,planes,t_length=t_length))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        if not self.test:\n",
    "            out = out.view(out.size(0),-1)#按列展开\n",
    "        if not self.feat:\n",
    "            out = self.fc(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLCNet(nn.Module):\n",
    "    def __init__(self,Test,block,layers,imagenet_pre,num_classes=1000,feat=False,t_length=8,**kwargs):\n",
    "        if not isinstance(block, list):\n",
    "            block = [block] * 4\n",
    "        self.inplanes = 64\n",
    "        super(NLCNet, self).__init__()\n",
    "\n",
    "        #self.nlc = NLC_block()\n",
    "\n",
    "        self.feat = feat\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(1, 7, 7),stride=(1, 2, 2), padding=(0, 3, 3),bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
    "        self.layer1 = self._make_layer(block[0], 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block[1],128,layers[1],stride=2,t_stride=1, t_length=t_length)\n",
    "        self.layer3 = self._make_layer(block[2],256,layers[2],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer4 = self._make_layer(block[3],512,layers[3],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "        self.feat_dim = 512 * block[0].expansion\n",
    "        self.test = Test\n",
    "        if imagenet_pre and is_main_process():\n",
    "            print('using imagenet pretraining weight set the BN as zero')\n",
    "\n",
    "        if not feat:\n",
    "            self.fc = nn.Linear(self.feat_dim, num_classes)\n",
    "        \n",
    "        #初始化参数\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.Conv3d) or isinstance(m,nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if isinstance(m,nn.BatchNorm3d) or isinstance(m,nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight,0)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            #if 'big' in n:\n",
    "                #if isinstance(m, nn.BatchNorm3d):\n",
    "                    #nn.init.constant_(m.weight, 0)\n",
    "                    #nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self,block,planes,blocks,stride=1,t_stride=1,t_length=8):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.inplanes,planes * block.expansion,kernel_size=1,stride=(1, stride, stride),bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, t_length=t_length))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def _make_full_layer(self,block,planes,blocks,stride=1,t_stride=1,t_length=8):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.inplanes,planes * block.expansion,kernel_size=1,stride=(1, stride, stride),bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(NLC_block(self.inplanes,reduction = 16))\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(NLC_block(self.inplanes,reduction = 16))\n",
    "            layers.append(block(self.inplanes, planes, t_length=t_length))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def _make_last_layer(self,block,planes,blocks,stride=1,t_stride=1,t_length=8):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.inplanes,planes * block.expansion,kernel_size=1,stride=(1, stride, stride),bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        \n",
    "        for i in range(1, blocks):\n",
    "            if i != blocks-1:\n",
    "                layers.append(block(self.inplanes,planes,t_length=t_length))\n",
    "            else:\n",
    "                layers.append(NLC_block(self.inplanes,reduction = 16))\n",
    "                layers.append(block(self.inplanes,planes,t_length=t_length))    \n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        if not self.test:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        if not self.feat:\n",
    "            x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,Test,block,layers,imagenet_pre,num_classes=1000,feat=False,t_length=8,**kwargs):\n",
    "        if not isinstance(block,list):\n",
    "            block = [block]*4\n",
    "        self.inplanes = 64\n",
    "        super(ResNet,self).__init__()\n",
    "\n",
    "        self.feat = feat\n",
    "        self.num_segment = t_length\n",
    "        self.conv1 = nn.Conv3d(3,64,kernel_size=(1,7,7),stride=[1,2,2],padding=(0,3,3),bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(1,3,3),stride=[1,2,2],padding=(0,1,1))#这层无需参数\n",
    "        self.layer1 = self._make_layer(block[0],64,layers[0])    \n",
    "        self.layer2 = self._make_layer(block[1],128,layers[1],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer3 = self._make_layer(block[2],256,layers[2],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer4 = self._make_layer(block[3],512,layers[3],stride = 2,t_stride = 1,t_length=t_length)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "        self.feat_dim = 512 * block[0].expansion\n",
    "        self.test = Test\n",
    "        if imagenet_pre and is_main_process():\n",
    "            print('using imagenet pretraining weight set the BN as zero')\n",
    "\n",
    "        if not feat:\n",
    "            self.fc = nn.Linear(self.feat_dim,num_classes)\n",
    "        \n",
    "        #参数初始化\n",
    "        for n,m in self.named_modules():\n",
    "            if isinstance(m,nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')#kaiming初始化 \n",
    "            elif isinstance(m,nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "    def _make_layer(self,block,planes,blocks,stride=1,t_stride=1,t_length=8):\n",
    "        downsample = None\n",
    "        #步长为1，视频帧大小不会发生变化\n",
    "        if stride != 1 or self.inplanes != planes*block.expansion:\n",
    "            downsample = nn.Sequential(nn.Conv3d(self.inplanes,planes*block.expansion,kernel_size=1,stride=(1,stride,stride),bias=False),\n",
    "                                    nn.BatchNorm3d(planes*block.expansion),)\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(block(self.inplanes,planes,t_length=t_length))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view((-1, 3) + x.size()[-2:])#nt,c,h,w\n",
    "        nt,c,h,w = x.size()\n",
    "        x = x.reshape(x.size()[0]//self.num_segment,c,self.num_segment,h,w)#n,c,t,h,w\n",
    "        \n",
    "        out = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        if not self.test:\n",
    "            out = out.view(out.size(0),-1)#按列展开\n",
    "        if not self.feat:\n",
    "            out = self.fc(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet2D(nn.Module):\n",
    "    def __init__(self,Test,block,layers,imagenet_pre,num_classes=1000,feat=False,t_length=8,**kwargs):\n",
    "        if not isinstance(block,list):\n",
    "            block = [block]*4\n",
    "        self.inplanes = 64\n",
    "        super(ResNet2D,self).__init__()\n",
    "            \n",
    "        self.feat = feat\n",
    "        self.num_segment = t_length\n",
    "        self.conv1 = nn.Conv3d(3,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3,stride=2,padding=1)#这层无需参数\n",
    "        self.layer1 = self._make_layer(block[0],64,layers[0])    \n",
    "        self.layer2 = self._make_layer(block[1],128,layers[1],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer3 = self._make_layer(block[2],256,layers[2],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer4 = self._make_layer(block[3],512,layers[3],stride = 2,t_stride = 1,t_length=t_length)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "        self.feat_dim = 512 * block[0].expansion\n",
    "        self.test = Test\n",
    "        if imagenet_pre and is_main_process():\n",
    "            print('using imagenet pretraining weight set the BN as zero')\n",
    "\n",
    "        if not feat:\n",
    "            self.fc = nn.Linear(self.feat_dim,num_classes)\n",
    "        \n",
    "        #参数初始化\n",
    "        for n,m in self.named_modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')#kaiming初始化 \n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "    def _make_layer(self,block,planes,blocks,stride=1,t_stride=1,t_length=8):\n",
    "        downsample = None\n",
    "        #步长为1，视频帧大小不会发生变化\n",
    "        if stride != 1 or self.inplanes != planes*block.expansion:\n",
    "            downsample = nn.Sequential(nn.Conv2d(self.inplanes,planes*block.expansion,kernel_size=1,stride=stride,bias=False),\n",
    "                                    nn.BatchNorm2d(planes*block.expansion),)\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(block(self.inplanes,planes,t_length=t_length))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        b,c,t,h,w = x.size()\n",
    "        x = x.permute(0,2,1,3,4)\n",
    "        x = x.reshape(-1,c,h,w)\n",
    "        out = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.reshape(b,t,out.shape[1],out.shape[2],out.shape[3])\n",
    "        out = out.permute(0,2,1,3,4)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        if not self.test:\n",
    "            out = out.view(out.size(0),-1)#按列展开\n",
    "        if not self.feat:\n",
    "            out = self.fc(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet2D_1(nn.Module):\n",
    "    def __init__(self,Test,block,layers,imagenet_pre,num_classes=1000,feat=False,t_length=8,**kwargs):\n",
    "        if not isinstance(block,list):\n",
    "            block = [block]*4\n",
    "        self.inplanes = 64\n",
    "        super(ResNet2D_1,self).__init__()\n",
    "\n",
    "        self.feat = feat\n",
    "        self.num_segment = t_length\n",
    "        self.conv1 = nn.Conv3d(3,64,kernel_size=(1,7,7),stride=[1,2,2],padding=(0,3,3),bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(1,3,3),stride=[1,2,2],padding=(0,1,1))#这层无需参数\n",
    "        self.layer1 = self._make_layer(block[0],64,layers[0])    \n",
    "        self.layer2 = self._make_layer(block[1],128,layers[1],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer3 = self._make_layer(block[2],256,layers[2],stride=2,t_stride=1,t_length=t_length)\n",
    "        self.layer4 = self._make_layer(block[3],512,layers[3],stride = 2,t_stride = 1,t_length=t_length)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "        self.feat_dim = 512 * block[0].expansion\n",
    "        self.test = Test\n",
    "        if imagenet_pre and is_main_process():\n",
    "            print('using imagenet pretraining weight set the BN as zero')\n",
    "\n",
    "        if not feat:\n",
    "            self.fc = nn.Linear(self.feat_dim,num_classes)\n",
    "        \n",
    "        #参数初始化\n",
    "        for n,m in self.named_modules():\n",
    "            if isinstance(m,nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')#kaiming初始化 \n",
    "            elif isinstance(m,nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "    def _make_layer(self,block,planes,blocks,stride=1,t_stride=1,t_length=8,last_block=False):\n",
    "        downsample = None\n",
    "        #步长为1，视频帧大小不会发生变化\n",
    "        if stride != 1 or self.inplanes != planes*block.expansion:\n",
    "            downsample = nn.Sequential(nn.Conv3d(self.inplanes,planes*block.expansion,kernel_size=1,stride=(1,stride,stride),bias=False),\n",
    "                                    nn.BatchNorm3d(planes*block.expansion),)\n",
    "        layers = []\n",
    "        if last_block:\n",
    "            layers.append(block(self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "            self.inplanes = planes * block.expansion\n",
    "            last_idx = blocks -1 \n",
    "\n",
    "            for i in range(1,last_idx):\n",
    "                layers.append(block(self.inplanes,planes,t_length=t_length))\n",
    "                \n",
    "            if last_block:\n",
    "                layers.append(GTC_block(self.inplanes,num_segment=self.num_segment))\n",
    "                layers.append(block(self.inplanes,planes,t_length=t_length))\n",
    "                \n",
    "            return nn.Sequential(*layers)\n",
    "        else:    \n",
    "            layers.append(block(self.inplanes,planes,stride=stride,t_stride=t_stride,downsample=downsample,t_length=t_length))\n",
    "            self.inplanes = planes * block.expansion\n",
    "\n",
    "            for i in range(1,blocks):\n",
    "                layers.append(block(self.inplanes,planes,t_length=t_length))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view((-1, 3) + x.size()[-2:])#nt,c,h,w\n",
    "        nt,c,h,w = x.size()\n",
    "        x = x.reshape(x.size()[0]//self.num_segment,c,self.num_segment,h,w)#n,c,t,h,w\n",
    "        \n",
    "        out = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        if not self.test:\n",
    "            out = out.view(out.size(0),-1)#按列展开\n",
    "        if not self.feat:\n",
    "            out = self.fc(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import model_zoo \n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "#part_state_dict()函数\n",
    "def use_image_pre_train(model,model_names):\n",
    "    if '50' or '23' in model_names:\n",
    "        state_dict = model_zoo.load_url(model_urls['resnet50'])\n",
    "    elif '101' in model_names:\n",
    "        state_dict = model_zoo.load_url(model_urls['resnet101'])\n",
    "    new_state_dict = part_state_dict(state_dict,model.state_dict())\n",
    "    idx = 0\n",
    "    model_dict = model.state_dict()\n",
    "    for k,v in new_state_dict.items():\n",
    "        if k in model_dict:\n",
    "            if v.shape == model_dict[k].shape:\n",
    "                model_dict[k] = v.cuda()\n",
    "                idx += 1\n",
    "    if is_main_process():\n",
    "        print(len(new_state_dict))\n",
    "        print(idx)\n",
    "        print('imagenet pre-trained weight upload already')\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_image_pre_train2D(model,model_names):\n",
    "    if '50' or '23' in model_names:\n",
    "        state_dict = model_zoo.load_url(model_urls['resnet50'])\n",
    "    elif '101' in model_names:\n",
    "        state_dict = model_zoo.load_url(model_urls['resnet101'])\n",
    "    #new_state_dict = part_state_dict(state_dict,model.state_dict())\n",
    "    idx = 0\n",
    "    model_dict = model.state_dict()\n",
    "    for k,v in state_dict.items():\n",
    "        if k in model_dict:\n",
    "            if v.shape == model_dict[k].shape:\n",
    "                model_dict[k] = v.cuda()\n",
    "                idx += 1\n",
    "    if is_main_process():\n",
    "        print(len(state_dict))\n",
    "        print(idx)\n",
    "        print('imagenet pre-trained weight upload already')\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#冻结resnet50卷积层参数，只对fc层进行优化\n",
    "def freeze_model(model):\n",
    "    for n,p in model.named_parameters():\n",
    "        if 'fc' not in n:\n",
    "            p.requires_grad = False\n",
    "    print('the parameters of model have been freezed')        \n",
    "    return model      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#冻结卷积层参数，只对fc层和nlc进行优化\n",
    "def freeze_gtcnet(model):\n",
    "    for n,p in model.named_parameters():\n",
    "        #if 'fc' not in n and'layer3.5' not in n:\n",
    "        if 'GTC' in n or 'fc' in n:\n",
    "            p.requires_grad = True\n",
    "        else:\n",
    "            p.requires_grad = False    \n",
    "    return model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#冻结卷积层参数，只对fc层和nlc进行优化\n",
    "def freeze_nlcnet(model):\n",
    "    for n,p in model.named_parameters():\n",
    "        #if 'fc' not in n and'layer3.5' not in n:\n",
    "        if 'nlc' in n or 'fc' in n:\n",
    "            p.requires_grad = True\n",
    "        else:\n",
    "            p.requires_grad = False    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSENet_50(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = TSENet(\n",
    "        test, [Bottleneck2D,Bottleneck2D,Bottleneck2D,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BigNet_50(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = BigNet(\n",
    "        test, [Bottleneck2D,Bottleneck2D,Bottleneck2D,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_50(model_names,num_classes,t_length,imagenet=False,test=False,feat=False):\n",
    "    model = ResNet(\n",
    "        test, [Bottleneck2D,Bottleneck2D,Bottleneck2D,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet2D_50(model_names,num_classes,t_length,imagenet=False,test=False,feat=False):\n",
    "    model = ResNet2D(\n",
    "        test, [Bottleneck,Bottleneck,Bottleneck,Bottleneck],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train2D(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TseBigNet_50(model_names,num_classes,t_length,imagenet=False,test=False,feat=False):\n",
    "    model = TseBigNet(\n",
    "        test, [Bottleneck_T,Bottleneck_T,Bottleneck_T,Bottleneck_T],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLCnet(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = NLCNet(\n",
    "        test, [Bottleneck2D,Bottleneck_NLC,Bottleneck2D,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLCnet1(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = NLCNet(\n",
    "        test, [Bottleneck_NLC,Bottleneck2D,Bottleneck2D,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLCnet2(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = NLCNet(\n",
    "        test, [Bottleneck2D,Bottleneck2D,Bottleneck_NLC,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLCnet3(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = NLCNet(\n",
    "        test, [Bottleneck2D,Bottleneck2D,Bottleneck2D,Bottleneck_NLC],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlc5的块 做对照实验\n",
    "def NLCnet5(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = NLCNet(\n",
    "        test, [Bottleneck_NLC5,Bottleneck2D,Bottleneck2D,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlc5的块 做对照实验\n",
    "def NLCnet7(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = NLCNet(\n",
    "        test, [Bottleneck_NLC7,Bottleneck2D,Bottleneck2D,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将nlc块添加到res2、3、4\n",
    "def NLCnet_full(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = NLCNet(\n",
    "        test, [Bottleneck_NLC,Bottleneck_NLC,Bottleneck_NLC,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将nlc块添加到res1、3\n",
    "def NLCnet_13(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = NLCNet(\n",
    "        test, [Bottleneck_NLC,Bottleneck2D,Bottleneck_NLC,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将nlc块添加到res1、3\n",
    "def GTCnet3(model_names,num_classes,t_length,num_channels,imagenet=False,test=False,feat=False):\n",
    "    model = ResNet2D_1(\n",
    "        test, [Bottleneck2D,Bottleneck_GTC,Bottleneck2D,Bottleneck2D],\n",
    "        [3, 4, 6, 3], imagenet, num_classes=num_classes, feat=feat, t_length=t_length,num_channels=num_channels)\n",
    "    if is_main_process():\n",
    "        #print(model)\n",
    "        #print_model_parm_flops(model, frame=args.t_length)\n",
    "        print('Total of model parameters:',sum([np.prod(param.data.shape) for param in model.parameters()]))#网络参数数量\n",
    "        print('Total params:%.3fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    if imagenet:\n",
    "        model = use_image_pre_train(model,model_names=model_names)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23740069\n",
      "Total params:23.740M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "gtcnet3 = GTCnet3(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "gtcnet3 = freeze_gtcnet(gtcnet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23742197\n",
      "Total params:23.742M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "nlcnet = NLCnet(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "nlcnet = freeze_nlcnet(nlcnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23723729\n",
      "Total params:23.724M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "nlcnet1 = NLCnet1(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "nlcnet1 = freeze_nlcnet(nlcnet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23800517\n",
      "Total params:23.801M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "nlcnet2 = NLCnet2(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "nlcnet2 = freeze_nlcnet(nlcnet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23792741\n",
      "Total params:23.793M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "nlcnet3 = NLCnet3(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "nlcnet3 = freeze_nlcnet(nlcnet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23714981\n",
      "Total params:23.71M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n",
      "the parameters of model have been freezed\n"
     ]
    }
   ],
   "source": [
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "net = ResNet_50(model_names,num_classes,t_length,imagenet=True)#使用预训练参数的resnet50网络\n",
    "net = freeze_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_names =['resnet50']\n",
    "#t_length ,num_classes= 16,101\n",
    "#net = ResNet2D_50(model_names,num_classes,t_length,imagenet=True)#使用预训练参数的resnet50网络\n",
    "#net = freeze_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23728337\n",
      "Total params:23.728M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "#kernel_size=5\n",
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "nlcnet5 = NLCnet5(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "nlcnet5 = freeze_nlcnet(nlcnet5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23732945\n",
      "Total params:23.733M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "#kernel_size=7\n",
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "nlcnet7 = NLCnet7(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "nlcnet7 = freeze_nlcnet(nlcnet7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 266, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23836481\n",
      "Total params:23.836M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "#在res1、2、3添加模块\n",
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "nlcnet_full = NLCnet_full(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "nlcnet_full = freeze_nlcnet(nlcnet_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet pretraining weight set the BN as zero\n",
      "Total of model parameters: 23809265\n",
      "Total params:23.809M\n",
      "267\n",
      "265\n",
      "imagenet pre-trained weight upload already\n"
     ]
    }
   ],
   "source": [
    "#在res1、3添加模块\n",
    "model_names =['resnet50']\n",
    "t_length ,num_classes= 16,101\n",
    "num_channels = [64,128,256,512]\n",
    "nlcnet_13 = NLCnet_13(model_names,num_classes,t_length,num_channels,imagenet=True)\n",
    "nlcnet_13 = freeze_nlcnet(nlcnet_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 101])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ResNet50\n",
    "Y1 = net(X)\n",
    "Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net,device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(data_iter):\n",
    "            X = data[0]\n",
    "            y = data[1]\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def train(net,lr,train_dataloader, test_dataloader,milestones,batch_size, device, num_epochs,save_path = None):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \",device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.CrossEntropyLoss()#交叉熵损失函数\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                          lr=lr,momentum=0.9,weight_decay=5e-4)#动量设置为0.9，权重衰减5e-4，并过滤参数，训练没有冻结的部分\n",
    "    #optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9,weight_decay=5e-4)#动量设置为0.9，权重衰减5e-4\n",
    "    #shceduler = optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)\n",
    "    shceduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones,gamma=0.1)#多间隔学习率调整\n",
    "\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for i,data in enumerate(train_dataloader):\n",
    "            X = data[0]\n",
    "            y = data[1]\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1      \n",
    "        test_acc = evaluate_accuracy(test_dataloader,net)\n",
    "        shceduler.step()  \n",
    "        if (epoch+1)%20 == 0:\n",
    "            checkpoint = {\n",
    "                'model': net.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            torch.save(checkpoint, save_path + 'ckpt_best_%s.pth' % (str(epoch + 1)))\n",
    "            \n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.9310, train acc 0.215, test acc 0.434, time 1535.0 sec\n",
      "epoch 2, loss 1.4150, train acc 0.500, test acc 0.600, time 1276.4 sec\n",
      "epoch 3, loss 0.7395, train acc 0.615, test acc 0.653, time 1288.0 sec\n",
      "epoch 4, loss 0.4655, train acc 0.671, test acc 0.699, time 1290.6 sec\n",
      "epoch 5, loss 0.3246, train acc 0.706, test acc 0.726, time 1304.8 sec\n",
      "epoch 6, loss 0.2444, train acc 0.729, test acc 0.748, time 1312.1 sec\n",
      "epoch 7, loss 0.1906, train acc 0.743, test acc 0.759, time 1315.0 sec\n",
      "epoch 8, loss 0.1555, train acc 0.759, test acc 0.757, time 1364.0 sec\n",
      "epoch 9, loss 0.1307, train acc 0.768, test acc 0.772, time 1379.4 sec\n",
      "epoch 10, loss 0.1093, train acc 0.784, test acc 0.780, time 1375.3 sec\n",
      "epoch 11, loss 0.0943, train acc 0.792, test acc 0.794, time 1383.3 sec\n",
      "epoch 12, loss 0.0831, train acc 0.799, test acc 0.803, time 1362.3 sec\n",
      "epoch 13, loss 0.0744, train acc 0.800, test acc 0.806, time 1326.1 sec\n",
      "epoch 14, loss 0.0659, train acc 0.812, test acc 0.804, time 1346.8 sec\n",
      "epoch 15, loss 0.0590, train acc 0.826, test acc 0.818, time 1360.7 sec\n",
      "epoch 16, loss 0.0538, train acc 0.817, test acc 0.821, time 1363.7 sec\n",
      "epoch 17, loss 0.0489, train acc 0.823, test acc 0.822, time 1319.2 sec\n",
      "epoch 18, loss 0.0452, train acc 0.827, test acc 0.824, time 1320.9 sec\n",
      "epoch 19, loss 0.0413, train acc 0.838, test acc 0.833, time 1322.8 sec\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(VideoDataset(dataset \u001b[38;5;241m=\u001b[39m dataset,split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,clip_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m,preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),batch_size \u001b[38;5;241m=\u001b[39mbatch_size,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)     \n\u001b[1;32m     10\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(VideoDataset(dataset \u001b[38;5;241m=\u001b[39m dataset,split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m,clip_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m,preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),batch_size \u001b[38;5;241m=\u001b[39m batch_size,num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmilestones\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, train_dataloader, test_dataloader, milestones, batch_size, device, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: net\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch\n\u001b[1;32m     55\u001b[0m     }\n\u001b[0;32m---> 56\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(checkpoint, \u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mckpt_best_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, loss \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m, train acc \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m, test acc \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m, time \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     59\u001b[0m       \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, train_l_sum \u001b[38;5;241m/\u001b[39m batch_count, train_acc_sum \u001b[38;5;241m/\u001b[39m n, test_acc, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "#milestones = [15,30,45]#多间隔学习率调整训练周期 \n",
    "#milestones = [35,45,55]#多间隔学习率调整\n",
    "milestones = [60,85,90]\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16\n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',clip_len = 8,preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',clip_len = 8,preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#没有添加预训练模型\n",
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train(net0,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#未使用预训练模型的resnet，划分0.7的训练集和0.3的测试集\n",
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train(net0,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 4.1377, train acc 0.069, test acc 0.169, time 1991.2 sec\n",
      "epoch 2, loss 1.4184, train acc 0.279, test acc 0.379, time 1969.0 sec\n",
      "epoch 3, loss 0.6660, train acc 0.455, test acc 0.540, time 2097.2 sec\n",
      "epoch 4, loss 0.3847, train acc 0.567, test acc 0.600, time 2098.3 sec\n",
      "epoch 5, loss 0.2549, train acc 0.640, test acc 0.695, time 2097.5 sec\n",
      "epoch 6, loss 0.1796, train acc 0.697, test acc 0.696, time 2119.6 sec\n",
      "epoch 7, loss 0.1341, train acc 0.733, test acc 0.706, time 1947.6 sec\n",
      "epoch 8, loss 0.1081, train acc 0.752, test acc 0.692, time 1939.1 sec\n",
      "epoch 9, loss 0.0862, train acc 0.769, test acc 0.760, time 1949.2 sec\n",
      "epoch 10, loss 0.0701, train acc 0.793, test acc 0.790, time 1990.2 sec\n",
      "epoch 11, loss 0.0291, train acc 0.912, test acc 0.919, time 2044.9 sec\n",
      "epoch 12, loss 0.0180, train acc 0.943, test acc 0.930, time 2073.8 sec\n",
      "epoch 13, loss 0.0142, train acc 0.953, test acc 0.941, time 2056.0 sec\n",
      "epoch 14, loss 0.0115, train acc 0.960, test acc 0.943, time 2068.1 sec\n",
      "epoch 15, loss 0.0100, train acc 0.962, test acc 0.945, time 2043.1 sec\n",
      "epoch 16, loss 0.0086, train acc 0.967, test acc 0.950, time 2014.7 sec\n",
      "epoch 17, loss 0.0072, train acc 0.973, test acc 0.947, time 1977.5 sec\n",
      "epoch 18, loss 0.0066, train acc 0.973, test acc 0.953, time 1985.8 sec\n",
      "epoch 19, loss 0.0055, train acc 0.976, test acc 0.953, time 1964.4 sec\n",
      "epoch 20, loss 0.0055, train acc 0.975, test acc 0.952, time 1989.4 sec\n",
      "epoch 23, loss 0.0038, train acc 0.983, test acc 0.956, time 2030.7 sec\n",
      "epoch 24, loss 0.0039, train acc 0.983, test acc 0.959, time 2020.7 sec\n",
      "epoch 25, loss 0.0034, train acc 0.984, test acc 0.953, time 2007.2 sec\n",
      "epoch 26, loss 0.0032, train acc 0.984, test acc 0.952, time 2012.2 sec\n",
      "epoch 27, loss 0.0032, train acc 0.983, test acc 0.956, time 2011.5 sec\n",
      "epoch 28, loss 0.0028, train acc 0.985, test acc 0.953, time 2027.7 sec\n",
      "epoch 29, loss 0.0029, train acc 0.983, test acc 0.954, time 2028.9 sec\n",
      "epoch 30, loss 0.0028, train acc 0.983, test acc 0.960, time 2019.4 sec\n"
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet\n",
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 2.8209, train acc 0.399, test acc 0.636, time 1427.6 sec\n",
      "epoch 2, loss 0.7968, train acc 0.603, test acc 0.726, time 1414.9 sec\n",
      "epoch 3, loss 0.4186, train acc 0.675, test acc 0.729, time 1422.3 sec\n",
      "epoch 4, loss 0.2817, train acc 0.702, test acc 0.773, time 1429.4 sec\n",
      "epoch 5, loss 0.2097, train acc 0.726, test acc 0.798, time 1438.8 sec\n",
      "epoch 6, loss 0.1525, train acc 0.754, test acc 0.821, time 1430.6 sec\n",
      "epoch 7, loss 0.1252, train acc 0.761, test acc 0.820, time 1423.1 sec\n",
      "epoch 8, loss 0.1024, train acc 0.773, test acc 0.827, time 1427.6 sec\n",
      "epoch 9, loss 0.0952, train acc 0.764, test acc 0.825, time 1429.6 sec\n",
      "epoch 10, loss 0.0793, train acc 0.779, test acc 0.833, time 1440.5 sec\n",
      "epoch 11, loss 0.0354, train acc 0.890, test acc 0.896, time 1422.7 sec\n",
      "epoch 12, loss 0.0294, train acc 0.901, test acc 0.897, time 1402.2 sec\n",
      "epoch 13, loss 0.0269, train acc 0.899, test acc 0.903, time 1409.7 sec\n",
      "epoch 14, loss 0.0248, train acc 0.904, test acc 0.901, time 1407.5 sec\n",
      "epoch 15, loss 0.0225, train acc 0.909, test acc 0.904, time 1404.5 sec\n",
      "epoch 16, loss 0.0215, train acc 0.906, test acc 0.901, time 1403.7 sec\n",
      "epoch 17, loss 0.0199, train acc 0.904, test acc 0.908, time 1405.7 sec\n",
      "epoch 18, loss 0.0186, train acc 0.910, test acc 0.904, time 1410.3 sec\n",
      "epoch 19, loss 0.0178, train acc 0.907, test acc 0.909, time 1414.8 sec\n",
      "epoch 20, loss 0.0159, train acc 0.916, test acc 0.910, time 1407.3 sec\n",
      "epoch 21, loss 0.0148, train acc 0.917, test acc 0.913, time 1407.7 sec\n",
      "epoch 22, loss 0.0144, train acc 0.918, test acc 0.911, time 1407.6 sec\n",
      "epoch 23, loss 0.0135, train acc 0.919, test acc 0.917, time 1412.9 sec\n",
      "epoch 24, loss 0.0132, train acc 0.917, test acc 0.912, time 1416.4 sec\n",
      "epoch 25, loss 0.0126, train acc 0.917, test acc 0.912, time 1408.3 sec\n",
      "epoch 26, loss 0.0120, train acc 0.920, test acc 0.915, time 1413.5 sec\n",
      "epoch 27, loss 0.0115, train acc 0.919, test acc 0.911, time 1411.7 sec\n",
      "epoch 28, loss 0.0115, train acc 0.915, test acc 0.909, time 1418.7 sec\n",
      "epoch 29, loss 0.0107, train acc 0.919, test acc 0.911, time 1411.4 sec\n",
      "epoch 30, loss 0.0099, train acc 0.925, test acc 0.912, time 1420.5 sec\n"
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 3.6920, train acc 0.230, test acc 0.528, time 1730.6 sec\n",
      "epoch 2, loss 1.2222, train acc 0.525, test acc 0.647, time 1710.1 sec\n",
      "epoch 3, loss 0.6277, train acc 0.628, test acc 0.713, time 1687.6 sec\n",
      "epoch 4, loss 0.3950, train acc 0.680, test acc 0.727, time 1688.0 sec\n",
      "epoch 5, loss 0.2807, train acc 0.712, test acc 0.760, time 1700.0 sec\n",
      "epoch 6, loss 0.2106, train acc 0.729, test acc 0.777, time 1706.3 sec\n",
      "epoch 7, loss 0.1678, train acc 0.749, test acc 0.788, time 1656.3 sec\n",
      "epoch 8, loss 0.1369, train acc 0.765, test acc 0.794, time 1625.7 sec\n",
      "epoch 9, loss 0.1142, train acc 0.770, test acc 0.800, time 1613.0 sec\n",
      "epoch 10, loss 0.0975, train acc 0.783, test acc 0.806, time 1608.7 sec\n",
      "epoch 11, loss 0.0842, train acc 0.796, test acc 0.820, time 1601.2 sec\n",
      "epoch 12, loss 0.0742, train acc 0.803, test acc 0.833, time 1606.3 sec\n",
      "epoch 13, loss 0.0661, train acc 0.809, test acc 0.824, time 1595.1 sec\n",
      "epoch 14, loss 0.0581, train acc 0.816, test acc 0.844, time 1586.7 sec\n",
      "epoch 15, loss 0.0537, train acc 0.817, test acc 0.831, time 1590.3 sec\n",
      "epoch 16, loss 0.0469, train acc 0.840, test acc 0.849, time 1592.5 sec\n",
      "epoch 17, loss 0.0430, train acc 0.844, test acc 0.851, time 1589.2 sec\n",
      "epoch 18, loss 0.0411, train acc 0.844, test acc 0.849, time 1584.2 sec\n",
      "epoch 19, loss 0.0382, train acc 0.849, test acc 0.850, time 1594.4 sec\n",
      "epoch 20, loss 0.0366, train acc 0.845, test acc 0.845, time 1587.8 sec\n",
      "epoch 21, loss 0.0348, train acc 0.846, test acc 0.849, time 1588.1 sec\n",
      "epoch 22, loss 0.0331, train acc 0.851, test acc 0.851, time 1585.3 sec\n",
      "epoch 23, loss 0.0316, train acc 0.843, test acc 0.854, time 1588.3 sec\n",
      "epoch 24, loss 0.0301, train acc 0.846, test acc 0.848, time 1587.7 sec\n",
      "epoch 25, loss 0.0290, train acc 0.844, test acc 0.852, time 1582.6 sec\n",
      "epoch 26, loss 0.0276, train acc 0.846, test acc 0.851, time 1587.5 sec\n",
      "epoch 27, loss 0.0265, train acc 0.849, test acc 0.852, time 1639.1 sec\n",
      "epoch 28, loss 0.0254, train acc 0.850, test acc 0.854, time 1641.4 sec\n",
      "epoch 29, loss 0.0248, train acc 0.845, test acc 0.858, time 1715.5 sec\n",
      "epoch 30, loss 0.0238, train acc 0.853, test acc 0.855, time 1718.1 sec\n",
      "epoch 31, loss 0.0229, train acc 0.854, test acc 0.850, time 1699.4 sec\n",
      "epoch 32, loss 0.0221, train acc 0.850, test acc 0.851, time 1711.9 sec\n",
      "epoch 33, loss 0.0221, train acc 0.848, test acc 0.851, time 1690.0 sec\n",
      "epoch 34, loss 0.0207, train acc 0.852, test acc 0.865, time 1680.6 sec\n",
      "epoch 35, loss 0.0203, train acc 0.856, test acc 0.857, time 1663.0 sec\n"
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "milestones = [15,25,30]#多间隔学习率调整训练周期 \n",
    "num_epochs = 35\n",
    "lr = 0.001   \n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 4.1394, train acc 0.261, test acc 0.360, time 1469.8 sec\n",
      "epoch 2, loss 1.9080, train acc 0.383, test acc 0.436, time 1470.6 sec\n",
      "epoch 3, loss 1.1740, train acc 0.458, test acc 0.502, time 1466.4 sec\n",
      "epoch 4, loss 0.8157, train acc 0.534, test acc 0.532, time 1464.4 sec\n",
      "epoch 5, loss 0.6080, train acc 0.559, test acc 0.600, time 1465.6 sec\n",
      "epoch 6, loss 0.4731, train acc 0.601, test acc 0.595, time 1473.4 sec\n",
      "epoch 7, loss 0.3810, train acc 0.623, test acc 0.628, time 1475.3 sec\n",
      "epoch 8, loss 0.3134, train acc 0.647, test acc 0.638, time 1491.6 sec\n",
      "epoch 9, loss 0.2637, train acc 0.663, test acc 0.656, time 1484.5 sec\n",
      "epoch 10, loss 0.2247, train acc 0.684, test acc 0.668, time 1560.5 sec\n",
      "epoch 11, loss 0.1947, train acc 0.697, test acc 0.689, time 1572.0 sec\n",
      "epoch 12, loss 0.1705, train acc 0.709, test acc 0.692, time 1548.6 sec\n",
      "epoch 13, loss 0.1508, train acc 0.718, test acc 0.705, time 1526.7 sec\n",
      "epoch 14, loss 0.1343, train acc 0.725, test acc 0.725, time 1558.4 sec\n",
      "epoch 15, loss 0.1207, train acc 0.735, test acc 0.721, time 1595.4 sec\n",
      "epoch 16, loss 0.1102, train acc 0.744, test acc 0.718, time 1572.7 sec\n",
      "epoch 17, loss 0.1035, train acc 0.745, test acc 0.727, time 1571.8 sec\n",
      "epoch 18, loss 0.0970, train acc 0.751, test acc 0.726, time 1608.5 sec\n",
      "epoch 19, loss 0.0918, train acc 0.748, test acc 0.727, time 1560.3 sec\n",
      "epoch 20, loss 0.0867, train acc 0.747, test acc 0.730, time 1532.9 sec\n",
      "epoch 21, loss 0.0822, train acc 0.754, test acc 0.725, time 1527.7 sec\n",
      "epoch 22, loss 0.0779, train acc 0.759, test acc 0.732, time 1523.5 sec\n",
      "epoch 23, loss 0.0742, train acc 0.758, test acc 0.735, time 1525.0 sec\n",
      "epoch 24, loss 0.0712, train acc 0.756, test acc 0.729, time 1572.9 sec\n",
      "epoch 25, loss 0.0680, train acc 0.758, test acc 0.733, time 1655.7 sec\n",
      "epoch 26, loss 0.0655, train acc 0.759, test acc 0.733, time 1661.2 sec\n",
      "epoch 27, loss 0.0626, train acc 0.756, test acc 0.732, time 1654.0 sec\n",
      "epoch 28, loss 0.0604, train acc 0.756, test acc 0.733, time 1638.6 sec\n",
      "epoch 29, loss 0.0582, train acc 0.756, test acc 0.733, time 1649.8 sec\n",
      "epoch 30, loss 0.0558, train acc 0.761, test acc 0.735, time 1657.9 sec\n",
      "epoch 31, loss 0.0538, train acc 0.763, test acc 0.737, time 1657.9 sec\n",
      "epoch 32, loss 0.0521, train acc 0.761, test acc 0.731, time 1605.4 sec\n",
      "epoch 33, loss 0.0505, train acc 0.759, test acc 0.734, time 1526.3 sec\n",
      "epoch 34, loss 0.0491, train acc 0.763, test acc 0.735, time 1525.7 sec\n",
      "epoch 35, loss 0.0477, train acc 0.760, test acc 0.732, time 1529.3 sec\n",
      "epoch 36, loss 0.0463, train acc 0.759, test acc 0.737, time 1527.5 sec\n",
      "epoch 37, loss 0.0450, train acc 0.763, test acc 0.741, time 1535.3 sec\n",
      "epoch 38, loss 0.0439, train acc 0.759, test acc 0.732, time 1538.6 sec\n",
      "epoch 39, loss 0.0427, train acc 0.761, test acc 0.735, time 1552.4 sec\n",
      "epoch 40, loss 0.0416, train acc 0.764, test acc 0.735, time 1543.2 sec\n",
      "epoch 41, loss 0.0406, train acc 0.757, test acc 0.742, time 1571.3 sec\n",
      "epoch 42, loss 0.0397, train acc 0.756, test acc 0.735, time 1708.8 sec\n",
      "epoch 43, loss 0.0387, train acc 0.764, test acc 0.732, time 1686.3 sec\n",
      "epoch 44, loss 0.0377, train acc 0.766, test acc 0.740, time 1668.6 sec\n",
      "epoch 45, loss 0.0370, train acc 0.763, test acc 0.735, time 1642.9 sec\n",
      "epoch 46, loss 0.0361, train acc 0.759, test acc 0.739, time 1697.6 sec\n",
      "epoch 47, loss 0.0353, train acc 0.768, test acc 0.744, time 1672.4 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(VideoDataset(dataset \u001b[38;5;241m=\u001b[39m dataset,split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),batch_size \u001b[38;5;241m=\u001b[39mbatch_size,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)     \n\u001b[1;32m      8\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(VideoDataset(dataset \u001b[38;5;241m=\u001b[39m dataset,split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m,preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),batch_size \u001b[38;5;241m=\u001b[39m batch_size,num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmilestones\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, train_dataloader, test_dataloader, milestones, batch_size, device, num_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 44\u001b[0m train_l_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     45\u001b[0m train_acc_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (y_hat\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     46\u001b[0m n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "#milestones = [15,30,45]#多间隔学习率调整训练周期 \n",
    "milestones = [30,40,55]#多间隔学习率调整\n",
    "num_epochs = 60\n",
    "lr = 0.001\n",
    "batch_size = 96\n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 4.4688, train acc 0.070, test acc 0.182, time 1684.4 sec\n",
      "epoch 2, loss 2.0519, train acc 0.262, test acc 0.363, time 1662.5 sec\n",
      "epoch 3, loss 1.2599, train acc 0.392, test acc 0.469, time 1502.8 sec\n",
      "epoch 4, loss 0.8715, train acc 0.498, test acc 0.520, time 1511.8 sec\n",
      "epoch 5, loss 0.6463, train acc 0.543, test acc 0.546, time 1516.1 sec\n",
      "epoch 6, loss 0.5014, train acc 0.577, test acc 0.566, time 1511.0 sec\n",
      "epoch 7, loss 0.4019, train acc 0.605, test acc 0.625, time 1511.7 sec\n",
      "epoch 8, loss 0.3303, train acc 0.629, test acc 0.634, time 1515.3 sec\n",
      "epoch 9, loss 0.2772, train acc 0.654, test acc 0.657, time 1512.5 sec\n",
      "epoch 10, loss 0.2354, train acc 0.668, test acc 0.678, time 1517.7 sec\n",
      "epoch 11, loss 0.2033, train acc 0.683, test acc 0.673, time 1520.9 sec\n",
      "epoch 12, loss 0.1774, train acc 0.701, test acc 0.699, time 1527.8 sec\n",
      "epoch 13, loss 0.1560, train acc 0.716, test acc 0.696, time 1536.5 sec\n",
      "epoch 14, loss 0.1391, train acc 0.718, test acc 0.711, time 1542.1 sec\n",
      "epoch 15, loss 0.1249, train acc 0.730, test acc 0.710, time 1579.7 sec\n",
      "epoch 16, loss 0.1122, train acc 0.738, test acc 0.729, time 1540.6 sec\n",
      "epoch 17, loss 0.1020, train acc 0.747, test acc 0.738, time 1562.8 sec\n",
      "epoch 18, loss 0.0930, train acc 0.753, test acc 0.727, time 1554.2 sec\n",
      "epoch 19, loss 0.0855, train acc 0.756, test acc 0.738, time 1554.0 sec\n",
      "epoch 20, loss 0.0785, train acc 0.764, test acc 0.736, time 1558.9 sec\n",
      "epoch 21, loss 0.0726, train acc 0.768, test acc 0.750, time 1558.2 sec\n",
      "epoch 22, loss 0.0673, train acc 0.776, test acc 0.756, time 1558.5 sec\n",
      "epoch 23, loss 0.0626, train acc 0.783, test acc 0.761, time 1549.2 sec\n",
      "epoch 24, loss 0.0585, train acc 0.783, test acc 0.758, time 1555.0 sec\n",
      "epoch 25, loss 0.0552, train acc 0.782, test acc 0.762, time 1536.1 sec\n",
      "epoch 26, loss 0.0517, train acc 0.796, test acc 0.777, time 1511.7 sec\n",
      "epoch 27, loss 0.0485, train acc 0.795, test acc 0.769, time 1497.9 sec\n",
      "epoch 28, loss 0.0458, train acc 0.800, test acc 0.774, time 1488.9 sec\n",
      "epoch 29, loss 0.0430, train acc 0.805, test acc 0.781, time 1492.1 sec\n",
      "epoch 30, loss 0.0410, train acc 0.802, test acc 0.778, time 1488.9 sec\n",
      "epoch 31, loss 0.0387, train acc 0.815, test acc 0.781, time 1499.9 sec\n",
      "epoch 32, loss 0.0368, train acc 0.816, test acc 0.778, time 1492.7 sec\n",
      "epoch 33, loss 0.0350, train acc 0.818, test acc 0.790, time 1497.6 sec\n",
      "epoch 34, loss 0.0334, train acc 0.816, test acc 0.787, time 1492.2 sec\n",
      "epoch 35, loss 0.0321, train acc 0.821, test acc 0.787, time 1492.2 sec\n",
      "epoch 36, loss 0.0308, train acc 0.826, test acc 0.793, time 1490.8 sec\n",
      "epoch 37, loss 0.0296, train acc 0.826, test acc 0.797, time 1495.3 sec\n",
      "epoch 38, loss 0.0289, train acc 0.825, test acc 0.791, time 1490.8 sec\n",
      "epoch 39, loss 0.0280, train acc 0.826, test acc 0.792, time 1496.6 sec\n",
      "epoch 40, loss 0.0273, train acc 0.825, test acc 0.790, time 1512.4 sec\n",
      "epoch 41, loss 0.0266, train acc 0.825, test acc 0.797, time 1537.6 sec\n",
      "epoch 42, loss 0.0260, train acc 0.828, test acc 0.800, time 1554.7 sec\n",
      "epoch 43, loss 0.0253, train acc 0.826, test acc 0.791, time 1634.7 sec\n",
      "epoch 44, loss 0.0247, train acc 0.828, test acc 0.789, time 1596.6 sec\n",
      "epoch 45, loss 0.0240, train acc 0.829, test acc 0.792, time 1600.4 sec\n",
      "epoch 46, loss 0.0235, train acc 0.826, test acc 0.789, time 1548.1 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(VideoDataset(dataset \u001b[38;5;241m=\u001b[39m dataset,split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),batch_size \u001b[38;5;241m=\u001b[39mbatch_size,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)     \n\u001b[1;32m      9\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(VideoDataset(dataset \u001b[38;5;241m=\u001b[39m dataset,split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m,preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),batch_size \u001b[38;5;241m=\u001b[39m batch_size,num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmilestones\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, train_dataloader, test_dataloader, milestones, batch_size, device, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m X \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m net(X)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "#milestones = [15,30,45]#多间隔学习率调整训练周期 \n",
    "#milestones = [35,45,55]#多间隔学习率调整\n",
    "milestones = [55,65,70]\n",
    "num_epochs = 75\n",
    "lr = 0.001\n",
    "batch_size = 96\n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 4.2396, train acc 0.196, test acc 0.293, time 1554.6 sec\n",
      "epoch 2, loss 1.9529, train acc 0.347, test acc 0.413, time 1553.1 sec\n",
      "epoch 3, loss 1.2010, train acc 0.434, test acc 0.487, time 1552.9 sec\n",
      "epoch 4, loss 0.8332, train acc 0.511, test acc 0.535, time 1548.1 sec\n",
      "epoch 5, loss 0.6196, train acc 0.553, test acc 0.578, time 1549.1 sec\n",
      "epoch 6, loss 0.4825, train acc 0.586, test acc 0.611, time 1551.4 sec\n",
      "epoch 7, loss 0.3877, train acc 0.622, test acc 0.625, time 1550.2 sec\n",
      "epoch 8, loss 0.3188, train acc 0.640, test acc 0.649, time 1556.3 sec\n",
      "epoch 9, loss 0.2672, train acc 0.664, test acc 0.650, time 1549.6 sec\n",
      "epoch 10, loss 0.2279, train acc 0.684, test acc 0.675, time 1547.5 sec\n",
      "epoch 11, loss 0.1964, train acc 0.699, test acc 0.686, time 1544.6 sec\n",
      "epoch 12, loss 0.1722, train acc 0.707, test acc 0.702, time 1548.3 sec\n",
      "epoch 13, loss 0.1525, train acc 0.714, test acc 0.720, time 1543.2 sec\n",
      "epoch 14, loss 0.1356, train acc 0.727, test acc 0.720, time 1538.7 sec\n",
      "epoch 15, loss 0.1219, train acc 0.735, test acc 0.718, time 1540.4 sec\n",
      "epoch 16, loss 0.1100, train acc 0.742, test acc 0.726, time 1537.4 sec\n",
      "epoch 17, loss 0.0998, train acc 0.752, test acc 0.734, time 1537.5 sec\n",
      "epoch 18, loss 0.0911, train acc 0.758, test acc 0.745, time 1545.1 sec\n",
      "epoch 19, loss 0.0839, train acc 0.761, test acc 0.749, time 1541.0 sec\n",
      "epoch 20, loss 0.0774, train acc 0.766, test acc 0.748, time 1533.2 sec\n",
      "epoch 21, loss 0.0717, train acc 0.772, test acc 0.752, time 1547.9 sec\n",
      "epoch 22, loss 0.0662, train acc 0.783, test acc 0.749, time 1548.8 sec\n",
      "epoch 23, loss 0.0617, train acc 0.782, test acc 0.757, time 1553.3 sec\n",
      "epoch 24, loss 0.0579, train acc 0.788, test acc 0.764, time 1561.4 sec\n",
      "epoch 25, loss 0.0543, train acc 0.787, test acc 0.773, time 1555.3 sec\n",
      "epoch 26, loss 0.0507, train acc 0.798, test acc 0.767, time 1560.0 sec\n",
      "epoch 27, loss 0.0477, train acc 0.802, test acc 0.767, time 1564.0 sec\n",
      "epoch 28, loss 0.0450, train acc 0.805, test acc 0.771, time 1573.6 sec\n",
      "epoch 29, loss 0.0426, train acc 0.806, test acc 0.779, time 1624.3 sec\n",
      "epoch 30, loss 0.0405, train acc 0.808, test acc 0.787, time 1619.6 sec\n",
      "epoch 31, loss 0.0384, train acc 0.810, test acc 0.787, time 1587.7 sec\n",
      "epoch 32, loss 0.0364, train acc 0.815, test acc 0.787, time 1586.3 sec\n",
      "epoch 33, loss 0.0348, train acc 0.817, test acc 0.791, time 1629.9 sec\n",
      "epoch 34, loss 0.0329, train acc 0.822, test acc 0.796, time 1664.8 sec\n",
      "epoch 35, loss 0.0316, train acc 0.822, test acc 0.794, time 1639.6 sec\n",
      "epoch 36, loss 0.0303, train acc 0.822, test acc 0.795, time 1664.2 sec\n",
      "epoch 37, loss 0.0289, train acc 0.826, test acc 0.795, time 1669.3 sec\n",
      "epoch 38, loss 0.0278, train acc 0.829, test acc 0.796, time 1663.2 sec\n",
      "epoch 39, loss 0.0267, train acc 0.833, test acc 0.795, time 1656.6 sec\n",
      "epoch 40, loss 0.0255, train acc 0.830, test acc 0.806, time 1653.5 sec\n",
      "epoch 41, loss 0.0245, train acc 0.837, test acc 0.810, time 1665.4 sec\n",
      "epoch 42, loss 0.0236, train acc 0.835, test acc 0.809, time 1661.5 sec\n",
      "epoch 43, loss 0.0228, train acc 0.842, test acc 0.804, time 1661.3 sec\n",
      "epoch 44, loss 0.0219, train acc 0.841, test acc 0.803, time 1633.5 sec\n",
      "epoch 45, loss 0.0213, train acc 0.842, test acc 0.802, time 1596.8 sec\n",
      "epoch 46, loss 0.0205, train acc 0.846, test acc 0.814, time 1593.9 sec\n",
      "epoch 47, loss 0.0197, train acc 0.847, test acc 0.818, time 1607.3 sec\n",
      "epoch 48, loss 0.0192, train acc 0.845, test acc 0.814, time 1612.7 sec\n",
      "epoch 49, loss 0.0185, train acc 0.850, test acc 0.819, time 1585.6 sec\n",
      "epoch 50, loss 0.0179, train acc 0.849, test acc 0.822, time 1617.6 sec\n",
      "epoch 51, loss 0.0174, train acc 0.852, test acc 0.822, time 1599.8 sec\n",
      "epoch 52, loss 0.0167, train acc 0.856, test acc 0.826, time 1558.9 sec\n",
      "epoch 53, loss 0.0163, train acc 0.857, test acc 0.820, time 1558.8 sec\n",
      "epoch 54, loss 0.0158, train acc 0.855, test acc 0.826, time 1558.7 sec\n",
      "epoch 55, loss 0.0153, train acc 0.862, test acc 0.826, time 1553.3 sec\n",
      "epoch 56, loss 0.0149, train acc 0.859, test acc 0.828, time 1575.7 sec\n",
      "epoch 57, loss 0.0146, train acc 0.860, test acc 0.823, time 1556.7 sec\n",
      "epoch 58, loss 0.0140, train acc 0.865, test acc 0.826, time 1550.9 sec\n",
      "epoch 59, loss 0.0139, train acc 0.861, test acc 0.822, time 1547.1 sec\n",
      "epoch 60, loss 0.0133, train acc 0.867, test acc 0.833, time 1547.7 sec\n",
      "epoch 61, loss 0.0132, train acc 0.864, test acc 0.826, time 1549.2 sec\n",
      "epoch 62, loss 0.0128, train acc 0.864, test acc 0.825, time 1546.3 sec\n",
      "epoch 63, loss 0.0126, train acc 0.867, test acc 0.833, time 1550.6 sec\n",
      "epoch 64, loss 0.0124, train acc 0.866, test acc 0.835, time 1541.4 sec\n",
      "epoch 65, loss 0.0122, train acc 0.869, test acc 0.830, time 1537.0 sec\n",
      "epoch 66, loss 0.0119, train acc 0.871, test acc 0.829, time 1548.0 sec\n",
      "epoch 67, loss 0.0118, train acc 0.870, test acc 0.827, time 1544.0 sec\n",
      "epoch 68, loss 0.0116, train acc 0.869, test acc 0.833, time 1543.8 sec\n",
      "epoch 69, loss 0.0115, train acc 0.863, test acc 0.830, time 1544.9 sec\n",
      "epoch 70, loss 0.0112, train acc 0.867, test acc 0.831, time 1548.5 sec\n",
      "epoch 71, loss 0.0110, train acc 0.870, test acc 0.832, time 1540.6 sec\n",
      "epoch 72, loss 0.0108, train acc 0.870, test acc 0.830, time 1542.6 sec\n",
      "epoch 73, loss 0.0107, train acc 0.868, test acc 0.832, time 1547.9 sec\n",
      "epoch 74, loss 0.0106, train acc 0.870, test acc 0.828, time 1543.8 sec\n",
      "epoch 75, loss 0.0105, train acc 0.869, test acc 0.834, time 1543.0 sec\n",
      "epoch 76, loss 0.0104, train acc 0.865, test acc 0.834, time 1549.8 sec\n",
      "epoch 77, loss 0.0102, train acc 0.867, test acc 0.825, time 1543.5 sec\n",
      "epoch 78, loss 0.0100, train acc 0.869, test acc 0.830, time 1594.6 sec\n",
      "epoch 79, loss 0.0099, train acc 0.870, test acc 0.831, time 1605.3 sec\n",
      "epoch 80, loss 0.0097, train acc 0.872, test acc 0.832, time 1611.3 sec\n",
      "epoch 81, loss 0.0096, train acc 0.873, test acc 0.835, time 1613.8 sec\n",
      "epoch 82, loss 0.0095, train acc 0.872, test acc 0.832, time 1609.9 sec\n",
      "epoch 83, loss 0.0095, train acc 0.870, test acc 0.831, time 1607.1 sec\n",
      "epoch 84, loss 0.0093, train acc 0.868, test acc 0.836, time 1602.8 sec\n",
      "epoch 85, loss 0.0091, train acc 0.867, test acc 0.830, time 1603.5 sec\n",
      "epoch 86, loss 0.0091, train acc 0.868, test acc 0.833, time 1602.4 sec\n",
      "epoch 87, loss 0.0089, train acc 0.869, test acc 0.834, time 1618.2 sec\n",
      "epoch 88, loss 0.0088, train acc 0.867, test acc 0.830, time 1609.6 sec\n",
      "epoch 89, loss 0.0087, train acc 0.869, test acc 0.832, time 1595.1 sec\n",
      "epoch 90, loss 0.0086, train acc 0.869, test acc 0.837, time 1615.4 sec\n",
      "epoch 91, loss 0.0085, train acc 0.873, test acc 0.836, time 1616.4 sec\n",
      "epoch 92, loss 0.0084, train acc 0.868, test acc 0.831, time 1618.3 sec\n",
      "epoch 93, loss 0.0083, train acc 0.870, test acc 0.835, time 1607.8 sec\n",
      "epoch 94, loss 0.0083, train acc 0.867, test acc 0.830, time 1603.9 sec\n",
      "epoch 95, loss 0.0081, train acc 0.871, test acc 0.834, time 1616.3 sec\n",
      "epoch 96, loss 0.0081, train acc 0.870, test acc 0.836, time 1622.7 sec\n",
      "epoch 97, loss 0.0080, train acc 0.867, test acc 0.830, time 1621.9 sec\n",
      "epoch 98, loss 0.0079, train acc 0.872, test acc 0.836, time 1597.9 sec\n",
      "epoch 99, loss 0.0077, train acc 0.874, test acc 0.831, time 1592.7 sec\n",
      "epoch 100, loss 0.0078, train acc 0.869, test acc 0.835, time 1574.4 sec\n"
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "#milestones = [15,30,45]#多间隔学习率调整训练周期 \n",
    "#milestones = [35,45,55]#多间隔学习率调整\n",
    "milestones = [60,85,95]\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 96 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.9367, train acc 0.213, test acc 0.442, time 1708.0 sec\n",
      "epoch 2, loss 1.4134, train acc 0.509, test acc 0.610, time 1746.2 sec\n",
      "epoch 3, loss 0.7372, train acc 0.622, test acc 0.670, time 1729.8 sec\n",
      "epoch 4, loss 0.4598, train acc 0.685, test acc 0.715, time 1749.8 sec\n",
      "epoch 5, loss 0.3216, train acc 0.716, test acc 0.742, time 1760.4 sec\n",
      "epoch 6, loss 0.2392, train acc 0.741, test acc 0.744, time 1777.4 sec\n",
      "epoch 7, loss 0.1869, train acc 0.759, test acc 0.764, time 1762.8 sec\n",
      "epoch 8, loss 0.1507, train acc 0.769, test acc 0.782, time 1703.3 sec\n",
      "epoch 9, loss 0.1258, train acc 0.786, test acc 0.795, time 1703.0 sec\n",
      "epoch 10, loss 0.1062, train acc 0.801, test acc 0.801, time 1718.3 sec\n",
      "epoch 11, loss 0.0909, train acc 0.809, test acc 0.803, time 1725.3 sec\n",
      "epoch 12, loss 0.0792, train acc 0.817, test acc 0.809, time 1721.6 sec\n",
      "epoch 13, loss 0.0707, train acc 0.821, test acc 0.822, time 1722.2 sec\n",
      "epoch 14, loss 0.0628, train acc 0.830, test acc 0.819, time 1706.4 sec\n",
      "epoch 15, loss 0.0566, train acc 0.834, test acc 0.827, time 1696.8 sec\n",
      "epoch 16, loss 0.0510, train acc 0.841, test acc 0.832, time 1698.7 sec\n",
      "epoch 17, loss 0.0461, train acc 0.848, test acc 0.841, time 1701.6 sec\n",
      "epoch 18, loss 0.0424, train acc 0.845, test acc 0.836, time 1710.4 sec\n",
      "epoch 19, loss 0.0391, train acc 0.851, test acc 0.847, time 1705.7 sec\n",
      "epoch 20, loss 0.0359, train acc 0.855, test acc 0.838, time 1710.6 sec\n",
      "epoch 21, loss 0.0334, train acc 0.858, test acc 0.854, time 1709.8 sec\n",
      "epoch 22, loss 0.0311, train acc 0.863, test acc 0.848, time 1722.0 sec\n",
      "epoch 23, loss 0.0292, train acc 0.866, test acc 0.850, time 1694.8 sec\n",
      "epoch 24, loss 0.0275, train acc 0.870, test acc 0.859, time 1690.6 sec\n",
      "epoch 25, loss 0.0252, train acc 0.875, test acc 0.861, time 1695.7 sec\n",
      "epoch 26, loss 0.0239, train acc 0.877, test acc 0.870, time 1693.6 sec\n",
      "epoch 27, loss 0.0229, train acc 0.878, test acc 0.857, time 1702.5 sec\n",
      "epoch 28, loss 0.0212, train acc 0.883, test acc 0.866, time 1716.9 sec\n",
      "epoch 29, loss 0.0206, train acc 0.880, test acc 0.871, time 1707.7 sec\n",
      "epoch 30, loss 0.0192, train acc 0.886, test acc 0.868, time 1703.8 sec\n",
      "epoch 31, loss 0.0182, train acc 0.890, test acc 0.870, time 1715.1 sec\n",
      "epoch 32, loss 0.0173, train acc 0.889, test acc 0.871, time 1714.4 sec\n",
      "epoch 33, loss 0.0165, train acc 0.894, test acc 0.864, time 1713.1 sec\n",
      "epoch 34, loss 0.0159, train acc 0.890, test acc 0.879, time 1713.4 sec\n",
      "epoch 35, loss 0.0152, train acc 0.895, test acc 0.879, time 1710.1 sec\n",
      "epoch 36, loss 0.0145, train acc 0.898, test acc 0.876, time 1713.4 sec\n",
      "epoch 37, loss 0.0139, train acc 0.902, test acc 0.876, time 1712.9 sec\n",
      "epoch 38, loss 0.0134, train acc 0.899, test acc 0.879, time 1712.9 sec\n",
      "epoch 39, loss 0.0131, train acc 0.897, test acc 0.891, time 1716.0 sec\n",
      "epoch 40, loss 0.0123, train acc 0.902, test acc 0.882, time 1709.9 sec\n",
      "epoch 41, loss 0.0120, train acc 0.903, test acc 0.885, time 1694.8 sec\n",
      "epoch 42, loss 0.0113, train acc 0.908, test acc 0.891, time 1680.0 sec\n",
      "epoch 43, loss 0.0112, train acc 0.907, test acc 0.883, time 1680.3 sec\n",
      "epoch 44, loss 0.0107, train acc 0.908, test acc 0.890, time 1683.8 sec\n",
      "epoch 45, loss 0.0104, train acc 0.905, test acc 0.885, time 1688.9 sec\n",
      "epoch 46, loss 0.0101, train acc 0.908, test acc 0.890, time 1698.7 sec\n",
      "epoch 47, loss 0.0097, train acc 0.910, test acc 0.897, time 1689.6 sec\n",
      "epoch 48, loss 0.0096, train acc 0.906, test acc 0.895, time 1688.4 sec\n",
      "epoch 49, loss 0.0090, train acc 0.915, test acc 0.895, time 1679.2 sec\n",
      "epoch 50, loss 0.0087, train acc 0.916, test acc 0.892, time 1680.9 sec\n",
      "epoch 51, loss 0.0085, train acc 0.917, test acc 0.897, time 1681.9 sec\n",
      "epoch 52, loss 0.0083, train acc 0.916, test acc 0.899, time 1678.6 sec\n",
      "epoch 53, loss 0.0082, train acc 0.916, test acc 0.902, time 1683.9 sec\n",
      "epoch 54, loss 0.0080, train acc 0.916, test acc 0.900, time 1679.2 sec\n",
      "epoch 55, loss 0.0077, train acc 0.918, test acc 0.900, time 1679.4 sec\n",
      "epoch 56, loss 0.0076, train acc 0.917, test acc 0.899, time 1680.3 sec\n",
      "epoch 57, loss 0.0074, train acc 0.918, test acc 0.898, time 1676.6 sec\n",
      "epoch 58, loss 0.0071, train acc 0.922, test acc 0.903, time 1680.5 sec\n",
      "epoch 59, loss 0.0068, train acc 0.922, test acc 0.905, time 1673.1 sec\n",
      "epoch 60, loss 0.0068, train acc 0.922, test acc 0.903, time 1675.8 sec\n",
      "epoch 61, loss 0.0065, train acc 0.927, test acc 0.902, time 1671.7 sec\n",
      "epoch 62, loss 0.0062, train acc 0.927, test acc 0.908, time 1668.2 sec\n",
      "epoch 63, loss 0.0061, train acc 0.929, test acc 0.906, time 1677.8 sec\n",
      "epoch 64, loss 0.0060, train acc 0.928, test acc 0.903, time 1680.5 sec\n",
      "epoch 65, loss 0.0059, train acc 0.930, test acc 0.908, time 1676.3 sec\n",
      "epoch 66, loss 0.0059, train acc 0.930, test acc 0.903, time 1672.9 sec\n",
      "epoch 67, loss 0.0058, train acc 0.929, test acc 0.906, time 1680.6 sec\n",
      "epoch 68, loss 0.0056, train acc 0.928, test acc 0.910, time 1675.4 sec\n",
      "epoch 69, loss 0.0057, train acc 0.924, test acc 0.910, time 1673.7 sec\n",
      "epoch 70, loss 0.0054, train acc 0.930, test acc 0.904, time 1671.4 sec\n",
      "epoch 71, loss 0.0054, train acc 0.928, test acc 0.905, time 1680.5 sec\n",
      "epoch 72, loss 0.0055, train acc 0.924, test acc 0.900, time 1674.5 sec\n",
      "epoch 73, loss 0.0053, train acc 0.929, test acc 0.907, time 1674.6 sec\n",
      "epoch 74, loss 0.0053, train acc 0.924, test acc 0.899, time 1677.5 sec\n",
      "epoch 75, loss 0.0051, train acc 0.933, test acc 0.910, time 1674.5 sec\n",
      "epoch 76, loss 0.0051, train acc 0.932, test acc 0.910, time 1679.6 sec\n",
      "epoch 77, loss 0.0050, train acc 0.928, test acc 0.912, time 1686.7 sec\n",
      "epoch 78, loss 0.0049, train acc 0.930, test acc 0.908, time 1679.2 sec\n",
      "epoch 79, loss 0.0049, train acc 0.929, test acc 0.906, time 1676.3 sec\n",
      "epoch 80, loss 0.0047, train acc 0.929, test acc 0.901, time 1674.1 sec\n",
      "epoch 81, loss 0.0046, train acc 0.932, test acc 0.903, time 1675.1 sec\n",
      "epoch 82, loss 0.0046, train acc 0.932, test acc 0.903, time 1674.4 sec\n",
      "epoch 83, loss 0.0046, train acc 0.929, test acc 0.903, time 1669.9 sec\n",
      "epoch 84, loss 0.0046, train acc 0.926, test acc 0.907, time 1670.6 sec\n",
      "epoch 85, loss 0.0045, train acc 0.929, test acc 0.903, time 1675.8 sec\n",
      "epoch 86, loss 0.0045, train acc 0.927, test acc 0.901, time 1675.8 sec\n",
      "epoch 87, loss 0.0044, train acc 0.931, test acc 0.905, time 1680.8 sec\n",
      "epoch 88, loss 0.0044, train acc 0.927, test acc 0.904, time 1671.9 sec\n",
      "epoch 89, loss 0.0043, train acc 0.926, test acc 0.908, time 1672.5 sec\n",
      "epoch 90, loss 0.0043, train acc 0.928, test acc 0.904, time 1675.5 sec\n",
      "epoch 91, loss 0.0042, train acc 0.930, test acc 0.910, time 1675.4 sec\n",
      "epoch 92, loss 0.0042, train acc 0.927, test acc 0.912, time 1679.4 sec\n",
      "epoch 93, loss 0.0040, train acc 0.933, test acc 0.904, time 1677.0 sec\n",
      "epoch 94, loss 0.0040, train acc 0.933, test acc 0.904, time 1676.4 sec\n",
      "epoch 95, loss 0.0039, train acc 0.932, test acc 0.909, time 1672.2 sec\n",
      "epoch 96, loss 0.0040, train acc 0.930, test acc 0.904, time 1680.9 sec\n",
      "epoch 97, loss 0.0038, train acc 0.934, test acc 0.905, time 1684.2 sec\n",
      "epoch 98, loss 0.0038, train acc 0.932, test acc 0.905, time 1745.5 sec\n",
      "epoch 99, loss 0.0038, train acc 0.932, test acc 0.904, time 1870.0 sec\n",
      "epoch 100, loss 0.0038, train acc 0.928, test acc 0.907, time 1888.7 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlc_block添加到res2块中的模型\n",
    "save_path = 'nlcnet_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 2.5865, train acc 0.559, test acc 0.635, time 1916.1 sec\n",
      "epoch 2, loss 1.0438, train acc 0.634, test acc 0.689, time 1820.9 sec\n",
      "epoch 3, loss 0.5884, train acc 0.688, test acc 0.720, time 1827.5 sec\n",
      "epoch 4, loss 0.3872, train acc 0.723, test acc 0.737, time 1833.4 sec\n",
      "epoch 5, loss 0.2778, train acc 0.746, test acc 0.757, time 1836.1 sec\n",
      "epoch 6, loss 0.2131, train acc 0.762, test acc 0.769, time 1804.8 sec\n",
      "epoch 7, loss 0.1688, train acc 0.777, test acc 0.784, time 1805.9 sec\n",
      "epoch 8, loss 0.1381, train acc 0.788, test acc 0.779, time 1815.2 sec\n",
      "epoch 9, loss 0.1158, train acc 0.800, test acc 0.796, time 1812.2 sec\n",
      "epoch 10, loss 0.0990, train acc 0.812, test acc 0.799, time 1841.1 sec\n",
      "epoch 11, loss 0.0860, train acc 0.813, test acc 0.818, time 1875.2 sec\n",
      "epoch 12, loss 0.0752, train acc 0.822, test acc 0.817, time 1860.5 sec\n",
      "epoch 13, loss 0.0668, train acc 0.831, test acc 0.827, time 1881.6 sec\n",
      "epoch 14, loss 0.0588, train acc 0.838, test acc 0.825, time 1876.6 sec\n",
      "epoch 15, loss 0.0536, train acc 0.840, test acc 0.832, time 1842.1 sec\n",
      "epoch 16, loss 0.0485, train acc 0.849, test acc 0.830, time 1843.9 sec\n",
      "epoch 17, loss 0.0446, train acc 0.848, test acc 0.836, time 1838.2 sec\n",
      "epoch 18, loss 0.0408, train acc 0.853, test acc 0.839, time 1854.7 sec\n",
      "epoch 19, loss 0.0378, train acc 0.855, test acc 0.848, time 1798.6 sec\n",
      "epoch 20, loss 0.0347, train acc 0.862, test acc 0.852, time 1797.9 sec\n",
      "epoch 21, loss 0.0320, train acc 0.868, test acc 0.852, time 1819.2 sec\n",
      "epoch 22, loss 0.0301, train acc 0.865, test acc 0.850, time 1796.1 sec\n",
      "epoch 23, loss 0.0284, train acc 0.871, test acc 0.862, time 1810.3 sec\n",
      "epoch 24, loss 0.0266, train acc 0.870, test acc 0.851, time 1810.5 sec\n",
      "epoch 25, loss 0.0243, train acc 0.874, test acc 0.866, time 1805.5 sec\n",
      "epoch 26, loss 0.0238, train acc 0.875, test acc 0.868, time 1764.5 sec\n",
      "epoch 27, loss 0.0219, train acc 0.882, test acc 0.861, time 1764.8 sec\n",
      "epoch 28, loss 0.0210, train acc 0.883, test acc 0.871, time 1767.5 sec\n",
      "epoch 29, loss 0.0198, train acc 0.884, test acc 0.866, time 1764.5 sec\n",
      "epoch 30, loss 0.0185, train acc 0.892, test acc 0.872, time 1769.5 sec\n",
      "epoch 31, loss 0.0174, train acc 0.894, test acc 0.876, time 1757.4 sec\n",
      "epoch 32, loss 0.0167, train acc 0.893, test acc 0.880, time 1752.3 sec\n",
      "epoch 33, loss 0.0162, train acc 0.892, test acc 0.879, time 1755.0 sec\n",
      "epoch 34, loss 0.0156, train acc 0.894, test acc 0.882, time 1732.4 sec\n",
      "epoch 35, loss 0.0148, train acc 0.896, test acc 0.882, time 1727.8 sec\n",
      "epoch 36, loss 0.0142, train acc 0.898, test acc 0.880, time 1729.8 sec\n",
      "epoch 37, loss 0.0136, train acc 0.899, test acc 0.882, time 1731.1 sec\n",
      "epoch 38, loss 0.0130, train acc 0.903, test acc 0.884, time 1747.9 sec\n",
      "epoch 39, loss 0.0125, train acc 0.902, test acc 0.891, time 1764.0 sec\n",
      "epoch 40, loss 0.0123, train acc 0.900, test acc 0.887, time 1820.9 sec\n",
      "epoch 41, loss 0.0115, train acc 0.909, test acc 0.889, time 1821.4 sec\n",
      "epoch 42, loss 0.0112, train acc 0.907, test acc 0.886, time 1837.0 sec\n",
      "epoch 43, loss 0.0108, train acc 0.908, test acc 0.890, time 1796.7 sec\n",
      "epoch 44, loss 0.0105, train acc 0.910, test acc 0.889, time 1770.0 sec\n",
      "epoch 45, loss 0.0102, train acc 0.910, test acc 0.893, time 1779.2 sec\n",
      "epoch 46, loss 0.0099, train acc 0.910, test acc 0.896, time 1746.1 sec\n",
      "epoch 47, loss 0.0097, train acc 0.909, test acc 0.889, time 1746.8 sec\n",
      "epoch 48, loss 0.0094, train acc 0.912, test acc 0.885, time 1738.9 sec\n",
      "epoch 49, loss 0.0090, train acc 0.914, test acc 0.889, time 1734.2 sec\n",
      "epoch 50, loss 0.0086, train acc 0.914, test acc 0.890, time 1768.1 sec\n",
      "epoch 51, loss 0.0084, train acc 0.915, test acc 0.889, time 1829.6 sec\n",
      "epoch 52, loss 0.0083, train acc 0.917, test acc 0.895, time 1796.6 sec\n",
      "epoch 53, loss 0.0077, train acc 0.923, test acc 0.900, time 1878.5 sec\n",
      "epoch 54, loss 0.0077, train acc 0.914, test acc 0.899, time 1950.9 sec\n",
      "epoch 55, loss 0.0076, train acc 0.920, test acc 0.900, time 1953.8 sec\n",
      "epoch 56, loss 0.0074, train acc 0.920, test acc 0.893, time 1977.6 sec\n",
      "epoch 57, loss 0.0070, train acc 0.925, test acc 0.900, time 2011.3 sec\n",
      "epoch 58, loss 0.0069, train acc 0.924, test acc 0.907, time 1991.0 sec\n",
      "epoch 59, loss 0.0068, train acc 0.923, test acc 0.901, time 1861.5 sec\n",
      "epoch 60, loss 0.0065, train acc 0.925, test acc 0.906, time 1865.2 sec\n",
      "epoch 61, loss 0.0063, train acc 0.927, test acc 0.898, time 1874.9 sec\n",
      "epoch 62, loss 0.0061, train acc 0.932, test acc 0.910, time 1847.7 sec\n",
      "epoch 63, loss 0.0060, train acc 0.930, test acc 0.913, time 1839.7 sec\n",
      "epoch 64, loss 0.0059, train acc 0.929, test acc 0.901, time 1918.1 sec\n",
      "epoch 65, loss 0.0057, train acc 0.931, test acc 0.905, time 1932.7 sec\n",
      "epoch 66, loss 0.0058, train acc 0.929, test acc 0.907, time 1939.5 sec\n",
      "epoch 67, loss 0.0058, train acc 0.928, test acc 0.907, time 1939.0 sec\n",
      "epoch 68, loss 0.0056, train acc 0.930, test acc 0.906, time 1946.6 sec\n",
      "epoch 69, loss 0.0056, train acc 0.926, test acc 0.900, time 1872.0 sec\n",
      "epoch 70, loss 0.0054, train acc 0.934, test acc 0.901, time 1799.1 sec\n",
      "epoch 71, loss 0.0054, train acc 0.927, test acc 0.908, time 1758.6 sec\n",
      "epoch 72, loss 0.0052, train acc 0.928, test acc 0.906, time 1756.0 sec\n",
      "epoch 73, loss 0.0052, train acc 0.933, test acc 0.904, time 1756.3 sec\n",
      "epoch 74, loss 0.0050, train acc 0.932, test acc 0.898, time 1753.8 sec\n",
      "epoch 75, loss 0.0050, train acc 0.930, test acc 0.903, time 1755.8 sec\n",
      "epoch 76, loss 0.0050, train acc 0.930, test acc 0.905, time 1745.0 sec\n",
      "epoch 77, loss 0.0049, train acc 0.927, test acc 0.903, time 1745.3 sec\n",
      "epoch 78, loss 0.0048, train acc 0.928, test acc 0.904, time 1744.3 sec\n",
      "epoch 79, loss 0.0047, train acc 0.931, test acc 0.909, time 1747.8 sec\n",
      "epoch 80, loss 0.0047, train acc 0.931, test acc 0.912, time 1748.7 sec\n",
      "epoch 81, loss 0.0047, train acc 0.928, test acc 0.903, time 1741.3 sec\n",
      "epoch 82, loss 0.0045, train acc 0.930, test acc 0.901, time 1742.4 sec\n",
      "epoch 83, loss 0.0045, train acc 0.931, test acc 0.912, time 1744.1 sec\n",
      "epoch 84, loss 0.0045, train acc 0.932, test acc 0.906, time 1738.6 sec\n",
      "epoch 85, loss 0.0044, train acc 0.931, test acc 0.910, time 1721.8 sec\n",
      "epoch 86, loss 0.0044, train acc 0.927, test acc 0.907, time 1725.7 sec\n",
      "epoch 87, loss 0.0043, train acc 0.933, test acc 0.904, time 1725.9 sec\n",
      "epoch 88, loss 0.0043, train acc 0.930, test acc 0.903, time 1723.8 sec\n",
      "epoch 89, loss 0.0041, train acc 0.933, test acc 0.911, time 1729.2 sec\n",
      "epoch 90, loss 0.0042, train acc 0.929, test acc 0.904, time 1725.0 sec\n",
      "epoch 91, loss 0.0042, train acc 0.928, test acc 0.906, time 1722.8 sec\n",
      "epoch 92, loss 0.0041, train acc 0.931, test acc 0.908, time 1732.6 sec\n",
      "epoch 93, loss 0.0039, train acc 0.937, test acc 0.911, time 1727.8 sec\n",
      "epoch 94, loss 0.0040, train acc 0.933, test acc 0.901, time 1740.2 sec\n",
      "epoch 95, loss 0.0040, train acc 0.930, test acc 0.907, time 1778.2 sec\n",
      "epoch 96, loss 0.0039, train acc 0.931, test acc 0.906, time 1763.7 sec\n",
      "epoch 97, loss 0.0038, train acc 0.931, test acc 0.908, time 1765.8 sec\n",
      "epoch 98, loss 0.0038, train acc 0.930, test acc 0.909, time 1766.4 sec\n",
      "epoch 99, loss 0.0037, train acc 0.931, test acc 0.903, time 1764.8 sec\n",
      "epoch 100, loss 0.0038, train acc 0.929, test acc 0.901, time 1801.8 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlc_block添加到res1块中的模型\n",
    "save_path = 'nlcnet1_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet1,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.9455, train acc 0.205, test acc 0.417, time 1630.7 sec\n",
      "epoch 2, loss 1.4197, train acc 0.498, test acc 0.608, time 1628.4 sec\n",
      "epoch 3, loss 0.7387, train acc 0.626, test acc 0.666, time 1625.8 sec\n",
      "epoch 4, loss 0.4612, train acc 0.681, test acc 0.710, time 1633.0 sec\n",
      "epoch 5, loss 0.3221, train acc 0.712, test acc 0.731, time 1633.6 sec\n",
      "epoch 6, loss 0.2404, train acc 0.738, test acc 0.759, time 1617.7 sec\n",
      "epoch 7, loss 0.1875, train acc 0.758, test acc 0.769, time 1614.9 sec\n",
      "epoch 8, loss 0.1516, train acc 0.772, test acc 0.779, time 1614.1 sec\n",
      "epoch 9, loss 0.1256, train acc 0.784, test acc 0.782, time 1603.8 sec\n",
      "epoch 10, loss 0.1068, train acc 0.796, test acc 0.790, time 1598.5 sec\n",
      "epoch 11, loss 0.0924, train acc 0.802, test acc 0.804, time 1619.8 sec\n",
      "epoch 12, loss 0.0796, train acc 0.815, test acc 0.812, time 1612.9 sec\n",
      "epoch 13, loss 0.0707, train acc 0.820, test acc 0.812, time 1597.4 sec\n",
      "epoch 14, loss 0.0633, train acc 0.823, test acc 0.817, time 1602.4 sec\n",
      "epoch 15, loss 0.0560, train acc 0.831, test acc 0.822, time 1596.6 sec\n",
      "epoch 16, loss 0.0512, train acc 0.831, test acc 0.832, time 1590.5 sec\n",
      "epoch 17, loss 0.0457, train acc 0.847, test acc 0.836, time 1596.1 sec\n",
      "epoch 18, loss 0.0426, train acc 0.848, test acc 0.848, time 1593.3 sec\n",
      "epoch 19, loss 0.0391, train acc 0.852, test acc 0.834, time 1592.0 sec\n",
      "epoch 20, loss 0.0361, train acc 0.857, test acc 0.845, time 1592.0 sec\n",
      "epoch 21, loss 0.0336, train acc 0.855, test acc 0.852, time 1597.7 sec\n",
      "epoch 22, loss 0.0310, train acc 0.863, test acc 0.850, time 1597.9 sec\n",
      "epoch 23, loss 0.0289, train acc 0.867, test acc 0.854, time 1592.9 sec\n",
      "epoch 24, loss 0.0271, train acc 0.868, test acc 0.861, time 1598.2 sec\n",
      "epoch 25, loss 0.0257, train acc 0.871, test acc 0.856, time 1604.1 sec\n",
      "epoch 26, loss 0.0244, train acc 0.874, test acc 0.864, time 1607.6 sec\n",
      "epoch 27, loss 0.0224, train acc 0.880, test acc 0.860, time 1601.7 sec\n",
      "epoch 28, loss 0.0218, train acc 0.878, test acc 0.870, time 1599.5 sec\n",
      "epoch 29, loss 0.0203, train acc 0.878, test acc 0.867, time 1593.9 sec\n",
      "epoch 30, loss 0.0193, train acc 0.884, test acc 0.864, time 1594.9 sec\n",
      "epoch 31, loss 0.0183, train acc 0.888, test acc 0.869, time 1601.7 sec\n",
      "epoch 32, loss 0.0173, train acc 0.890, test acc 0.880, time 1596.6 sec\n",
      "epoch 33, loss 0.0166, train acc 0.889, test acc 0.866, time 1596.7 sec\n",
      "epoch 34, loss 0.0159, train acc 0.893, test acc 0.881, time 1596.3 sec\n",
      "epoch 35, loss 0.0152, train acc 0.892, test acc 0.878, time 1599.7 sec\n",
      "epoch 36, loss 0.0147, train acc 0.893, test acc 0.875, time 1599.3 sec\n",
      "epoch 37, loss 0.0142, train acc 0.895, test acc 0.878, time 1598.1 sec\n",
      "epoch 38, loss 0.0137, train acc 0.896, test acc 0.879, time 1598.6 sec\n",
      "epoch 39, loss 0.0129, train acc 0.900, test acc 0.882, time 1596.4 sec\n",
      "epoch 40, loss 0.0123, train acc 0.903, test acc 0.881, time 1596.2 sec\n",
      "epoch 41, loss 0.0120, train acc 0.901, test acc 0.893, time 1602.2 sec\n",
      "epoch 42, loss 0.0115, train acc 0.902, test acc 0.881, time 1607.7 sec\n",
      "epoch 43, loss 0.0110, train acc 0.904, test acc 0.880, time 1636.8 sec\n",
      "epoch 44, loss 0.0108, train acc 0.905, test acc 0.878, time 1601.2 sec\n",
      "epoch 45, loss 0.0102, train acc 0.908, test acc 0.891, time 1603.4 sec\n",
      "epoch 46, loss 0.0100, train acc 0.909, test acc 0.884, time 1601.9 sec\n",
      "epoch 47, loss 0.0098, train acc 0.912, test acc 0.895, time 1595.4 sec\n",
      "epoch 48, loss 0.0095, train acc 0.913, test acc 0.892, time 1599.8 sec\n",
      "epoch 49, loss 0.0091, train acc 0.916, test acc 0.892, time 1598.5 sec\n",
      "epoch 50, loss 0.0089, train acc 0.910, test acc 0.894, time 1607.6 sec\n",
      "epoch 51, loss 0.0086, train acc 0.914, test acc 0.895, time 1596.6 sec\n",
      "epoch 52, loss 0.0082, train acc 0.914, test acc 0.894, time 1596.4 sec\n",
      "epoch 53, loss 0.0082, train acc 0.912, test acc 0.900, time 1599.8 sec\n",
      "epoch 54, loss 0.0079, train acc 0.918, test acc 0.891, time 1599.4 sec\n",
      "epoch 55, loss 0.0078, train acc 0.915, test acc 0.896, time 1598.8 sec\n",
      "epoch 56, loss 0.0075, train acc 0.919, test acc 0.899, time 1601.9 sec\n",
      "epoch 57, loss 0.0072, train acc 0.919, test acc 0.902, time 1598.8 sec\n",
      "epoch 58, loss 0.0071, train acc 0.916, test acc 0.898, time 1588.0 sec\n",
      "epoch 59, loss 0.0069, train acc 0.915, test acc 0.906, time 1591.1 sec\n",
      "epoch 60, loss 0.0065, train acc 0.929, test acc 0.901, time 1593.0 sec\n",
      "epoch 61, loss 0.0064, train acc 0.927, test acc 0.904, time 1596.2 sec\n",
      "epoch 62, loss 0.0063, train acc 0.926, test acc 0.905, time 1587.6 sec\n",
      "epoch 63, loss 0.0063, train acc 0.924, test acc 0.905, time 1561.1 sec\n",
      "epoch 64, loss 0.0061, train acc 0.926, test acc 0.907, time 1558.3 sec\n",
      "epoch 65, loss 0.0059, train acc 0.928, test acc 0.906, time 1562.7 sec\n",
      "epoch 66, loss 0.0058, train acc 0.928, test acc 0.905, time 1597.0 sec\n",
      "epoch 67, loss 0.0058, train acc 0.928, test acc 0.904, time 1601.0 sec\n",
      "epoch 68, loss 0.0056, train acc 0.929, test acc 0.906, time 1594.2 sec\n",
      "epoch 69, loss 0.0056, train acc 0.928, test acc 0.902, time 1593.6 sec\n",
      "epoch 70, loss 0.0054, train acc 0.930, test acc 0.903, time 1589.7 sec\n",
      "epoch 71, loss 0.0054, train acc 0.928, test acc 0.907, time 1589.3 sec\n",
      "epoch 72, loss 0.0053, train acc 0.929, test acc 0.903, time 1591.1 sec\n",
      "epoch 73, loss 0.0053, train acc 0.928, test acc 0.899, time 1602.4 sec\n",
      "epoch 74, loss 0.0052, train acc 0.926, test acc 0.909, time 1597.4 sec\n",
      "epoch 75, loss 0.0051, train acc 0.931, test acc 0.906, time 1594.5 sec\n",
      "epoch 76, loss 0.0050, train acc 0.930, test acc 0.904, time 1593.0 sec\n",
      "epoch 77, loss 0.0050, train acc 0.930, test acc 0.901, time 1604.0 sec\n",
      "epoch 78, loss 0.0048, train acc 0.931, test acc 0.912, time 1595.0 sec\n",
      "epoch 79, loss 0.0049, train acc 0.927, test acc 0.906, time 1589.8 sec\n",
      "epoch 80, loss 0.0047, train acc 0.928, test acc 0.905, time 1596.5 sec\n",
      "epoch 81, loss 0.0048, train acc 0.929, test acc 0.900, time 1595.9 sec\n",
      "epoch 82, loss 0.0047, train acc 0.928, test acc 0.907, time 1594.5 sec\n",
      "epoch 83, loss 0.0046, train acc 0.927, test acc 0.901, time 1597.5 sec\n",
      "epoch 84, loss 0.0044, train acc 0.931, test acc 0.903, time 1595.7 sec\n",
      "epoch 85, loss 0.0045, train acc 0.929, test acc 0.900, time 1594.8 sec\n",
      "epoch 86, loss 0.0043, train acc 0.934, test acc 0.908, time 1594.4 sec\n",
      "epoch 87, loss 0.0044, train acc 0.928, test acc 0.904, time 1596.3 sec\n",
      "epoch 88, loss 0.0043, train acc 0.928, test acc 0.905, time 1592.6 sec\n",
      "epoch 89, loss 0.0042, train acc 0.933, test acc 0.903, time 1601.1 sec\n",
      "epoch 90, loss 0.0042, train acc 0.932, test acc 0.907, time 1595.9 sec\n",
      "epoch 91, loss 0.0042, train acc 0.932, test acc 0.901, time 1596.6 sec\n",
      "epoch 92, loss 0.0042, train acc 0.927, test acc 0.907, time 1592.2 sec\n",
      "epoch 93, loss 0.0041, train acc 0.930, test acc 0.910, time 1600.2 sec\n",
      "epoch 94, loss 0.0040, train acc 0.932, test acc 0.903, time 1611.0 sec\n",
      "epoch 95, loss 0.0040, train acc 0.929, test acc 0.904, time 1605.9 sec\n",
      "epoch 96, loss 0.0039, train acc 0.932, test acc 0.900, time 1625.0 sec\n",
      "epoch 97, loss 0.0039, train acc 0.931, test acc 0.903, time 1614.4 sec\n",
      "epoch 98, loss 0.0038, train acc 0.934, test acc 0.902, time 1617.2 sec\n",
      "epoch 99, loss 0.0037, train acc 0.933, test acc 0.900, time 1615.7 sec\n",
      "epoch 100, loss 0.0038, train acc 0.934, test acc 0.903, time 1613.7 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlc_block添加到res4块中的模型\n",
    "save_path = 'nlcnet3_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet3,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.9284, train acc 0.214, test acc 0.444, time 1688.7 sec\n",
      "epoch 2, loss 1.4146, train acc 0.503, test acc 0.612, time 1693.2 sec\n",
      "epoch 3, loss 0.7413, train acc 0.619, test acc 0.680, time 1716.6 sec\n",
      "epoch 4, loss 0.4653, train acc 0.672, test acc 0.724, time 1681.8 sec\n",
      "epoch 5, loss 0.3218, train acc 0.714, test acc 0.739, time 1685.4 sec\n",
      "epoch 6, loss 0.2393, train acc 0.736, test acc 0.760, time 1700.4 sec\n",
      "epoch 7, loss 0.1875, train acc 0.762, test acc 0.759, time 1722.4 sec\n",
      "epoch 8, loss 0.1508, train acc 0.772, test acc 0.774, time 1724.9 sec\n",
      "epoch 9, loss 0.1260, train acc 0.785, test acc 0.789, time 1724.5 sec\n",
      "epoch 10, loss 0.1060, train acc 0.795, test acc 0.802, time 1698.8 sec\n",
      "epoch 11, loss 0.0920, train acc 0.806, test acc 0.809, time 1753.1 sec\n",
      "epoch 12, loss 0.0801, train acc 0.811, test acc 0.818, time 1793.6 sec\n",
      "epoch 13, loss 0.0706, train acc 0.817, test acc 0.816, time 1771.8 sec\n",
      "epoch 14, loss 0.0624, train acc 0.826, test acc 0.809, time 1761.0 sec\n",
      "epoch 15, loss 0.0565, train acc 0.830, test acc 0.835, time 1742.7 sec\n",
      "epoch 16, loss 0.0503, train acc 0.841, test acc 0.829, time 1708.8 sec\n",
      "epoch 17, loss 0.0465, train acc 0.842, test acc 0.840, time 1700.1 sec\n",
      "epoch 18, loss 0.0422, train acc 0.849, test acc 0.833, time 1770.0 sec\n",
      "epoch 19, loss 0.0387, train acc 0.853, test acc 0.837, time 1765.6 sec\n",
      "epoch 20, loss 0.0359, train acc 0.856, test acc 0.840, time 1750.7 sec\n",
      "epoch 21, loss 0.0338, train acc 0.854, test acc 0.848, time 1706.0 sec\n",
      "epoch 22, loss 0.0310, train acc 0.861, test acc 0.847, time 1679.5 sec\n",
      "epoch 23, loss 0.0291, train acc 0.862, test acc 0.859, time 1679.2 sec\n",
      "epoch 24, loss 0.0269, train acc 0.871, test acc 0.855, time 1730.8 sec\n",
      "epoch 25, loss 0.0253, train acc 0.873, test acc 0.868, time 1727.4 sec\n",
      "epoch 26, loss 0.0239, train acc 0.872, test acc 0.870, time 1714.6 sec\n",
      "epoch 27, loss 0.0227, train acc 0.877, test acc 0.864, time 1703.1 sec\n",
      "epoch 28, loss 0.0214, train acc 0.876, test acc 0.864, time 1687.7 sec\n",
      "epoch 29, loss 0.0203, train acc 0.885, test acc 0.870, time 1683.8 sec\n",
      "epoch 30, loss 0.0193, train acc 0.884, test acc 0.869, time 1684.5 sec\n",
      "epoch 31, loss 0.0186, train acc 0.882, test acc 0.874, time 1682.5 sec\n",
      "epoch 32, loss 0.0169, train acc 0.895, test acc 0.874, time 1686.2 sec\n",
      "epoch 33, loss 0.0165, train acc 0.887, test acc 0.873, time 1683.8 sec\n",
      "epoch 34, loss 0.0159, train acc 0.891, test acc 0.873, time 1684.3 sec\n",
      "epoch 35, loss 0.0150, train acc 0.896, test acc 0.876, time 1681.8 sec\n",
      "epoch 36, loss 0.0147, train acc 0.894, test acc 0.881, time 1685.8 sec\n",
      "epoch 37, loss 0.0138, train acc 0.899, test acc 0.887, time 1679.5 sec\n",
      "epoch 38, loss 0.0133, train acc 0.898, test acc 0.889, time 1681.1 sec\n",
      "epoch 39, loss 0.0126, train acc 0.905, test acc 0.888, time 1683.1 sec\n",
      "epoch 40, loss 0.0122, train acc 0.903, test acc 0.887, time 1684.4 sec\n",
      "epoch 41, loss 0.0120, train acc 0.902, test acc 0.882, time 1685.5 sec\n",
      "epoch 42, loss 0.0114, train acc 0.905, test acc 0.890, time 1685.6 sec\n",
      "epoch 43, loss 0.0109, train acc 0.907, test acc 0.885, time 1685.4 sec\n",
      "epoch 44, loss 0.0107, train acc 0.905, test acc 0.885, time 1682.9 sec\n",
      "epoch 45, loss 0.0102, train acc 0.910, test acc 0.888, time 1699.6 sec\n",
      "epoch 46, loss 0.0100, train acc 0.910, test acc 0.888, time 1717.5 sec\n",
      "epoch 47, loss 0.0095, train acc 0.914, test acc 0.896, time 1715.8 sec\n",
      "epoch 48, loss 0.0094, train acc 0.913, test acc 0.890, time 1698.2 sec\n",
      "epoch 49, loss 0.0090, train acc 0.912, test acc 0.894, time 1707.4 sec\n",
      "epoch 50, loss 0.0087, train acc 0.914, test acc 0.898, time 1710.9 sec\n",
      "epoch 51, loss 0.0085, train acc 0.914, test acc 0.899, time 1717.0 sec\n",
      "epoch 52, loss 0.0082, train acc 0.916, test acc 0.897, time 1729.2 sec\n",
      "epoch 53, loss 0.0079, train acc 0.920, test acc 0.902, time 1720.4 sec\n",
      "epoch 54, loss 0.0077, train acc 0.921, test acc 0.902, time 1713.0 sec\n",
      "epoch 55, loss 0.0075, train acc 0.918, test acc 0.897, time 1738.9 sec\n",
      "epoch 56, loss 0.0074, train acc 0.923, test acc 0.901, time 1732.5 sec\n",
      "epoch 57, loss 0.0073, train acc 0.918, test acc 0.899, time 1740.3 sec\n",
      "epoch 58, loss 0.0069, train acc 0.923, test acc 0.906, time 1804.8 sec\n",
      "epoch 59, loss 0.0068, train acc 0.918, test acc 0.903, time 1841.0 sec\n",
      "epoch 60, loss 0.0066, train acc 0.925, test acc 0.902, time 1844.7 sec\n",
      "epoch 61, loss 0.0063, train acc 0.929, test acc 0.910, time 1802.4 sec\n",
      "epoch 62, loss 0.0061, train acc 0.933, test acc 0.906, time 1769.2 sec\n",
      "epoch 63, loss 0.0060, train acc 0.929, test acc 0.906, time 1806.5 sec\n",
      "epoch 64, loss 0.0060, train acc 0.932, test acc 0.906, time 1754.5 sec\n",
      "epoch 65, loss 0.0058, train acc 0.929, test acc 0.908, time 1784.8 sec\n",
      "epoch 66, loss 0.0059, train acc 0.925, test acc 0.903, time 1722.2 sec\n",
      "epoch 67, loss 0.0057, train acc 0.930, test acc 0.910, time 1702.3 sec\n",
      "epoch 68, loss 0.0057, train acc 0.930, test acc 0.905, time 1727.1 sec\n",
      "epoch 69, loss 0.0054, train acc 0.930, test acc 0.905, time 1721.2 sec\n",
      "epoch 70, loss 0.0055, train acc 0.925, test acc 0.907, time 1698.6 sec\n",
      "epoch 71, loss 0.0054, train acc 0.928, test acc 0.900, time 1695.3 sec\n",
      "epoch 72, loss 0.0053, train acc 0.927, test acc 0.901, time 1699.0 sec\n",
      "epoch 73, loss 0.0051, train acc 0.933, test acc 0.909, time 1702.2 sec\n",
      "epoch 74, loss 0.0052, train acc 0.930, test acc 0.907, time 1704.4 sec\n",
      "epoch 75, loss 0.0051, train acc 0.928, test acc 0.908, time 1681.6 sec\n",
      "epoch 76, loss 0.0049, train acc 0.933, test acc 0.908, time 1677.0 sec\n",
      "epoch 77, loss 0.0048, train acc 0.933, test acc 0.906, time 1676.4 sec\n",
      "epoch 78, loss 0.0048, train acc 0.927, test acc 0.908, time 1677.6 sec\n",
      "epoch 79, loss 0.0049, train acc 0.926, test acc 0.906, time 1675.7 sec\n",
      "epoch 80, loss 0.0048, train acc 0.928, test acc 0.909, time 1674.0 sec\n",
      "epoch 81, loss 0.0047, train acc 0.930, test acc 0.905, time 1673.8 sec\n",
      "epoch 82, loss 0.0046, train acc 0.932, test acc 0.908, time 1678.4 sec\n",
      "epoch 83, loss 0.0046, train acc 0.928, test acc 0.906, time 1677.5 sec\n",
      "epoch 84, loss 0.0044, train acc 0.931, test acc 0.909, time 1681.7 sec\n",
      "epoch 85, loss 0.0045, train acc 0.930, test acc 0.908, time 1678.2 sec\n",
      "epoch 86, loss 0.0043, train acc 0.935, test acc 0.903, time 1683.8 sec\n",
      "epoch 87, loss 0.0043, train acc 0.932, test acc 0.911, time 1674.1 sec\n",
      "epoch 88, loss 0.0042, train acc 0.932, test acc 0.907, time 1679.0 sec\n",
      "epoch 89, loss 0.0043, train acc 0.929, test acc 0.909, time 1681.8 sec\n",
      "epoch 90, loss 0.0042, train acc 0.928, test acc 0.905, time 1679.5 sec\n",
      "epoch 91, loss 0.0041, train acc 0.932, test acc 0.901, time 1675.3 sec\n",
      "epoch 92, loss 0.0041, train acc 0.930, test acc 0.903, time 1675.9 sec\n",
      "epoch 93, loss 0.0040, train acc 0.931, test acc 0.902, time 1673.2 sec\n",
      "epoch 94, loss 0.0039, train acc 0.933, test acc 0.905, time 1678.3 sec\n",
      "epoch 95, loss 0.0039, train acc 0.932, test acc 0.910, time 1679.5 sec\n",
      "epoch 96, loss 0.0039, train acc 0.933, test acc 0.907, time 1679.0 sec\n",
      "epoch 97, loss 0.0040, train acc 0.930, test acc 0.905, time 1688.3 sec\n",
      "epoch 98, loss 0.0039, train acc 0.929, test acc 0.913, time 1695.4 sec\n",
      "epoch 99, loss 0.0038, train acc 0.929, test acc 0.909, time 1694.9 sec\n",
      "epoch 100, loss 0.0037, train acc 0.933, test acc 0.906, time 1698.4 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlc_block添加到res3块中的模型\n",
    "save_path = 'nlcnet2_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet2,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.9288, train acc 0.224, test acc 0.464, time 1752.0 sec\n",
      "epoch 2, loss 1.4060, train acc 0.523, test acc 0.605, time 1586.3 sec\n",
      "epoch 3, loss 0.7333, train acc 0.624, test acc 0.690, time 1578.8 sec\n",
      "epoch 4, loss 0.4588, train acc 0.683, test acc 0.718, time 1580.1 sec\n",
      "epoch 5, loss 0.3176, train acc 0.718, test acc 0.735, time 1589.9 sec\n",
      "epoch 6, loss 0.2355, train acc 0.743, test acc 0.753, time 1592.2 sec\n",
      "epoch 7, loss 0.1853, train acc 0.758, test acc 0.766, time 1583.6 sec\n",
      "epoch 8, loss 0.1494, train acc 0.777, test acc 0.786, time 1583.8 sec\n",
      "epoch 9, loss 0.1246, train acc 0.785, test acc 0.792, time 1579.5 sec\n",
      "epoch 10, loss 0.1057, train acc 0.797, test acc 0.795, time 1582.3 sec\n",
      "epoch 11, loss 0.0904, train acc 0.809, test acc 0.813, time 1584.6 sec\n",
      "epoch 12, loss 0.0786, train acc 0.819, test acc 0.807, time 1584.5 sec\n",
      "epoch 13, loss 0.0699, train acc 0.822, test acc 0.813, time 1581.0 sec\n",
      "epoch 14, loss 0.0618, train acc 0.831, test acc 0.819, time 1580.1 sec\n",
      "epoch 15, loss 0.0553, train acc 0.841, test acc 0.829, time 1584.5 sec\n",
      "epoch 16, loss 0.0510, train acc 0.834, test acc 0.823, time 1584.6 sec\n",
      "epoch 17, loss 0.0456, train acc 0.847, test acc 0.839, time 1586.4 sec\n",
      "epoch 18, loss 0.0422, train acc 0.850, test acc 0.837, time 1585.0 sec\n",
      "epoch 19, loss 0.0385, train acc 0.856, test acc 0.848, time 1592.3 sec\n",
      "epoch 20, loss 0.0358, train acc 0.857, test acc 0.860, time 1588.9 sec\n",
      "epoch 21, loss 0.0333, train acc 0.862, test acc 0.860, time 1606.0 sec\n",
      "epoch 22, loss 0.0306, train acc 0.863, test acc 0.859, time 1596.9 sec\n",
      "epoch 23, loss 0.0285, train acc 0.868, test acc 0.857, time 1616.3 sec\n",
      "epoch 24, loss 0.0268, train acc 0.872, test acc 0.857, time 1632.3 sec\n",
      "epoch 25, loss 0.0253, train acc 0.874, test acc 0.861, time 1649.2 sec\n",
      "epoch 26, loss 0.0235, train acc 0.878, test acc 0.865, time 1669.2 sec\n",
      "epoch 27, loss 0.0221, train acc 0.879, test acc 0.866, time 1667.4 sec\n",
      "epoch 28, loss 0.0211, train acc 0.884, test acc 0.869, time 1647.0 sec\n",
      "epoch 29, loss 0.0204, train acc 0.881, test acc 0.869, time 1634.8 sec\n",
      "epoch 30, loss 0.0186, train acc 0.890, test acc 0.868, time 1631.0 sec\n",
      "epoch 31, loss 0.0180, train acc 0.889, test acc 0.871, time 1626.1 sec\n",
      "epoch 32, loss 0.0173, train acc 0.889, test acc 0.874, time 1637.3 sec\n",
      "epoch 33, loss 0.0161, train acc 0.898, test acc 0.880, time 1632.0 sec\n",
      "epoch 34, loss 0.0157, train acc 0.891, test acc 0.877, time 1626.0 sec\n",
      "epoch 35, loss 0.0149, train acc 0.899, test acc 0.880, time 1633.9 sec\n",
      "epoch 36, loss 0.0142, train acc 0.901, test acc 0.879, time 1641.5 sec\n",
      "epoch 37, loss 0.0137, train acc 0.901, test acc 0.884, time 1637.2 sec\n",
      "epoch 38, loss 0.0133, train acc 0.900, test acc 0.881, time 1631.9 sec\n",
      "epoch 39, loss 0.0124, train acc 0.906, test acc 0.888, time 1637.2 sec\n",
      "epoch 40, loss 0.0121, train acc 0.905, test acc 0.886, time 1634.5 sec\n",
      "epoch 41, loss 0.0118, train acc 0.904, test acc 0.884, time 1644.1 sec\n",
      "epoch 42, loss 0.0113, train acc 0.905, test acc 0.893, time 1642.6 sec\n",
      "epoch 43, loss 0.0109, train acc 0.905, test acc 0.885, time 1656.7 sec\n",
      "epoch 44, loss 0.0105, train acc 0.909, test acc 0.889, time 1654.4 sec\n",
      "epoch 45, loss 0.0102, train acc 0.908, test acc 0.893, time 1662.2 sec\n",
      "epoch 46, loss 0.0100, train acc 0.908, test acc 0.892, time 1661.6 sec\n",
      "epoch 47, loss 0.0096, train acc 0.913, test acc 0.891, time 1654.5 sec\n",
      "epoch 48, loss 0.0094, train acc 0.909, test acc 0.888, time 1651.3 sec\n",
      "epoch 49, loss 0.0089, train acc 0.918, test acc 0.896, time 1665.4 sec\n",
      "epoch 50, loss 0.0087, train acc 0.917, test acc 0.894, time 1666.6 sec\n",
      "epoch 51, loss 0.0085, train acc 0.914, test acc 0.899, time 1691.3 sec\n",
      "epoch 52, loss 0.0084, train acc 0.914, test acc 0.894, time 1694.8 sec\n",
      "epoch 53, loss 0.0081, train acc 0.916, test acc 0.895, time 1707.2 sec\n",
      "epoch 54, loss 0.0076, train acc 0.923, test acc 0.899, time 1698.0 sec\n",
      "epoch 55, loss 0.0076, train acc 0.917, test acc 0.897, time 1682.7 sec\n",
      "epoch 56, loss 0.0074, train acc 0.923, test acc 0.895, time 1676.7 sec\n",
      "epoch 57, loss 0.0073, train acc 0.922, test acc 0.896, time 1673.2 sec\n",
      "epoch 58, loss 0.0071, train acc 0.917, test acc 0.898, time 1646.5 sec\n",
      "epoch 59, loss 0.0068, train acc 0.924, test acc 0.903, time 1638.6 sec\n",
      "epoch 60, loss 0.0067, train acc 0.920, test acc 0.900, time 1650.9 sec\n",
      "epoch 61, loss 0.0063, train acc 0.929, test acc 0.900, time 1653.7 sec\n",
      "epoch 62, loss 0.0061, train acc 0.928, test acc 0.903, time 1646.3 sec\n",
      "epoch 63, loss 0.0060, train acc 0.928, test acc 0.904, time 1645.2 sec\n",
      "epoch 64, loss 0.0060, train acc 0.927, test acc 0.905, time 1641.1 sec\n",
      "epoch 65, loss 0.0058, train acc 0.929, test acc 0.906, time 1638.6 sec\n",
      "epoch 66, loss 0.0058, train acc 0.929, test acc 0.900, time 1638.3 sec\n",
      "epoch 67, loss 0.0058, train acc 0.928, test acc 0.902, time 1645.5 sec\n",
      "epoch 68, loss 0.0056, train acc 0.929, test acc 0.902, time 1641.7 sec\n",
      "epoch 69, loss 0.0055, train acc 0.932, test acc 0.907, time 1635.5 sec\n",
      "epoch 70, loss 0.0055, train acc 0.928, test acc 0.905, time 1633.1 sec\n",
      "epoch 71, loss 0.0053, train acc 0.931, test acc 0.907, time 1639.7 sec\n",
      "epoch 72, loss 0.0054, train acc 0.929, test acc 0.903, time 1637.3 sec\n",
      "epoch 73, loss 0.0052, train acc 0.930, test acc 0.903, time 1641.9 sec\n",
      "epoch 74, loss 0.0051, train acc 0.931, test acc 0.908, time 1640.2 sec\n",
      "epoch 75, loss 0.0051, train acc 0.928, test acc 0.904, time 1638.5 sec\n",
      "epoch 76, loss 0.0050, train acc 0.932, test acc 0.905, time 1638.6 sec\n",
      "epoch 77, loss 0.0049, train acc 0.927, test acc 0.905, time 1635.4 sec\n",
      "epoch 78, loss 0.0048, train acc 0.932, test acc 0.909, time 1644.2 sec\n",
      "epoch 79, loss 0.0048, train acc 0.931, test acc 0.904, time 1634.3 sec\n",
      "epoch 80, loss 0.0046, train acc 0.932, test acc 0.908, time 1639.8 sec\n",
      "epoch 81, loss 0.0046, train acc 0.933, test acc 0.907, time 1636.9 sec\n",
      "epoch 82, loss 0.0046, train acc 0.931, test acc 0.909, time 1637.2 sec\n",
      "epoch 83, loss 0.0046, train acc 0.929, test acc 0.901, time 1635.9 sec\n",
      "epoch 84, loss 0.0045, train acc 0.930, test acc 0.907, time 1627.4 sec\n",
      "epoch 85, loss 0.0045, train acc 0.930, test acc 0.905, time 1631.5 sec\n",
      "epoch 86, loss 0.0043, train acc 0.933, test acc 0.903, time 1622.2 sec\n",
      "epoch 87, loss 0.0043, train acc 0.930, test acc 0.906, time 1613.5 sec\n",
      "epoch 88, loss 0.0043, train acc 0.928, test acc 0.904, time 1614.2 sec\n",
      "epoch 89, loss 0.0042, train acc 0.934, test acc 0.906, time 1609.5 sec\n",
      "epoch 90, loss 0.0042, train acc 0.929, test acc 0.909, time 1599.6 sec\n",
      "epoch 91, loss 0.0041, train acc 0.934, test acc 0.913, time 1584.2 sec\n",
      "epoch 92, loss 0.0041, train acc 0.933, test acc 0.909, time 1591.8 sec\n",
      "epoch 93, loss 0.0040, train acc 0.932, test acc 0.904, time 1591.9 sec\n",
      "epoch 94, loss 0.0040, train acc 0.929, test acc 0.908, time 1610.9 sec\n",
      "epoch 95, loss 0.0039, train acc 0.932, test acc 0.902, time 1587.5 sec\n",
      "epoch 96, loss 0.0039, train acc 0.928, test acc 0.906, time 1582.3 sec\n",
      "epoch 97, loss 0.0039, train acc 0.931, test acc 0.905, time 1587.7 sec\n",
      "epoch 98, loss 0.0038, train acc 0.932, test acc 0.909, time 1588.2 sec\n",
      "epoch 99, loss 0.0038, train acc 0.932, test acc 0.901, time 1592.5 sec\n",
      "epoch 100, loss 0.0037, train acc 0.931, test acc 0.909, time 1598.3 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlc5_block添加到res1块中的模型\n",
    "save_path = 'nlcnet5_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet5,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.9298, train acc 0.229, test acc 0.436, time 1711.1 sec\n",
      "epoch 2, loss 1.4110, train acc 0.508, test acc 0.594, time 1712.8 sec\n",
      "epoch 3, loss 0.7360, train acc 0.622, test acc 0.674, time 1715.3 sec\n",
      "epoch 4, loss 0.4593, train acc 0.680, test acc 0.719, time 1717.4 sec\n",
      "epoch 5, loss 0.3195, train acc 0.716, test acc 0.732, time 1730.3 sec\n",
      "epoch 6, loss 0.2390, train acc 0.735, test acc 0.754, time 1730.1 sec\n",
      "epoch 7, loss 0.1847, train acc 0.763, test acc 0.768, time 1735.9 sec\n",
      "epoch 8, loss 0.1508, train acc 0.771, test acc 0.780, time 1737.1 sec\n",
      "epoch 9, loss 0.1256, train acc 0.785, test acc 0.790, time 1734.5 sec\n",
      "epoch 10, loss 0.1045, train acc 0.801, test acc 0.801, time 1734.4 sec\n",
      "epoch 11, loss 0.0904, train acc 0.806, test acc 0.800, time 1732.3 sec\n",
      "epoch 12, loss 0.0799, train acc 0.816, test acc 0.813, time 1734.7 sec\n",
      "epoch 13, loss 0.0701, train acc 0.822, test acc 0.818, time 1732.2 sec\n",
      "epoch 14, loss 0.0621, train acc 0.830, test acc 0.817, time 1741.1 sec\n",
      "epoch 15, loss 0.0561, train acc 0.833, test acc 0.823, time 1736.6 sec\n",
      "epoch 16, loss 0.0498, train acc 0.842, test acc 0.828, time 1734.6 sec\n",
      "epoch 17, loss 0.0458, train acc 0.849, test acc 0.833, time 1733.1 sec\n",
      "epoch 18, loss 0.0417, train acc 0.848, test acc 0.833, time 1730.2 sec\n",
      "epoch 19, loss 0.0386, train acc 0.853, test acc 0.843, time 1739.8 sec\n",
      "epoch 20, loss 0.0357, train acc 0.857, test acc 0.853, time 1727.6 sec\n",
      "epoch 21, loss 0.0330, train acc 0.864, test acc 0.843, time 1733.2 sec\n",
      "epoch 22, loss 0.0308, train acc 0.864, test acc 0.846, time 1732.7 sec\n",
      "epoch 23, loss 0.0285, train acc 0.869, test acc 0.856, time 1737.0 sec\n",
      "epoch 24, loss 0.0268, train acc 0.875, test acc 0.859, time 1733.8 sec\n",
      "epoch 25, loss 0.0256, train acc 0.869, test acc 0.857, time 1733.9 sec\n",
      "epoch 26, loss 0.0240, train acc 0.872, test acc 0.859, time 1729.9 sec\n",
      "epoch 27, loss 0.0224, train acc 0.878, test acc 0.862, time 1737.0 sec\n",
      "epoch 28, loss 0.0211, train acc 0.885, test acc 0.869, time 1728.5 sec\n",
      "epoch 29, loss 0.0199, train acc 0.884, test acc 0.872, time 1735.0 sec\n",
      "epoch 30, loss 0.0191, train acc 0.882, test acc 0.865, time 1736.1 sec\n",
      "epoch 31, loss 0.0182, train acc 0.887, test acc 0.869, time 1732.6 sec\n",
      "epoch 32, loss 0.0169, train acc 0.891, test acc 0.869, time 1722.3 sec\n",
      "epoch 33, loss 0.0165, train acc 0.891, test acc 0.877, time 1716.1 sec\n",
      "epoch 34, loss 0.0158, train acc 0.894, test acc 0.881, time 1721.9 sec\n",
      "epoch 35, loss 0.0152, train acc 0.892, test acc 0.869, time 1736.6 sec\n",
      "epoch 36, loss 0.0142, train acc 0.899, test acc 0.884, time 1738.5 sec\n",
      "epoch 37, loss 0.0136, train acc 0.901, test acc 0.879, time 1730.4 sec\n",
      "epoch 38, loss 0.0133, train acc 0.900, test acc 0.875, time 1731.7 sec\n",
      "epoch 39, loss 0.0127, train acc 0.901, test acc 0.878, time 1732.5 sec\n",
      "epoch 40, loss 0.0123, train acc 0.902, test acc 0.885, time 1734.6 sec\n",
      "epoch 41, loss 0.0119, train acc 0.902, test acc 0.882, time 1730.6 sec\n",
      "epoch 42, loss 0.0114, train acc 0.908, test acc 0.890, time 1740.3 sec\n",
      "epoch 43, loss 0.0107, train acc 0.911, test acc 0.889, time 1737.2 sec\n",
      "epoch 44, loss 0.0105, train acc 0.910, test acc 0.881, time 1732.4 sec\n",
      "epoch 45, loss 0.0104, train acc 0.906, test acc 0.888, time 1734.5 sec\n",
      "epoch 46, loss 0.0100, train acc 0.908, test acc 0.888, time 1730.5 sec\n",
      "epoch 47, loss 0.0097, train acc 0.912, test acc 0.897, time 1730.9 sec\n",
      "epoch 48, loss 0.0095, train acc 0.913, test acc 0.884, time 1735.8 sec\n",
      "epoch 49, loss 0.0091, train acc 0.912, test acc 0.893, time 1735.1 sec\n",
      "epoch 50, loss 0.0086, train acc 0.913, test acc 0.895, time 1731.3 sec\n",
      "epoch 51, loss 0.0085, train acc 0.921, test acc 0.892, time 1726.9 sec\n",
      "epoch 52, loss 0.0083, train acc 0.914, test acc 0.893, time 1738.6 sec\n",
      "epoch 53, loss 0.0079, train acc 0.921, test acc 0.898, time 1733.8 sec\n",
      "epoch 54, loss 0.0077, train acc 0.920, test acc 0.891, time 1748.6 sec\n",
      "epoch 55, loss 0.0075, train acc 0.920, test acc 0.900, time 1746.1 sec\n",
      "epoch 56, loss 0.0073, train acc 0.918, test acc 0.900, time 1735.1 sec\n",
      "epoch 57, loss 0.0071, train acc 0.923, test acc 0.897, time 1744.4 sec\n",
      "epoch 58, loss 0.0071, train acc 0.919, test acc 0.902, time 1732.4 sec\n",
      "epoch 59, loss 0.0070, train acc 0.920, test acc 0.889, time 1744.4 sec\n",
      "epoch 60, loss 0.0067, train acc 0.924, test acc 0.904, time 1733.8 sec\n",
      "epoch 61, loss 0.0062, train acc 0.932, test acc 0.901, time 1738.4 sec\n",
      "epoch 62, loss 0.0063, train acc 0.926, test acc 0.899, time 1746.2 sec\n",
      "epoch 63, loss 0.0062, train acc 0.924, test acc 0.909, time 1743.6 sec\n",
      "epoch 64, loss 0.0059, train acc 0.930, test acc 0.904, time 1732.4 sec\n",
      "epoch 65, loss 0.0059, train acc 0.929, test acc 0.905, time 1735.5 sec\n",
      "epoch 66, loss 0.0057, train acc 0.930, test acc 0.902, time 1738.5 sec\n",
      "epoch 67, loss 0.0058, train acc 0.928, test acc 0.903, time 1737.3 sec\n",
      "epoch 68, loss 0.0056, train acc 0.931, test acc 0.908, time 1736.4 sec\n",
      "epoch 69, loss 0.0056, train acc 0.927, test acc 0.903, time 1731.1 sec\n",
      "epoch 70, loss 0.0055, train acc 0.932, test acc 0.905, time 1738.3 sec\n",
      "epoch 71, loss 0.0053, train acc 0.930, test acc 0.907, time 1736.3 sec\n",
      "epoch 72, loss 0.0054, train acc 0.924, test acc 0.904, time 1734.5 sec\n",
      "epoch 73, loss 0.0052, train acc 0.930, test acc 0.904, time 1735.4 sec\n",
      "epoch 74, loss 0.0051, train acc 0.929, test acc 0.905, time 1733.3 sec\n",
      "epoch 75, loss 0.0050, train acc 0.934, test acc 0.905, time 1743.7 sec\n",
      "epoch 76, loss 0.0049, train acc 0.929, test acc 0.904, time 1740.3 sec\n",
      "epoch 77, loss 0.0049, train acc 0.931, test acc 0.904, time 1735.9 sec\n",
      "epoch 78, loss 0.0048, train acc 0.931, test acc 0.907, time 1743.1 sec\n",
      "epoch 79, loss 0.0048, train acc 0.932, test acc 0.902, time 1753.1 sec\n",
      "epoch 80, loss 0.0047, train acc 0.935, test acc 0.904, time 1755.2 sec\n",
      "epoch 81, loss 0.0047, train acc 0.932, test acc 0.904, time 1754.3 sec\n",
      "epoch 82, loss 0.0046, train acc 0.933, test acc 0.906, time 1771.2 sec\n",
      "epoch 83, loss 0.0046, train acc 0.929, test acc 0.904, time 1768.3 sec\n",
      "epoch 84, loss 0.0045, train acc 0.931, test acc 0.905, time 1761.5 sec\n",
      "epoch 85, loss 0.0045, train acc 0.931, test acc 0.908, time 1762.7 sec\n",
      "epoch 86, loss 0.0045, train acc 0.930, test acc 0.905, time 1823.3 sec\n",
      "epoch 87, loss 0.0043, train acc 0.931, test acc 0.909, time 1823.7 sec\n",
      "epoch 88, loss 0.0042, train acc 0.934, test acc 0.904, time 1827.6 sec\n",
      "epoch 89, loss 0.0043, train acc 0.931, test acc 0.905, time 1828.3 sec\n",
      "epoch 90, loss 0.0042, train acc 0.929, test acc 0.905, time 1827.9 sec\n",
      "epoch 91, loss 0.0041, train acc 0.931, test acc 0.904, time 1822.9 sec\n",
      "epoch 92, loss 0.0040, train acc 0.932, test acc 0.905, time 1823.2 sec\n",
      "epoch 93, loss 0.0040, train acc 0.930, test acc 0.900, time 1824.1 sec\n",
      "epoch 94, loss 0.0039, train acc 0.933, test acc 0.899, time 1828.9 sec\n",
      "epoch 95, loss 0.0040, train acc 0.933, test acc 0.905, time 1818.9 sec\n",
      "epoch 96, loss 0.0039, train acc 0.930, test acc 0.906, time 1819.1 sec\n",
      "epoch 97, loss 0.0038, train acc 0.933, test acc 0.909, time 1815.9 sec\n",
      "epoch 98, loss 0.0038, train acc 0.932, test acc 0.900, time 1796.3 sec\n",
      "epoch 99, loss 0.0038, train acc 0.931, test acc 0.906, time 1775.0 sec\n",
      "epoch 100, loss 0.0037, train acc 0.933, test acc 0.901, time 1773.2 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlc7_block添加到res1块中的模型\n",
    "save_path = 'nlcnet7_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet7,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.9253, train acc 0.2139, test acc 0.4775, time 1746.1 sec\n",
      "epoch 2, loss 1.4086, train acc 0.5127, test acc 0.6302, time 1744.7 sec\n",
      "epoch 3, loss 0.7357, train acc 0.6207, test acc 0.6720, time 1739.9 sec\n",
      "epoch 4, loss 0.4597, train acc 0.6793, test acc 0.7047, time 1746.9 sec\n",
      "epoch 5, loss 0.3189, train acc 0.7213, test acc 0.7463, time 1753.1 sec\n",
      "epoch 6, loss 0.2385, train acc 0.7388, test acc 0.7515, time 1746.1 sec\n",
      "epoch 7, loss 0.1868, train acc 0.7565, test acc 0.7688, time 1741.8 sec\n",
      "epoch 8, loss 0.1496, train acc 0.7751, test acc 0.7678, time 1743.8 sec\n",
      "epoch 9, loss 0.1245, train acc 0.7876, test acc 0.7975, time 1735.1 sec\n",
      "epoch 10, loss 0.1052, train acc 0.8003, test acc 0.7985, time 1744.8 sec\n",
      "epoch 11, loss 0.0908, train acc 0.8097, test acc 0.7955, time 1740.2 sec\n",
      "epoch 12, loss 0.0789, train acc 0.8178, test acc 0.8027, time 1738.3 sec\n",
      "epoch 13, loss 0.0697, train acc 0.8259, test acc 0.8099, time 1722.5 sec\n",
      "epoch 14, loss 0.0616, train acc 0.8332, test acc 0.8233, time 1735.3 sec\n",
      "epoch 15, loss 0.0553, train acc 0.8407, test acc 0.8309, time 1748.4 sec\n",
      "epoch 16, loss 0.0507, train acc 0.8393, test acc 0.8275, time 1744.1 sec\n",
      "epoch 17, loss 0.0460, train acc 0.8428, test acc 0.8257, time 1771.7 sec\n",
      "epoch 18, loss 0.0421, train acc 0.8510, test acc 0.8381, time 1733.1 sec\n",
      "epoch 19, loss 0.0382, train acc 0.8540, test acc 0.8416, time 1739.5 sec\n",
      "epoch 20, loss 0.0357, train acc 0.8598, test acc 0.8473, time 1740.2 sec\n",
      "epoch 21, loss 0.0331, train acc 0.8630, test acc 0.8493, time 1747.0 sec\n",
      "epoch 22, loss 0.0308, train acc 0.8626, test acc 0.8480, time 1743.6 sec\n",
      "epoch 23, loss 0.0290, train acc 0.8661, test acc 0.8584, time 1752.2 sec\n",
      "epoch 24, loss 0.0269, train acc 0.8694, test acc 0.8604, time 1737.0 sec\n",
      "epoch 25, loss 0.0256, train acc 0.8723, test acc 0.8639, time 1740.0 sec\n",
      "epoch 26, loss 0.0236, train acc 0.8768, test acc 0.8589, time 1729.9 sec\n",
      "epoch 27, loss 0.0226, train acc 0.8792, test acc 0.8601, time 1732.7 sec\n",
      "epoch 28, loss 0.0212, train acc 0.8817, test acc 0.8688, time 1732.2 sec\n",
      "epoch 29, loss 0.0200, train acc 0.8861, test acc 0.8723, time 1738.1 sec\n",
      "epoch 30, loss 0.0191, train acc 0.8880, test acc 0.8619, time 1734.4 sec\n",
      "epoch 31, loss 0.0183, train acc 0.8877, test acc 0.8735, time 1740.1 sec\n",
      "epoch 32, loss 0.0170, train acc 0.8947, test acc 0.8666, time 1739.4 sec\n",
      "epoch 33, loss 0.0164, train acc 0.8919, test acc 0.8715, time 1738.3 sec\n",
      "epoch 34, loss 0.0157, train acc 0.8945, test acc 0.8725, time 1742.9 sec\n",
      "epoch 35, loss 0.0149, train acc 0.8953, test acc 0.8720, time 1733.8 sec\n",
      "epoch 36, loss 0.0144, train acc 0.8950, test acc 0.8780, time 1736.6 sec\n",
      "epoch 37, loss 0.0137, train acc 0.9042, test acc 0.8772, time 1736.9 sec\n",
      "epoch 38, loss 0.0132, train acc 0.9023, test acc 0.8782, time 1736.0 sec\n",
      "epoch 39, loss 0.0129, train acc 0.8955, test acc 0.8819, time 1733.1 sec\n",
      "epoch 40, loss 0.0123, train acc 0.9022, test acc 0.8851, time 1735.1 sec\n",
      "epoch 41, loss 0.0119, train acc 0.9010, test acc 0.8913, time 1731.7 sec\n",
      "epoch 42, loss 0.0115, train acc 0.9050, test acc 0.8856, time 1731.4 sec\n",
      "epoch 43, loss 0.0112, train acc 0.9023, test acc 0.8891, time 1727.8 sec\n",
      "epoch 44, loss 0.0105, train acc 0.9127, test acc 0.8896, time 1739.3 sec\n",
      "epoch 45, loss 0.0103, train acc 0.9068, test acc 0.8933, time 1746.4 sec\n",
      "epoch 46, loss 0.0099, train acc 0.9115, test acc 0.8849, time 1741.1 sec\n",
      "epoch 47, loss 0.0098, train acc 0.9071, test acc 0.8906, time 1741.3 sec\n",
      "epoch 48, loss 0.0092, train acc 0.9182, test acc 0.8916, time 1736.8 sec\n",
      "epoch 49, loss 0.0090, train acc 0.9151, test acc 0.8928, time 1731.6 sec\n",
      "epoch 50, loss 0.0087, train acc 0.9155, test acc 0.8906, time 1733.5 sec\n",
      "epoch 51, loss 0.0082, train acc 0.9141, test acc 0.8894, time 1744.5 sec\n",
      "epoch 52, loss 0.0084, train acc 0.9137, test acc 0.8948, time 1731.1 sec\n",
      "epoch 53, loss 0.0082, train acc 0.9135, test acc 0.8946, time 1728.8 sec\n",
      "epoch 54, loss 0.0080, train acc 0.9139, test acc 0.8965, time 1733.3 sec\n",
      "epoch 55, loss 0.0076, train acc 0.9164, test acc 0.8938, time 1739.8 sec\n",
      "epoch 56, loss 0.0074, train acc 0.9208, test acc 0.8953, time 1737.2 sec\n",
      "epoch 57, loss 0.0072, train acc 0.9200, test acc 0.8993, time 1728.9 sec\n",
      "epoch 58, loss 0.0070, train acc 0.9223, test acc 0.8978, time 1735.2 sec\n",
      "epoch 59, loss 0.0067, train acc 0.9265, test acc 0.8965, time 1733.4 sec\n",
      "epoch 60, loss 0.0068, train acc 0.9204, test acc 0.8968, time 1737.7 sec\n",
      "epoch 61, loss 0.0065, train acc 0.9237, test acc 0.8973, time 1741.6 sec\n",
      "epoch 62, loss 0.0062, train acc 0.9306, test acc 0.9032, time 1733.4 sec\n",
      "epoch 63, loss 0.0061, train acc 0.9283, test acc 0.9050, time 1741.6 sec\n",
      "epoch 64, loss 0.0059, train acc 0.9323, test acc 0.8990, time 1746.2 sec\n",
      "epoch 65, loss 0.0059, train acc 0.9279, test acc 0.9047, time 1741.7 sec\n",
      "epoch 66, loss 0.0059, train acc 0.9278, test acc 0.9027, time 1749.2 sec\n",
      "epoch 67, loss 0.0058, train acc 0.9270, test acc 0.9045, time 1732.7 sec\n",
      "epoch 68, loss 0.0056, train acc 0.9290, test acc 0.9012, time 1729.7 sec\n",
      "epoch 69, loss 0.0056, train acc 0.9300, test acc 0.9042, time 1729.0 sec\n",
      "epoch 70, loss 0.0054, train acc 0.9294, test acc 0.9035, time 1737.4 sec\n",
      "epoch 71, loss 0.0054, train acc 0.9300, test acc 0.9064, time 1740.9 sec\n",
      "epoch 72, loss 0.0052, train acc 0.9311, test acc 0.8980, time 1728.9 sec\n",
      "epoch 73, loss 0.0052, train acc 0.9268, test acc 0.9035, time 1741.1 sec\n",
      "epoch 74, loss 0.0051, train acc 0.9323, test acc 0.8980, time 1744.5 sec\n",
      "epoch 75, loss 0.0051, train acc 0.9298, test acc 0.9069, time 1766.6 sec\n",
      "epoch 76, loss 0.0050, train acc 0.9289, test acc 0.8985, time 1744.2 sec\n",
      "epoch 77, loss 0.0051, train acc 0.9267, test acc 0.9047, time 1741.5 sec\n",
      "epoch 78, loss 0.0048, train acc 0.9313, test acc 0.9052, time 1740.5 sec\n",
      "epoch 79, loss 0.0049, train acc 0.9259, test acc 0.9077, time 1745.3 sec\n",
      "epoch 80, loss 0.0047, train acc 0.9324, test acc 0.9047, time 1755.8 sec\n",
      "epoch 81, loss 0.0047, train acc 0.9308, test acc 0.8973, time 1742.9 sec\n",
      "epoch 82, loss 0.0046, train acc 0.9280, test acc 0.9045, time 1735.9 sec\n",
      "epoch 83, loss 0.0045, train acc 0.9315, test acc 0.9045, time 1745.0 sec\n",
      "epoch 84, loss 0.0045, train acc 0.9301, test acc 0.9020, time 1739.1 sec\n",
      "epoch 85, loss 0.0044, train acc 0.9302, test acc 0.9067, time 1734.1 sec\n",
      "epoch 86, loss 0.0043, train acc 0.9324, test acc 0.9082, time 1736.6 sec\n",
      "epoch 87, loss 0.0043, train acc 0.9325, test acc 0.9077, time 1735.5 sec\n",
      "epoch 88, loss 0.0044, train acc 0.9273, test acc 0.9050, time 1740.7 sec\n",
      "epoch 89, loss 0.0041, train acc 0.9342, test acc 0.9087, time 1732.9 sec\n",
      "epoch 90, loss 0.0042, train acc 0.9316, test acc 0.9040, time 1737.5 sec\n",
      "epoch 91, loss 0.0041, train acc 0.9295, test acc 0.9104, time 1709.6 sec\n",
      "epoch 92, loss 0.0041, train acc 0.9311, test acc 0.8988, time 1723.2 sec\n",
      "epoch 93, loss 0.0040, train acc 0.9286, test acc 0.9040, time 1739.0 sec\n",
      "epoch 94, loss 0.0040, train acc 0.9328, test acc 0.9015, time 1736.3 sec\n",
      "epoch 95, loss 0.0040, train acc 0.9288, test acc 0.9062, time 1739.6 sec\n",
      "epoch 96, loss 0.0038, train acc 0.9328, test acc 0.9042, time 1743.0 sec\n",
      "epoch 97, loss 0.0039, train acc 0.9293, test acc 0.9064, time 1735.7 sec\n",
      "epoch 98, loss 0.0038, train acc 0.9321, test acc 0.9094, time 1723.1 sec\n",
      "epoch 99, loss 0.0038, train acc 0.9272, test acc 0.9050, time 1726.1 sec\n",
      "epoch 100, loss 0.0038, train acc 0.9301, test acc 0.9106, time 1713.7 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlc5_block添加到res1块中的模型\n",
    "save_path = 'nlcnet5_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet5,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.6871, train acc 0.2370, test acc 0.5072, time 1867.1 sec\n",
      "epoch 2, loss 1.2149, train acc 0.5236, test acc 0.6250, time 1897.1 sec\n",
      "epoch 3, loss 0.6272, train acc 0.6237, test acc 0.7223, time 1890.0 sec\n",
      "epoch 4, loss 0.3953, train acc 0.6719, test acc 0.7418, time 1891.7 sec\n",
      "epoch 5, loss 0.2764, train acc 0.7141, test acc 0.7611, time 1896.0 sec\n",
      "epoch 6, loss 0.2115, train acc 0.7281, test acc 0.7819, time 1890.4 sec\n",
      "epoch 7, loss 0.1642, train acc 0.7520, test acc 0.7861, time 1905.8 sec\n",
      "epoch 8, loss 0.1339, train acc 0.7693, test acc 0.7980, time 1907.9 sec\n",
      "epoch 9, loss 0.1125, train acc 0.7758, test acc 0.8092, time 1905.3 sec\n",
      "epoch 10, loss 0.0953, train acc 0.7902, test acc 0.8156, time 1904.9 sec\n",
      "epoch 11, loss 0.0831, train acc 0.7968, test acc 0.8252, time 1907.2 sec\n",
      "epoch 12, loss 0.0728, train acc 0.8047, test acc 0.8342, time 1898.0 sec\n",
      "epoch 13, loss 0.0649, train acc 0.8107, test acc 0.8356, time 1908.9 sec\n",
      "epoch 14, loss 0.0571, train acc 0.8241, test acc 0.8478, time 1898.4 sec\n",
      "epoch 15, loss 0.0528, train acc 0.8228, test acc 0.8322, time 1911.3 sec\n",
      "epoch 16, loss 0.0473, train acc 0.8279, test acc 0.8458, time 1897.2 sec\n",
      "epoch 17, loss 0.0430, train acc 0.8346, test acc 0.8540, time 1900.6 sec\n",
      "epoch 18, loss 0.0390, train acc 0.8428, test acc 0.8540, time 1907.5 sec\n",
      "epoch 19, loss 0.0365, train acc 0.8438, test acc 0.8597, time 1894.6 sec\n",
      "epoch 20, loss 0.0340, train acc 0.8455, test acc 0.8673, time 1893.4 sec\n",
      "epoch 21, loss 0.0316, train acc 0.8463, test acc 0.8629, time 1897.1 sec\n",
      "epoch 22, loss 0.0294, train acc 0.8531, test acc 0.8775, time 1901.3 sec\n",
      "epoch 23, loss 0.0274, train acc 0.8589, test acc 0.8720, time 1901.9 sec\n",
      "epoch 24, loss 0.0260, train acc 0.8579, test acc 0.8728, time 1901.5 sec\n",
      "epoch 25, loss 0.0244, train acc 0.8600, test acc 0.8735, time 1910.7 sec\n",
      "epoch 26, loss 0.0234, train acc 0.8593, test acc 0.8653, time 1905.5 sec\n",
      "epoch 27, loss 0.0217, train acc 0.8675, test acc 0.8743, time 1904.3 sec\n",
      "epoch 28, loss 0.0203, train acc 0.8725, test acc 0.8777, time 1906.0 sec\n",
      "epoch 29, loss 0.0193, train acc 0.8736, test acc 0.8725, time 1898.0 sec\n",
      "epoch 30, loss 0.0185, train acc 0.8778, test acc 0.8713, time 1908.4 sec\n",
      "epoch 31, loss 0.0182, train acc 0.8700, test acc 0.8814, time 1905.5 sec\n",
      "epoch 32, loss 0.0173, train acc 0.8741, test acc 0.8876, time 1902.6 sec\n",
      "epoch 33, loss 0.0165, train acc 0.8778, test acc 0.8926, time 1900.3 sec\n",
      "epoch 34, loss 0.0157, train acc 0.8795, test acc 0.8827, time 1909.2 sec\n",
      "epoch 35, loss 0.0147, train acc 0.8870, test acc 0.8842, time 1919.1 sec\n",
      "epoch 36, loss 0.0144, train acc 0.8824, test acc 0.8869, time 1896.4 sec\n",
      "epoch 37, loss 0.0140, train acc 0.8833, test acc 0.8990, time 1904.0 sec\n",
      "epoch 38, loss 0.0134, train acc 0.8860, test acc 0.8911, time 1916.0 sec\n",
      "epoch 39, loss 0.0128, train acc 0.8891, test acc 0.8871, time 1946.1 sec\n",
      "epoch 40, loss 0.0126, train acc 0.8834, test acc 0.8938, time 1937.3 sec\n",
      "epoch 41, loss 0.0120, train acc 0.8847, test acc 0.8955, time 1918.8 sec\n",
      "epoch 42, loss 0.0119, train acc 0.8861, test acc 0.9020, time 1913.6 sec\n",
      "epoch 43, loss 0.0111, train acc 0.8867, test acc 0.8998, time 1916.7 sec\n",
      "epoch 44, loss 0.0107, train acc 0.8931, test acc 0.9045, time 1923.2 sec\n",
      "epoch 45, loss 0.0104, train acc 0.8942, test acc 0.8958, time 1913.4 sec\n",
      "epoch 46, loss 0.0101, train acc 0.8959, test acc 0.8946, time 1907.2 sec\n",
      "epoch 47, loss 0.0101, train acc 0.8921, test acc 0.8978, time 1905.7 sec\n",
      "epoch 48, loss 0.0096, train acc 0.8997, test acc 0.8943, time 1906.5 sec\n",
      "epoch 49, loss 0.0092, train acc 0.9001, test acc 0.9035, time 1909.5 sec\n",
      "epoch 50, loss 0.0092, train acc 0.8989, test acc 0.9017, time 1916.3 sec\n",
      "epoch 51, loss 0.0087, train acc 0.8997, test acc 0.9094, time 1995.5 sec\n",
      "epoch 52, loss 0.0088, train acc 0.8948, test acc 0.9082, time 1996.4 sec\n",
      "epoch 53, loss 0.0085, train acc 0.8986, test acc 0.9042, time 1998.8 sec\n",
      "epoch 54, loss 0.0082, train acc 0.8988, test acc 0.8993, time 1972.1 sec\n",
      "epoch 55, loss 0.0080, train acc 0.9065, test acc 0.9015, time 1972.7 sec\n",
      "epoch 56, loss 0.0077, train acc 0.9037, test acc 0.9092, time 1973.2 sec\n",
      "epoch 57, loss 0.0075, train acc 0.9017, test acc 0.9042, time 1970.9 sec\n",
      "epoch 58, loss 0.0074, train acc 0.9034, test acc 0.9022, time 1975.5 sec\n",
      "epoch 59, loss 0.0073, train acc 0.9052, test acc 0.9035, time 1967.2 sec\n",
      "epoch 60, loss 0.0071, train acc 0.9046, test acc 0.9104, time 1969.8 sec\n",
      "epoch 61, loss 0.0066, train acc 0.9107, test acc 0.9171, time 1971.7 sec\n",
      "epoch 62, loss 0.0064, train acc 0.9177, test acc 0.9136, time 1970.3 sec\n",
      "epoch 63, loss 0.0064, train acc 0.9151, test acc 0.9106, time 1976.3 sec\n",
      "epoch 64, loss 0.0062, train acc 0.9165, test acc 0.9121, time 1970.6 sec\n",
      "epoch 65, loss 0.0061, train acc 0.9192, test acc 0.9136, time 1971.9 sec\n",
      "epoch 66, loss 0.0060, train acc 0.9172, test acc 0.9109, time 1972.7 sec\n",
      "epoch 67, loss 0.0059, train acc 0.9196, test acc 0.9168, time 1974.0 sec\n",
      "epoch 68, loss 0.0058, train acc 0.9180, test acc 0.9193, time 1970.8 sec\n",
      "epoch 69, loss 0.0057, train acc 0.9183, test acc 0.9089, time 1972.6 sec\n",
      "epoch 70, loss 0.0057, train acc 0.9137, test acc 0.9097, time 1968.7 sec\n",
      "epoch 71, loss 0.0057, train acc 0.9130, test acc 0.9171, time 1909.6 sec\n",
      "epoch 72, loss 0.0054, train acc 0.9197, test acc 0.9151, time 1906.5 sec\n",
      "epoch 73, loss 0.0054, train acc 0.9177, test acc 0.9196, time 1903.1 sec\n",
      "epoch 74, loss 0.0053, train acc 0.9193, test acc 0.9151, time 1905.1 sec\n",
      "epoch 75, loss 0.0052, train acc 0.9186, test acc 0.9139, time 1907.1 sec\n",
      "epoch 76, loss 0.0052, train acc 0.9155, test acc 0.9136, time 1909.3 sec\n",
      "epoch 77, loss 0.0052, train acc 0.9178, test acc 0.9101, time 1906.3 sec\n",
      "epoch 78, loss 0.0050, train acc 0.9205, test acc 0.9196, time 1908.6 sec\n",
      "epoch 79, loss 0.0050, train acc 0.9198, test acc 0.9119, time 1904.7 sec\n",
      "epoch 80, loss 0.0050, train acc 0.9150, test acc 0.9161, time 1911.1 sec\n",
      "epoch 81, loss 0.0049, train acc 0.9147, test acc 0.9156, time 1936.0 sec\n",
      "epoch 82, loss 0.0048, train acc 0.9171, test acc 0.9176, time 1931.5 sec\n",
      "epoch 83, loss 0.0045, train acc 0.9248, test acc 0.9186, time 1930.6 sec\n",
      "epoch 84, loss 0.0047, train acc 0.9159, test acc 0.9134, time 1909.0 sec\n",
      "epoch 85, loss 0.0048, train acc 0.9151, test acc 0.9156, time 1920.9 sec\n",
      "epoch 86, loss 0.0045, train acc 0.9200, test acc 0.9126, time 1968.9 sec\n",
      "epoch 87, loss 0.0044, train acc 0.9217, test acc 0.9134, time 2002.5 sec\n",
      "epoch 88, loss 0.0044, train acc 0.9208, test acc 0.9191, time 2063.4 sec\n",
      "epoch 89, loss 0.0043, train acc 0.9214, test acc 0.9121, time 2041.9 sec\n",
      "epoch 90, loss 0.0043, train acc 0.9238, test acc 0.9111, time 1972.2 sec\n",
      "epoch 91, loss 0.0042, train acc 0.9197, test acc 0.9181, time 1911.6 sec\n",
      "epoch 92, loss 0.0042, train acc 0.9177, test acc 0.9186, time 1917.1 sec\n",
      "epoch 93, loss 0.0041, train acc 0.9211, test acc 0.9176, time 1912.8 sec\n",
      "epoch 94, loss 0.0042, train acc 0.9169, test acc 0.9171, time 1916.4 sec\n",
      "epoch 95, loss 0.0041, train acc 0.9177, test acc 0.9136, time 1919.3 sec\n",
      "epoch 96, loss 0.0041, train acc 0.9194, test acc 0.9173, time 1914.5 sec\n",
      "epoch 97, loss 0.0039, train acc 0.9269, test acc 0.9153, time 1917.1 sec\n",
      "epoch 98, loss 0.0040, train acc 0.9190, test acc 0.9218, time 1919.7 sec\n",
      "epoch 99, loss 0.0039, train acc 0.9238, test acc 0.9176, time 1922.9 sec\n",
      "epoch 100, loss 0.0038, train acc 0.9246, test acc 0.9186, time 1924.9 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlcfull_block添加到res1块中的模型\n",
    "save_path = 'nlcnetfull_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 8 \n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet_full,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.7156, train acc 0.233, test acc 0.526, time 1836.2 sec\n",
      "epoch 2, loss 1.2247, train acc 0.520, test acc 0.634, time 1839.3 sec\n",
      "epoch 3, loss 0.6314, train acc 0.620, test acc 0.715, time 1834.2 sec\n",
      "epoch 4, loss 0.4010, train acc 0.670, test acc 0.731, time 1831.8 sec\n",
      "epoch 5, loss 0.2801, train acc 0.710, test acc 0.749, time 1832.9 sec\n",
      "epoch 6, loss 0.2112, train acc 0.730, test acc 0.771, time 1837.8 sec\n",
      "epoch 7, loss 0.1669, train acc 0.745, test acc 0.783, time 1835.3 sec\n",
      "epoch 8, loss 0.1350, train acc 0.766, test acc 0.803, time 1832.9 sec\n",
      "epoch 9, loss 0.1131, train acc 0.777, test acc 0.809, time 1840.2 sec\n",
      "epoch 10, loss 0.0963, train acc 0.785, test acc 0.812, time 1840.9 sec\n",
      "epoch 11, loss 0.0837, train acc 0.793, test acc 0.825, time 1839.1 sec\n",
      "epoch 12, loss 0.0734, train acc 0.796, test acc 0.823, time 1842.1 sec\n",
      "epoch 13, loss 0.0650, train acc 0.812, test acc 0.832, time 1840.4 sec\n",
      "epoch 14, loss 0.0580, train acc 0.814, test acc 0.837, time 1836.7 sec\n",
      "epoch 15, loss 0.0515, train acc 0.827, test acc 0.843, time 1844.0 sec\n",
      "epoch 16, loss 0.0472, train acc 0.829, test acc 0.848, time 1851.2 sec\n",
      "epoch 17, loss 0.0436, train acc 0.833, test acc 0.859, time 1838.4 sec\n",
      "epoch 18, loss 0.0401, train acc 0.838, test acc 0.848, time 1844.6 sec\n",
      "epoch 19, loss 0.0369, train acc 0.838, test acc 0.860, time 1852.2 sec\n",
      "epoch 20, loss 0.0340, train acc 0.843, test acc 0.863, time 1861.2 sec\n",
      "epoch 21, loss 0.0314, train acc 0.852, test acc 0.864, time 1880.3 sec\n",
      "epoch 22, loss 0.0297, train acc 0.851, test acc 0.862, time 1863.6 sec\n",
      "epoch 23, loss 0.0281, train acc 0.850, test acc 0.868, time 1849.4 sec\n",
      "epoch 24, loss 0.0262, train acc 0.856, test acc 0.866, time 1852.6 sec\n",
      "epoch 25, loss 0.0246, train acc 0.861, test acc 0.868, time 1842.9 sec\n",
      "epoch 26, loss 0.0236, train acc 0.861, test acc 0.881, time 1862.0 sec\n",
      "epoch 27, loss 0.0225, train acc 0.862, test acc 0.873, time 1838.7 sec\n",
      "epoch 28, loss 0.0211, train acc 0.868, test acc 0.882, time 1849.4 sec\n",
      "epoch 29, loss 0.0195, train acc 0.871, test acc 0.885, time 1846.9 sec\n",
      "epoch 30, loss 0.0192, train acc 0.867, test acc 0.889, time 1851.8 sec\n",
      "epoch 31, loss 0.0181, train acc 0.873, test acc 0.884, time 1847.0 sec\n",
      "epoch 32, loss 0.0172, train acc 0.877, test acc 0.889, time 1853.6 sec\n",
      "epoch 33, loss 0.0162, train acc 0.879, test acc 0.889, time 1846.2 sec\n",
      "epoch 34, loss 0.0159, train acc 0.878, test acc 0.885, time 1850.3 sec\n",
      "epoch 35, loss 0.0153, train acc 0.880, test acc 0.886, time 1848.9 sec\n",
      "epoch 36, loss 0.0145, train acc 0.882, test acc 0.889, time 1838.2 sec\n",
      "epoch 37, loss 0.0139, train acc 0.884, test acc 0.889, time 1847.1 sec\n",
      "epoch 38, loss 0.0137, train acc 0.883, test acc 0.892, time 1846.9 sec\n",
      "epoch 39, loss 0.0130, train acc 0.886, test acc 0.890, time 1848.0 sec\n",
      "epoch 40, loss 0.0125, train acc 0.888, test acc 0.898, time 1846.1 sec\n",
      "epoch 41, loss 0.0121, train acc 0.887, test acc 0.896, time 1850.5 sec\n",
      "epoch 42, loss 0.0116, train acc 0.892, test acc 0.892, time 1845.4 sec\n",
      "epoch 43, loss 0.0114, train acc 0.891, test acc 0.898, time 1836.5 sec\n",
      "epoch 44, loss 0.0109, train acc 0.894, test acc 0.892, time 1849.6 sec\n",
      "epoch 45, loss 0.0105, train acc 0.893, test acc 0.902, time 1850.1 sec\n",
      "epoch 46, loss 0.0104, train acc 0.893, test acc 0.888, time 1841.4 sec\n",
      "epoch 47, loss 0.0101, train acc 0.895, test acc 0.901, time 1838.1 sec\n",
      "epoch 48, loss 0.0097, train acc 0.889, test acc 0.892, time 1833.8 sec\n",
      "epoch 49, loss 0.0096, train acc 0.892, test acc 0.904, time 1818.8 sec\n",
      "epoch 50, loss 0.0091, train acc 0.899, test acc 0.903, time 1815.4 sec\n",
      "epoch 51, loss 0.0090, train acc 0.899, test acc 0.900, time 1838.4 sec\n",
      "epoch 52, loss 0.0086, train acc 0.898, test acc 0.904, time 1828.2 sec\n",
      "epoch 53, loss 0.0086, train acc 0.896, test acc 0.907, time 1824.8 sec\n",
      "epoch 54, loss 0.0080, train acc 0.902, test acc 0.908, time 1842.2 sec\n",
      "epoch 55, loss 0.0082, train acc 0.899, test acc 0.904, time 1865.9 sec\n",
      "epoch 56, loss 0.0079, train acc 0.902, test acc 0.903, time 1889.0 sec\n",
      "epoch 57, loss 0.0076, train acc 0.906, test acc 0.905, time 1895.1 sec\n",
      "epoch 58, loss 0.0075, train acc 0.903, test acc 0.909, time 1915.0 sec\n",
      "epoch 59, loss 0.0072, train acc 0.905, test acc 0.905, time 1863.2 sec\n",
      "epoch 60, loss 0.0071, train acc 0.906, test acc 0.908, time 1863.0 sec\n",
      "epoch 61, loss 0.0067, train acc 0.913, test acc 0.907, time 1867.6 sec\n",
      "epoch 62, loss 0.0065, train acc 0.915, test acc 0.914, time 1845.4 sec\n",
      "epoch 63, loss 0.0063, train acc 0.915, test acc 0.907, time 1842.0 sec\n",
      "epoch 64, loss 0.0061, train acc 0.919, test acc 0.907, time 1851.0 sec\n",
      "epoch 65, loss 0.0061, train acc 0.920, test acc 0.909, time 1835.7 sec\n",
      "epoch 66, loss 0.0061, train acc 0.915, test acc 0.908, time 1831.8 sec\n",
      "epoch 67, loss 0.0059, train acc 0.919, test acc 0.915, time 1826.5 sec\n",
      "epoch 68, loss 0.0058, train acc 0.919, test acc 0.913, time 1827.8 sec\n",
      "epoch 69, loss 0.0059, train acc 0.911, test acc 0.910, time 1823.3 sec\n",
      "epoch 70, loss 0.0057, train acc 0.918, test acc 0.912, time 1828.6 sec\n",
      "epoch 71, loss 0.0056, train acc 0.916, test acc 0.912, time 1828.9 sec\n",
      "epoch 72, loss 0.0054, train acc 0.922, test acc 0.916, time 1830.4 sec\n",
      "epoch 73, loss 0.0054, train acc 0.915, test acc 0.913, time 1825.8 sec\n",
      "epoch 74, loss 0.0053, train acc 0.919, test acc 0.911, time 1827.1 sec\n",
      "epoch 75, loss 0.0052, train acc 0.920, test acc 0.914, time 1835.0 sec\n",
      "epoch 76, loss 0.0053, train acc 0.915, test acc 0.912, time 1834.4 sec\n",
      "epoch 77, loss 0.0051, train acc 0.917, test acc 0.913, time 1837.0 sec\n",
      "epoch 78, loss 0.0051, train acc 0.914, test acc 0.915, time 1831.2 sec\n",
      "epoch 79, loss 0.0050, train acc 0.917, test acc 0.915, time 1835.0 sec\n",
      "epoch 80, loss 0.0049, train acc 0.919, test acc 0.914, time 1839.8 sec\n",
      "epoch 81, loss 0.0048, train acc 0.920, test acc 0.912, time 1836.9 sec\n",
      "epoch 82, loss 0.0047, train acc 0.919, test acc 0.917, time 1831.5 sec\n",
      "epoch 83, loss 0.0048, train acc 0.916, test acc 0.909, time 1831.6 sec\n",
      "epoch 84, loss 0.0047, train acc 0.918, test acc 0.915, time 1834.3 sec\n",
      "epoch 85, loss 0.0046, train acc 0.918, test acc 0.911, time 1834.6 sec\n",
      "epoch 86, loss 0.0045, train acc 0.918, test acc 0.907, time 1833.7 sec\n",
      "epoch 87, loss 0.0045, train acc 0.922, test acc 0.913, time 1835.6 sec\n",
      "epoch 88, loss 0.0044, train acc 0.918, test acc 0.909, time 1841.2 sec\n",
      "epoch 89, loss 0.0043, train acc 0.921, test acc 0.908, time 1842.4 sec\n",
      "epoch 90, loss 0.0043, train acc 0.921, test acc 0.911, time 1845.5 sec\n",
      "epoch 91, loss 0.0043, train acc 0.921, test acc 0.916, time 1845.7 sec\n",
      "epoch 92, loss 0.0044, train acc 0.913, test acc 0.917, time 1842.3 sec\n",
      "epoch 93, loss 0.0044, train acc 0.918, test acc 0.913, time 1847.4 sec\n",
      "epoch 94, loss 0.0041, train acc 0.923, test acc 0.912, time 1846.1 sec\n",
      "epoch 95, loss 0.0041, train acc 0.919, test acc 0.911, time 1842.5 sec\n",
      "epoch 96, loss 0.0041, train acc 0.916, test acc 0.910, time 1842.1 sec\n",
      "epoch 97, loss 0.0040, train acc 0.915, test acc 0.921, time 1852.4 sec\n",
      "epoch 98, loss 0.0040, train acc 0.917, test acc 0.910, time 1840.4 sec\n",
      "epoch 99, loss 0.0039, train acc 0.919, test acc 0.916, time 1846.8 sec\n",
      "epoch 100, loss 0.0039, train acc 0.917, test acc 0.916, time 1846.7 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlcfull_block添加到res1块中的模型\n",
    "save_path = 'nlcnet_13'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 8 \n",
    "#加载分割数据集 \n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet_13,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.6638, train acc 0.241, test acc 0.499, time 1674.0 sec\n",
      "epoch 2, loss 1.1774, train acc 0.553, test acc 0.690, time 1590.6 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlcfull_block添加到res1块中的模型\n",
    "save_path = 'net'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 8 \n",
    "#加载分割数据集 \n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9280\n",
      "Number of val videos: 4040\n",
      "training on  cuda\n",
      "epoch 1, loss 3.9310, train acc 0.219, test acc 0.468, time 1559.5 sec\n",
      "epoch 2, loss 1.4097, train acc 0.515, test acc 0.617, time 1544.0 sec\n",
      "epoch 3, loss 0.7319, train acc 0.624, test acc 0.677, time 1551.6 sec\n",
      "epoch 4, loss 0.4581, train acc 0.683, test acc 0.713, time 1548.0 sec\n",
      "epoch 5, loss 0.3203, train acc 0.711, test acc 0.730, time 1547.0 sec\n",
      "epoch 6, loss 0.2390, train acc 0.740, test acc 0.763, time 1552.4 sec\n",
      "epoch 7, loss 0.1866, train acc 0.758, test acc 0.769, time 1555.8 sec\n",
      "epoch 8, loss 0.1498, train acc 0.776, test acc 0.770, time 1583.1 sec\n",
      "epoch 9, loss 0.1254, train acc 0.787, test acc 0.779, time 1571.5 sec\n",
      "epoch 10, loss 0.1068, train acc 0.798, test acc 0.796, time 1556.1 sec\n",
      "epoch 11, loss 0.0920, train acc 0.802, test acc 0.808, time 1568.0 sec\n",
      "epoch 12, loss 0.0800, train acc 0.813, test acc 0.811, time 1554.5 sec\n",
      "epoch 13, loss 0.0704, train acc 0.823, test acc 0.817, time 1573.7 sec\n",
      "epoch 14, loss 0.0620, train acc 0.830, test acc 0.812, time 1556.3 sec\n",
      "epoch 15, loss 0.0570, train acc 0.831, test acc 0.824, time 1575.5 sec\n",
      "epoch 16, loss 0.0509, train acc 0.838, test acc 0.831, time 1547.5 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(VideoDataset(dataset \u001b[38;5;241m=\u001b[39m dataset,split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),batch_size \u001b[38;5;241m=\u001b[39mbatch_size,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)     \n\u001b[1;32m     10\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(VideoDataset(dataset \u001b[38;5;241m=\u001b[39m dataset,split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m,preprocess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),batch_size \u001b[38;5;241m=\u001b[39m batch_size,num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmilestones\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, train_dataloader, test_dataloader, milestones, batch_size, device, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     33\u001b[0m     train_l_sum, train_acc_sum, n, start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     35\u001b[0m         X \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m         y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mVideoDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# Perform data augmentation\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandomflip(buffer)\n\u001b[0;32m--> 107\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_tensor(buffer)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(buffer), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(labels)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mVideoDataset.normalize\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(buffer):\n\u001b[0;32m--> 228\u001b[0m         frame \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[[\u001b[38;5;241m90.0\u001b[39m, \u001b[38;5;241m98.0\u001b[39m, \u001b[38;5;241m102.0\u001b[39m]]])\n\u001b[1;32m    229\u001b[0m         buffer[i] \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "#milestones = [15,30,45]#多间隔学习率调整训练周期 \n",
    "#milestones = [35,45,55]#多间隔学习率调整\n",
    "milestones = [60,85,95]\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16\n",
    "#加载分割数据集\n",
    "train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "#视频数据处理\n",
    "import os\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Path(object):\n",
    "    @staticmethod\n",
    "    def db_dir(database):\n",
    "        if database == 'ucf101':\n",
    "            #路径包含视频类标签\n",
    "            \n",
    "            root_dir = '/root/autodl-tmp/UCF-101'\n",
    "            #保存结果的输出路径\n",
    "            output_dir = '/root/autodl-tmp/data/data_test/ucf101'\n",
    "            return root_dir,output_dir\n",
    "\n",
    "        elif database == 'hmdb51':\n",
    "            root_dir = 'Path/to/hmdb-51'\n",
    "            #保存结果的输出路径\n",
    "            output_dir = 'Path/to/VAR/hmdb51'\n",
    "            return root_dir,output_dir\n",
    "        else:\n",
    "            print('Database {} not available.'.format(database))\n",
    "            raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def model_dir():\n",
    "        return './model/c3d-pretrained.pth'\n",
    "\n",
    "class VideoDatasetsplit(Dataset):\n",
    "    r\"\"\"A Dataset for a folder of videos. Expects the directory structure to be\n",
    "    directory->[train/val/test]->[class labels]->[videos]. Initializes with a list\n",
    "    of all file names, along with an array of labels, with label being automatically\n",
    "    inferred from the respective folder names.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): Name of dataset. Defaults to 'ucf101'.\n",
    "            split (str): Determines which folder of the directory the dataset will read from. Defaults to 'train'.\n",
    "            clip_len (int): Determines how many frames are there in each clip. Defaults to 16.\n",
    "            preprocess (bool): Determines whether to preprocess dataset. Default is False.\n",
    "    \"\"\"\n",
    "    # 注意第一次要预处理数据的\n",
    "    def __init__(self, dataset='ucf101', split='train', clip_len=16,split_train_name = None,split_test_name = None,preprocess=True):\n",
    "        self.root_dir, self.output_dir = Path.db_dir(dataset)\n",
    "        folder = os.path.join(self.output_dir, split)\n",
    "        self.clip_len = clip_len\n",
    "        self.split = split\n",
    "        self.split_train_name = split_train_name\n",
    "        self.split_test_name = split_test_name\n",
    "\n",
    "        # The following three parameters are chosen as described in the paper section 4.1\n",
    "        self.resize_height = 256\n",
    "        self.resize_width = 340\n",
    "        self.crop_size = 224\n",
    "\n",
    "        if not self.check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You need to download it from official website.')\n",
    "\n",
    "        if (not self.check_preprocess()) or preprocess:\n",
    "            print('Preprocessing of {} dataset, this will take long, but it will be done only once.'.format(dataset))\n",
    "            self.preprocess()\n",
    "\n",
    "        # Obtain all the filenames of files inside all the class folders\n",
    "        # Going through each class folder one at a time\n",
    "        self.fnames, labels = [], []\n",
    "        for label in sorted(os.listdir(folder)):\n",
    "            for fname in os.listdir(os.path.join(folder, label)):\n",
    "                self.fnames.append(os.path.join(folder, label, fname))\n",
    "                labels.append(label)\n",
    "\n",
    "        assert len(labels) == len(self.fnames)\n",
    "        print('Number of {} videos: {:d}'.format(split, len(self.fnames)))\n",
    "\n",
    "        # Prepare a mapping between the label names (strings) and indices (ints)\n",
    "        self.label2index = {label: index for index, label in enumerate(sorted(set(labels)))}\n",
    "        # Convert the list of label names into an array of label indices\n",
    "        self.label_array = np.array([self.label2index[label] for label in labels], dtype=int)\n",
    "\n",
    "        if dataset == \"ucf101\":\n",
    "            if not os.path.exists('ucf_labels.txt'):\n",
    "                with open('ucf_labels.txt', 'w') as f:\n",
    "                    for id, label in enumerate(sorted(self.label2index)):\n",
    "                        f.writelines(str(id+1) + ' ' + label + '\\n')\n",
    "\n",
    "        elif dataset == 'hmdb51':\n",
    "            if not os.path.exists('hmdb_labels.txt'):\n",
    "                with open('hmdb_labels.txt', 'w') as f:\n",
    "                    for id, label in enumerate(sorted(self.label2index)):\n",
    "                        f.writelines(str(id+1) + ' ' + label + '\\n')\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "    #需要重写__getitem__方法\n",
    "    def __getitem__(self, index):\n",
    "        # Loading and preprocessing.\n",
    "        buffer = self.load_frames(self.fnames[index]) #一共有8460个文件夹\n",
    "        buffer = self.crop(buffer, self.clip_len, self.crop_size)\n",
    "        labels = np.array(self.label_array[index])\n",
    "\n",
    "        if self.split == 'test':\n",
    "            # Perform data augmentation\n",
    "            buffer = self.randomflip(buffer)\n",
    "        buffer = self.normalize(buffer)\n",
    "        buffer = self.to_tensor(buffer)\n",
    "        return torch.from_numpy(buffer), torch.from_numpy(labels)\n",
    "\n",
    "    def check_integrity(self):\n",
    "        if not os.path.exists(self.root_dir):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def check_preprocess(self):\n",
    "        # TODO: Check image size in output_dir\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            return False\n",
    "        elif not os.path.exists(os.path.join(self.output_dir, 'train')):\n",
    "            return False\n",
    "        \n",
    "        for ii, video_class in enumerate(os.listdir(os.path.join(self.output_dir, 'train'))):\n",
    "            for video in os.listdir(os.path.join(self.output_dir, 'train', video_class)):\n",
    "                video_name = os.path.join(os.path.join(self.output_dir, 'train', video_class, video),\n",
    "                                    sorted(os.listdir(os.path.join(self.output_dir, 'train', video_class, video)))[0])\n",
    "                image = cv2.imread(video_name)\n",
    "                if np.shape(image)[0] != 256 or np.shape(image)[1] != 340:\n",
    "                    return False\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if ii == 10:\n",
    "                break\n",
    "\n",
    "        return True\n",
    "\n",
    "    def preprocess(self):\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            os.makedirs(os.path.join(self.output_dir, 'train'))\n",
    "            os.makedirs(os.path.join(self.output_dir, 'val'))\n",
    "            #os.makedirs(os.path.join(self.output_dir, 'test'))\n",
    "\n",
    "        # Split train/val sets\n",
    "        for file in os.listdir(self.root_dir):\n",
    "            #file_path = os.path.join(self.root_dir, file)\n",
    "            '''\n",
    "            video_files = [name for name in os.listdir(file_path)]\n",
    "\n",
    "            train, val = train_test_split(video_files, test_size=0.3, random_state=42)#将视频数据划分为70%的训练集和30%的验证集\n",
    "            '''\n",
    "            #train, val = train_test_split(train_and_valid, test_size=0.2, random_state=42)\n",
    "            with open(self.split_train_name) as f:\n",
    "                train = f.readlines()\n",
    "                train = [x.strip('\\r\\n').split(' ')[0].split('/') for x in train]\n",
    "            f.close()    \n",
    "            \n",
    "            with open(self.split_test_name) as l:\n",
    "                val = l.readlines()\n",
    "                val = [x.strip('\\r\\n').split(' ')[0].split('/') for x in val]\n",
    "            l.close()\n",
    "            train_list = []\n",
    "            val_list = []\n",
    "            \n",
    "            for train_name in train:\n",
    "                if file == train_name[0]:\n",
    "                    train_list.append(train_name[1])\n",
    "\n",
    "            for val_name in val:\n",
    "                #判断file_name是否与val_name相同\n",
    "                #val_name_split = val_name.split('_')[1]\n",
    "                if file == val_name[0]:\n",
    "                    val_list.append(val_name[1])\n",
    "\n",
    "\n",
    "            train_dir = os.path.join(self.output_dir, 'train',file)\n",
    "            val_dir = os.path.join(self.output_dir, 'val', file)\n",
    "            #test_dir = os.path.join(self.output_dir, 'test', file)\n",
    "\n",
    "            if not os.path.exists(train_dir):\n",
    "                os.mkdir(train_dir)\n",
    "            if not os.path.exists(val_dir):\n",
    "                os.mkdir(val_dir)\n",
    "            #if not os.path.exists(test_dir):\n",
    "                #os.mkdir(test_dir)\n",
    "\n",
    "            for video in train_list:\n",
    "                self.process_video(video, file, train_dir)\n",
    "\n",
    "            for video in val_list:\n",
    "                self.process_video(video, file, val_dir)\n",
    "\n",
    "            #for video in test:\n",
    "                #self.process_video(video, file, test_dir)\n",
    "\n",
    "        print('Preprocessing finished.')\n",
    "\n",
    "    def process_video(self, video, action_name, save_dir):\n",
    "        # Initialize a VideoCapture object to read video data into a numpy array\n",
    "        video_filename = video.split('.')[0]\n",
    "        if not os.path.exists(os.path.join(save_dir, video_filename)):\n",
    "            os.mkdir(os.path.join(save_dir, video_filename))\n",
    "\n",
    "        capture = cv2.VideoCapture(os.path.join(self.root_dir, action_name, video))\n",
    "\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Make sure splited video has at least 16 frames\n",
    "        EXTRACT_FREQUENCY = 4\n",
    "        if frame_count // EXTRACT_FREQUENCY <= 16:\n",
    "            EXTRACT_FREQUENCY -= 1\n",
    "            if frame_count // EXTRACT_FREQUENCY <= 16:\n",
    "                EXTRACT_FREQUENCY -= 1\n",
    "                if frame_count // EXTRACT_FREQUENCY <= 16:\n",
    "                    EXTRACT_FREQUENCY -= 1\n",
    "\n",
    "        count = 0\n",
    "        i = 0\n",
    "        retaining = True\n",
    "\n",
    "        while (count < frame_count and retaining):\n",
    "            retaining, frame = capture.read()\n",
    "            if frame is None:\n",
    "                continue\n",
    "\n",
    "            if count % EXTRACT_FREQUENCY == 0:\n",
    "                if (frame_height != self.resize_height) or (frame_width != self.resize_width):\n",
    "                    frame = cv2.resize(frame, (self.resize_width, self.resize_height))\n",
    "                cv2.imwrite(filename=os.path.join(save_dir, video_filename, '0000{}.jpg'.format(str(i))), img=frame)\n",
    "                i += 1\n",
    "            count += 1\n",
    "\n",
    "        # Release the VideoCapture once it is no longer needed\n",
    "        capture.release()\n",
    "\n",
    "    def randomflip(self, buffer):\n",
    "        \"\"\"Horizontally flip the given image and ground truth randomly with a probability of 0.5.\"\"\"\n",
    "\n",
    "        if np.random.random() < 0.5:\n",
    "            for i, frame in enumerate(buffer):\n",
    "                frame = cv2.flip(buffer[i], flipCode=1)\n",
    "                buffer[i] = cv2.flip(frame, flipCode=1)\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    def normalize(self, buffer):\n",
    "        for i, frame in enumerate(buffer):\n",
    "            frame -= np.array([[[90.0, 98.0, 102.0]]])\n",
    "            buffer[i] = frame\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    def to_tensor(self, buffer):\n",
    "        return buffer.transpose((3, 0, 1, 2))\n",
    "\n",
    "    def load_frames(self, file_dir):\n",
    "        frames = sorted([os.path.join(file_dir, img) for img in os.listdir(file_dir)])\n",
    "        frame_count = len(frames)\n",
    "        buffer = np.empty((frame_count,self.resize_height, self.resize_width,3), np.dtype('float32'))\n",
    "        for i, frame_name in enumerate(frames):\n",
    "            frame = np.array(cv2.imread(frame_name)).astype(np.float64)\n",
    "            buffer[i] = frame\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    def crop(self, buffer, clip_len, crop_size):\n",
    "        # randomly select time index for temporal jittering\n",
    "        time_index = np.random.randint(buffer.shape[0] - clip_len)\n",
    "\n",
    "        # Randomly select start indices in order to crop the video\n",
    "        height_index = np.random.randint(buffer.shape[1] - crop_size)\n",
    "        width_index = np.random.randint(buffer.shape[2] - crop_size)\n",
    "\n",
    "        # Crop and jitter the video using indexing. The spatial crop is performed on\n",
    "        # the entire array, so each frame is cropped in the same location. The temporal\n",
    "        # jitter takes place via the selection of consecutive frames\n",
    "        buffer = buffer[time_index:time_index + clip_len,\n",
    "                 height_index:height_index + crop_size,\n",
    "                 width_index:width_index + crop_size,:]\n",
    "\n",
    "        return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train videos: 9537\n",
      "Number of val videos: 3783\n"
     ]
    }
   ],
   "source": [
    "dataset = 'ucf101'\n",
    "trainlist = '/root/autodl-tmp/ucfTrainTestlist/trainlist01.txt'\n",
    "testlist = '/root/autodl-tmp/ucfTrainTestlist/testlist01.txt'\n",
    "batch_size = 16\n",
    "#加载分割数据集\n",
    "train_dataloader_split1 = DataLoader(VideoDatasetsplit(dataset = dataset,split = 'train',clip_len = 8,split_train_name = trainlist,split_test_name = testlist,preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "val_dataloader_split1 = DataLoader(VideoDatasetsplit(dataset = dataset,split = 'val',clip_len = 8,preprocess = False),batch_size = batch_size,num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 2.2955, train acc 0.441, test acc 0.326, time 1354.1 sec\n",
      "epoch 2, loss 0.5654, train acc 0.686, test acc 0.510, time 1358.1 sec\n",
      "epoch 3, loss 0.2208, train acc 0.805, test acc 0.564, time 1354.5 sec\n",
      "epoch 4, loss 0.1219, train acc 0.856, test acc 0.615, time 1460.5 sec\n",
      "epoch 5, loss 0.0769, train acc 0.888, test acc 0.639, time 1551.2 sec\n",
      "epoch 6, loss 0.0486, train acc 0.920, test acc 0.679, time 1608.7 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlcfull_block添加到res1块中的模型\n",
    "save_path = 'net'#添加断点保存路径\n",
    "\n",
    "milestones = [20]#设置多间隔学习率调整\n",
    "num_epochs = 40\n",
    "lr = 0.01\n",
    "#batch_size = 8 \n",
    "#加载分割数据集 \n",
    "#train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "#val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_dataloader_split1,val_dataloader_split1,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 3.6580, train acc 0.241, test acc 0.472, time 1889.7 sec\n",
      "epoch 2, loss 1.1851, train acc 0.540, test acc 0.563, time 1857.6 sec\n",
      "epoch 3, loss 0.6014, train acc 0.650, test acc 0.572, time 1873.6 sec\n",
      "epoch 4, loss 0.3740, train acc 0.702, test acc 0.609, time 1861.7 sec\n",
      "epoch 5, loss 0.2624, train acc 0.733, test acc 0.609, time 1855.9 sec\n",
      "epoch 6, loss 0.1921, train acc 0.765, test acc 0.636, time 1850.6 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#batch_size = 8 \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#加载分割数据集 \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnlcnet_13\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader_split1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader_split1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmilestones\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, train_dataloader, test_dataloader, milestones, batch_size, device, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     40\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 42\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     44\u001b[0m train_l_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#训练将nlcfull_block添加到res1块中的模型\n",
    "save_path = 'nlcnet_13_split'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "#batch_size = 8 \n",
    "#加载分割数据集 \n",
    "#train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "#val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(nlcnet_13,lr,train_dataloader_split1,val_dataloader_split1,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 3.6526, train acc 0.249, test acc 0.444, time 1594.9 sec\n"
     ]
    }
   ],
   "source": [
    "#训练将nlcfull_block添加到res1块中的模型\n",
    "save_path = 'net_'#添加断点保存路径\n",
    "\n",
    "milestones = [60,85,95]#设置多间隔学习率调整\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "#batch_size = 8 \n",
    "#加载分割数据集 \n",
    "#train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "#val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_dataloader_split1,val_dataloader_split1,milestones,batch_size,device,num_epochs,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        \"\"\"\n",
    "        Warning: does not synchronize the deque!\n",
    "        \"\"\"\n",
    "        if not is_dist_avail_and_initialized():\n",
    "            return\n",
    "        t = torch.tensor([self.count, self.sum],\n",
    "                         dtype=torch.float64, device='cuda')\n",
    "        dist.barrier()\n",
    "        dist.all_reduce(t)\n",
    "        t = t.tolist()\n",
    "        self.count = int(t[0])\n",
    "        self.sum = t[1]\n",
    "        self.avg = self.sum / (self.count + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算模型的flops\n",
    "def print_model_parm_flops(model, frame=16):\n",
    "\n",
    "    prods = {}\n",
    "\n",
    "    def save_hook(name):\n",
    "        def hook_per(self, input, output):\n",
    "                # print 'flops:{}'.format(self.__class__.__name__)\n",
    "                # print 'input:{}'.format(input)\n",
    "                # print '_dim:{}'.format(input[0].dim())\n",
    "                # print 'input_shape:{}'.format(np.prod(input[0].shape))\n",
    "                # prods.append(np.prod(input[0].shape))\n",
    "            prods[name] = np.prod(input[0].shape)\n",
    "            # prods.append(np.prod(input[0].shape))\n",
    "\n",
    "        return hook_per\n",
    "\n",
    "    list_1 = []\n",
    "\n",
    "    def simple_hook(self, input, output):\n",
    "        list_1.append(np.prod(input[0].shape))\n",
    "\n",
    "    list_2 = {}\n",
    "\n",
    "    def simple_hook2(self, input, output):\n",
    "        list_2['names'] = np.prod(input[0].shape)\n",
    "\n",
    "    multiply_adds = False\n",
    "    list_conv = []\n",
    "\n",
    "    def conv_hook(self, input, output):\n",
    "        batch_size, input_channels, time_stride, input_height, input_width = input[0].size(\n",
    "        )\n",
    "        output_channels, out_time, output_height, output_width = output[0].size(\n",
    "        )\n",
    "\n",
    "        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * self.kernel_size[2] * (\n",
    "            self.in_channels / self.groups) * (2 if multiply_adds else 1)\n",
    "        bias_ops = 1 if self.bias is not None else 0\n",
    "\n",
    "        params = output_channels * (kernel_ops + bias_ops)\n",
    "        flops = batch_size * params * output_height * output_width * out_time\n",
    "\n",
    "        list_conv.append(flops)\n",
    "\n",
    "    list_linear = []\n",
    "\n",
    "    def linear_hook(self, input, output):\n",
    "        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n",
    "\n",
    "        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n",
    "        bias_ops = self.bias.nelement()\n",
    "\n",
    "        flops = batch_size * (weight_ops + bias_ops)\n",
    "        list_linear.append(flops)\n",
    "\n",
    "    list_bn = []\n",
    "\n",
    "    def bn_hook(self, input, output):\n",
    "        list_bn.append(input[0].nelement())\n",
    "\n",
    "    list_relu = []\n",
    "\n",
    "    def relu_hook(self, input, output):\n",
    "        list_relu.append(input[0].nelement())\n",
    "\n",
    "    list_pooling = []\n",
    "\n",
    "    def pooling_hook(self, input, output):\n",
    "        batch_size, input_channels, time_stride, input_height, input_width = input[0].size(\n",
    "        )\n",
    "        output_channels, out_time, output_height, output_width = output[0].size(\n",
    "        )\n",
    "\n",
    "        kernel_ops = self.kernel_size[0] * \\\n",
    "            self.kernel_size[1] * self.kernel_size[2]\n",
    "        bias_ops = 0\n",
    "        params = output_channels * (kernel_ops + bias_ops)\n",
    "        flops = batch_size * params * output_height * output_width * out_time\n",
    "\n",
    "        list_pooling.append(flops)\n",
    "\n",
    "    def foo(net):\n",
    "        childrens = list(net.children())\n",
    "        if not childrens:\n",
    "            if isinstance(net, torch.nn.Conv3d):\n",
    "                    # net.register_forward_hook(save_hook(net.__class__.__name__))\n",
    "                    # net.register_forward_hook(simple_hook)\n",
    "                    # net.register_forward_hook(simple_hook2)\n",
    "                net.register_forward_hook(conv_hook)\n",
    "            if isinstance(net, torch.nn.Linear):\n",
    "                net.register_forward_hook(linear_hook)\n",
    "            if isinstance(net, torch.nn.BatchNorm3d):\n",
    "                net.register_forward_hook(bn_hook)\n",
    "            if isinstance(net, torch.nn.ReLU):\n",
    "                net.register_forward_hook(relu_hook)\n",
    "            if isinstance(\n",
    "                    net, torch.nn.MaxPool3d) or isinstance(\n",
    "                    net, torch.nn.AvgPool3d):\n",
    "                net.register_forward_hook(pooling_hook)\n",
    "            return\n",
    "        for c in childrens:\n",
    "            foo(c)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    model = model\n",
    "\n",
    "    foo(model)\n",
    "    input = Variable(torch.rand(1, 3, frame, 224, 224), requires_grad=True)\n",
    "    out = model(input)\n",
    "\n",
    "    total_flops = (\n",
    "        sum(list_conv) +\n",
    "        sum(list_linear) +\n",
    "        sum(list_bn) +\n",
    "        sum(list_relu) +\n",
    "        sum(list_pooling))\n",
    "\n",
    "    print('  + Number of FLOPs: %.2fG' % (total_flops / 1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  + Number of FLOPs: 65.75G\n"
     ]
    }
   ],
   "source": [
    "print_model_parm_flops(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from timm.utils import accuracy, AverageMeter, ModelEma\n",
    "def evaluate_accuracy1(data_iter, net,device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    criterion_val = nn.CrossEntropyLoss()\n",
    "    #acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(data_iter):\n",
    "            X = data[0]\n",
    "            y = data[1]\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                #acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                l = criterion_val(net(X),y)\n",
    "                #计算top1和top5准确率\n",
    "                prec1,prec5 = accuracy(net(X),y,topk=(1,5))\n",
    "                top5.update(prec5.cpu().item(),X.size(0))\n",
    "                losses.update(l.cpu().item(),X.size(0))\n",
    "                top1.update(prec1.cpu().item(),X.size(0))\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    #acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item()\n",
    "                    #X,y = X.to(device),y.to(device)\n",
    "                    l = criterion_val(net(X,is_training=False),y)\n",
    "                    #计算top1和top5准确率\n",
    "                    prec1,prec5 = accuracy(net(X,is_training=False),y,topk=(1,5))\n",
    "                    top5.update(prec5.item(),X.size(0))\n",
    "                    losses.update(l.item(),X.size(0))\n",
    "                    top1.update(prec1.item(),X.size(0)) \n",
    "                else:\n",
    "                    #acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "                    # X,y = X.to(device),y.to(device)\n",
    "                    l = criterion_val(net(X),y)\n",
    "                    #计算top1和top5准确率\n",
    "                    prec1,prec5 = accuracy(net(X),y,topk=(1,5))\n",
    "                    top5.update(prec5.item(),X.size(0))\n",
    "                    losses.update(l.item(),X.size(0))\n",
    "                    top1.update(prec1.item(),X.size(0)) \n",
    "        \n",
    "        acc1 = top1.avg\n",
    "        acc5 = top5.avg\n",
    "        ave_loss = losses.avg\n",
    "    return acc1,acc5,ave_loss\n",
    "\n",
    "def train1(net,lr,train_dataloader, test_dataloader,milestones,batch_size, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    print(\"training on \",device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.CrossEntropyLoss()#交叉熵损失函数\n",
    "    optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9,weight_decay=5e-4)#动量设置为0.9，权重衰减5e-4\n",
    "    #shceduler = optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)\n",
    "    shceduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones,gamma=0.1)#多间隔学习率调整\n",
    "\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for i,data in enumerate(train_dataloader):\n",
    "            X = data[0]\n",
    "            y = data[1]\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #计算top1和top5准确率\n",
    "            prec1,prec5 = accuracy(y_hat,y,topk=(1,5))\n",
    "            top5.update(prec5.item(),X.size(0))\n",
    "            losses.update(l.item(),X.size(0))\n",
    "            top1.update(prec1.item(),X.size(0))\n",
    "            #train_l_sum += l.cpu().item()\n",
    "            #train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            #n += y.shape[0]\n",
    "            #batch_count += 1\n",
    "        ave_loss = losses.avg\n",
    "        train_acc1 = top1.avg\n",
    "        train_acc5 = top5.avg\n",
    "        shceduler.step()        \n",
    "        test_acc1,test_acc5,test_loss = evaluate_accuracy1(test_dataloader,net)\n",
    "        print('epoch %d, loss %.4f, train_top1 acc %.3f,train_top5 acc %.3f , test_losses %.4f,test acc1 %.3f, test acc5 %.3f,time %.1f sec'\n",
    "              % (epoch + 1, ave_loss,train_acc1 ,train_acc5 , test_loss,test_acc1, test_acc5 , time.time() - start))\n",
    "        #print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              #% (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 3.5439, train_top1 acc 17.447,train_top5 acc 39.232 , test_losses 2.8372,test acc1 35.653, test acc5 69.789,time 1541.4 sec\n",
      "epoch 2, loss 2.7813, train_top1 acc 31.838,train_top5 acc 58.038 , test_losses 1.5754,test acc1 58.238, test acc5 84.783,time 1543.6 sec\n",
      "epoch 3, loss 2.3247, train_top1 acc 41.525,train_top5 acc 67.900 , test_losses 1.2325,test acc1 66.679, test acc5 91.262,time 1548.4 sec\n",
      "epoch 4, loss 2.0165, train_top1 acc 48.508,train_top5 acc 74.001 , test_losses 1.4680,test acc1 63.162, test acc5 89.930,time 1532.0 sec\n",
      "epoch 5, loss 1.8000, train_top1 acc 53.400,train_top5 acc 78.066 , test_losses 0.8108,test acc1 76.564, test acc5 95.742,time 1533.3 sec\n",
      "epoch 6, loss 1.6300, train_top1 acc 57.236,train_top5 acc 80.989 , test_losses 0.8695,test acc1 76.675, test acc5 95.631,time 1522.2 sec\n",
      "epoch 7, loss 1.4946, train_top1 acc 60.446,train_top5 acc 83.207 , test_losses 0.6669,test acc1 80.341, test acc5 96.853,time 1527.8 sec\n",
      "epoch 8, loss 1.3823, train_top1 acc 63.211,train_top5 acc 84.966 , test_losses 0.6140,test acc1 81.636, test acc5 96.742,time 1554.8 sec\n",
      "epoch 9, loss 1.2895, train_top1 acc 65.544,train_top5 acc 86.375 , test_losses 0.5920,test acc1 83.562, test acc5 97.075,time 1550.8 sec\n",
      "epoch 10, loss 1.2081, train_top1 acc 67.589,train_top5 acc 87.569 , test_losses 0.7064,test acc1 81.155, test acc5 97.334,time 1582.6 sec\n",
      "epoch 11, loss 1.1159, train_top1 acc 70.095,train_top5 acc 88.650 , test_losses 0.1996,test acc1 94.632, test acc5 99.297,time 1580.1 sec\n",
      "epoch 12, loss 1.0319, train_top1 acc 72.387,train_top5 acc 89.581 , test_losses 0.1928,test acc1 94.928, test acc5 99.408,time 1571.1 sec\n",
      "epoch 13, loss 0.9599, train_top1 acc 74.338,train_top5 acc 90.369 , test_losses 0.1625,test acc1 95.705, test acc5 99.445,time 1564.8 sec\n",
      "epoch 14, loss 0.8969, train_top1 acc 76.048,train_top5 acc 91.053 , test_losses 0.1526,test acc1 95.742, test acc5 99.593,time 1560.8 sec\n",
      "epoch 15, loss 0.8421, train_top1 acc 77.536,train_top5 acc 91.639 , test_losses 0.1427,test acc1 96.150, test acc5 99.519,time 1563.2 sec\n",
      "epoch 16, loss 0.7937, train_top1 acc 78.851,train_top5 acc 92.158 , test_losses 0.1403,test acc1 96.335, test acc5 99.556,time 1571.4 sec\n",
      "epoch 17, loss 0.7506, train_top1 acc 80.029,train_top5 acc 92.615 , test_losses 0.1364,test acc1 96.187, test acc5 99.519,time 1555.8 sec\n",
      "epoch 18, loss 0.7123, train_top1 acc 81.068,train_top5 acc 93.020 , test_losses 0.1294,test acc1 96.409, test acc5 99.556,time 1560.6 sec\n",
      "epoch 19, loss 0.6777, train_top1 acc 82.013,train_top5 acc 93.383 , test_losses 0.1310,test acc1 96.446, test acc5 99.482,time 1586.8 sec\n",
      "epoch 20, loss 0.6463, train_top1 acc 82.865,train_top5 acc 93.713 , test_losses 0.1382,test acc1 96.076, test acc5 99.371,time 1581.3 sec\n",
      "epoch 21, loss 0.6179, train_top1 acc 83.637,train_top5 acc 94.011 , test_losses 0.1275,test acc1 96.224, test acc5 99.630,time 1578.3 sec\n",
      "epoch 22, loss 0.5920, train_top1 acc 84.342,train_top5 acc 94.283 , test_losses 0.1228,test acc1 96.594, test acc5 99.519,time 1541.9 sec\n",
      "epoch 23, loss 0.5682, train_top1 acc 84.993,train_top5 acc 94.531 , test_losses 0.1347,test acc1 96.372, test acc5 99.482,time 1532.1 sec\n",
      "epoch 24, loss 0.5463, train_top1 acc 85.596,train_top5 acc 94.757 , test_losses 0.1175,test acc1 96.742, test acc5 99.556,time 1525.5 sec\n",
      "epoch 25, loss 0.5261, train_top1 acc 86.147,train_top5 acc 94.966 , test_losses 0.1249,test acc1 96.631, test acc5 99.519,time 1529.7 sec\n",
      "epoch 26, loss 0.5075, train_top1 acc 86.649,train_top5 acc 95.159 , test_losses 0.1301,test acc1 96.631, test acc5 99.445,time 1528.7 sec\n",
      "epoch 27, loss 0.4903, train_top1 acc 87.119,train_top5 acc 95.337 , test_losses 0.1265,test acc1 96.446, test acc5 99.630,time 1520.9 sec\n",
      "epoch 28, loss 0.4744, train_top1 acc 87.554,train_top5 acc 95.502 , test_losses 0.1294,test acc1 96.557, test acc5 99.482,time 1522.5 sec\n",
      "epoch 29, loss 0.4595, train_top1 acc 87.957,train_top5 acc 95.656 , test_losses 0.1286,test acc1 96.335, test acc5 99.519,time 1548.0 sec\n",
      "epoch 30, loss 0.4457, train_top1 acc 88.330,train_top5 acc 95.799 , test_losses 0.1316,test acc1 96.372, test acc5 99.482,time 1519.5 sec\n"
     ]
    }
   ],
   "source": [
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train1(net0,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 3.6167, train_top1 acc 15.957,train_top5 acc 38.097 , test_losses 3.3975,test acc1 29.782, test acc5 63.918,time 1349.4 sec\n",
      "epoch 2, loss 2.8014, train_top1 acc 31.637,train_top5 acc 57.766 , test_losses 1.7829,test acc1 54.840, test acc5 83.326,time 1307.2 sec\n",
      "epoch 3, loss 2.3344, train_top1 acc 41.229,train_top5 acc 67.664 , test_losses 1.5110,test acc1 65.030, test acc5 89.069,time 1319.1 sec\n",
      "epoch 4, loss 2.0200, train_top1 acc 48.162,train_top5 acc 73.777 , test_losses 1.0269,test acc1 72.487, test acc5 93.562,time 1310.2 sec\n",
      "epoch 5, loss 1.8031, train_top1 acc 53.165,train_top5 acc 77.785 , test_losses 0.9812,test acc1 73.460, test acc5 94.071,time 1309.6 sec\n",
      "epoch 6, loss 1.6308, train_top1 acc 57.268,train_top5 acc 80.758 , test_losses 0.7493,test acc1 79.805, test acc5 95.739,time 1310.2 sec\n",
      "epoch 7, loss 1.4939, train_top1 acc 60.566,train_top5 acc 83.019 , test_losses 0.6080,test acc1 82.770, test acc5 97.314,time 1306.8 sec\n",
      "epoch 8, loss 1.3850, train_top1 acc 63.205,train_top5 acc 84.780 , test_losses 0.6819,test acc1 81.056, test acc5 97.128,time 1293.3 sec\n",
      "epoch 9, loss 1.2941, train_top1 acc 65.427,train_top5 acc 86.210 , test_losses 1.4007,test acc1 70.125, test acc5 92.774,time 1308.2 sec\n",
      "epoch 10, loss 1.2129, train_top1 acc 67.478,train_top5 acc 87.382 , test_losses 0.5568,test acc1 85.178, test acc5 97.684,time 1307.9 sec\n",
      "epoch 11, loss 1.1189, train_top1 acc 70.001,train_top5 acc 88.492 , test_losses 0.2452,test acc1 93.654, test acc5 98.842,time 1307.6 sec\n",
      "epoch 12, loss 1.0350, train_top1 acc 72.270,train_top5 acc 89.432 , test_losses 0.2137,test acc1 93.886, test acc5 98.935,time 1304.9 sec\n",
      "epoch 13, loss 0.9629, train_top1 acc 74.254,train_top5 acc 90.236 , test_losses 0.1721,test acc1 95.044, test acc5 99.213,time 1306.2 sec\n",
      "epoch 14, loss 0.9000, train_top1 acc 75.977,train_top5 acc 90.927 , test_losses 0.1787,test acc1 95.229, test acc5 99.213,time 1314.9 sec\n",
      "epoch 15, loss 0.8447, train_top1 acc 77.485,train_top5 acc 91.529 , test_losses 0.1762,test acc1 95.183, test acc5 99.213,time 1326.4 sec\n",
      "epoch 16, loss 0.7962, train_top1 acc 78.805,train_top5 acc 92.055 , test_losses 0.1655,test acc1 95.183, test acc5 99.352,time 1326.5 sec\n",
      "epoch 17, loss 0.7529, train_top1 acc 79.984,train_top5 acc 92.518 , test_losses 0.1782,test acc1 95.322, test acc5 99.398,time 1328.7 sec\n",
      "epoch 18, loss 0.7144, train_top1 acc 81.037,train_top5 acc 92.928 , test_losses 0.1429,test acc1 96.063, test acc5 99.352,time 1327.0 sec\n",
      "epoch 19, loss 0.6797, train_top1 acc 81.981,train_top5 acc 93.297 , test_losses 0.1592,test acc1 95.692, test acc5 99.259,time 1328.6 sec\n",
      "epoch 20, loss 0.6484, train_top1 acc 82.838,train_top5 acc 93.631 , test_losses 0.1488,test acc1 95.600, test acc5 99.398,time 1336.3 sec\n",
      "epoch 21, loss 0.6199, train_top1 acc 83.614,train_top5 acc 93.933 , test_losses 0.1505,test acc1 95.831, test acc5 99.444,time 1345.4 sec\n",
      "epoch 22, loss 0.5939, train_top1 acc 84.326,train_top5 acc 94.206 , test_losses 0.1400,test acc1 96.017, test acc5 99.537,time 1343.4 sec\n",
      "epoch 23, loss 0.5700, train_top1 acc 84.977,train_top5 acc 94.458 , test_losses 0.1510,test acc1 95.924, test acc5 99.120,time 1340.8 sec\n",
      "epoch 24, loss 0.5481, train_top1 acc 85.577,train_top5 acc 94.688 , test_losses 0.1519,test acc1 95.553, test acc5 99.398,time 1342.9 sec\n",
      "epoch 25, loss 0.5280, train_top1 acc 86.128,train_top5 acc 94.898 , test_losses 0.1360,test acc1 95.924, test acc5 99.398,time 1341.6 sec\n",
      "epoch 26, loss 0.5096, train_top1 acc 86.624,train_top5 acc 95.094 , test_losses 0.1453,test acc1 95.646, test acc5 99.352,time 1320.2 sec\n",
      "epoch 27, loss 0.4923, train_top1 acc 87.098,train_top5 acc 95.276 , test_losses 0.1427,test acc1 96.341, test acc5 99.352,time 1329.5 sec\n",
      "epoch 28, loss 0.4763, train_top1 acc 87.535,train_top5 acc 95.443 , test_losses 0.1450,test acc1 96.017, test acc5 99.259,time 1347.7 sec\n",
      "epoch 29, loss 0.4615, train_top1 acc 87.941,train_top5 acc 95.599 , test_losses 0.1536,test acc1 95.878, test acc5 99.213,time 1363.5 sec\n",
      "epoch 30, loss 0.4476, train_top1 acc 88.321,train_top5 acc 95.745 , test_losses 0.1539,test acc1 95.785, test acc5 99.305,time 1350.9 sec\n"
     ]
    }
   ],
   "source": [
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train1(net0,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 3.8193, train_top1 acc 11.678,train_top5 acc 31.442 , test_losses 2.7138,test acc1 31.681, test acc5 62.205,time 1421.5 sec\n",
      "epoch 2, loss 3.0486, train_top1 acc 25.573,train_top5 acc 51.283 , test_losses 2.3755,test acc1 47.244, test acc5 73.830,time 1423.1 sec\n",
      "epoch 3, loss 2.5574, train_top1 acc 35.934,train_top5 acc 62.407 , test_losses 117.2748,test acc1 6.577, test acc5 13.895,time 1413.7 sec\n",
      "epoch 4, loss 2.2282, train_top1 acc 43.180,train_top5 acc 69.309 , test_losses 1.1232,test acc1 68.180, test acc5 92.543,time 1416.0 sec\n",
      "epoch 5, loss 1.9814, train_top1 acc 48.872,train_top5 acc 74.097 , test_losses 0.8413,test acc1 77.165, test acc5 95.137,time 1422.5 sec\n",
      "epoch 6, loss 1.7922, train_top1 acc 53.245,train_top5 acc 77.638 , test_losses 0.8128,test acc1 78.648, test acc5 95.739,time 1413.9 sec\n",
      "epoch 7, loss 1.6438, train_top1 acc 56.763,train_top5 acc 80.253 , test_losses 0.7935,test acc1 80.454, test acc5 95.739,time 1412.4 sec\n",
      "epoch 8, loss 1.5199, train_top1 acc 59.781,train_top5 acc 82.296 , test_losses 0.7490,test acc1 79.944, test acc5 96.619,time 1412.8 sec\n",
      "epoch 9, loss 1.4176, train_top1 acc 62.281,train_top5 acc 83.973 , test_losses 0.8794,test acc1 77.953, test acc5 95.368,time 1392.1 sec\n",
      "epoch 10, loss 1.3301, train_top1 acc 64.449,train_top5 acc 85.339 , test_losses 0.6630,test acc1 81.797, test acc5 96.989,time 1376.4 sec\n",
      "epoch 11, loss 1.2282, train_top1 acc 67.177,train_top5 acc 86.632 , test_losses 0.2286,test acc1 94.349, test acc5 99.305,time 1376.9 sec\n",
      "epoch 12, loss 1.1357, train_top1 acc 69.686,train_top5 acc 87.733 , test_losses 0.2054,test acc1 94.535, test acc5 99.213,time 1376.0 sec\n",
      "epoch 13, loss 1.0561, train_top1 acc 71.845,train_top5 acc 88.664 , test_losses 0.1861,test acc1 94.812, test acc5 99.444,time 1377.5 sec\n",
      "epoch 14, loss 0.9874, train_top1 acc 73.704,train_top5 acc 89.464 , test_losses 0.1736,test acc1 95.924, test acc5 99.305,time 1379.4 sec\n",
      "epoch 15, loss 0.9270, train_top1 acc 75.336,train_top5 acc 90.159 , test_losses 0.1781,test acc1 94.998, test acc5 99.398,time 1377.7 sec\n",
      "epoch 16, loss 0.8734, train_top1 acc 76.791,train_top5 acc 90.773 , test_losses 0.1654,test acc1 95.878, test acc5 99.491,time 1380.1 sec\n",
      "epoch 17, loss 0.8260, train_top1 acc 78.082,train_top5 acc 91.310 , test_losses 0.1634,test acc1 95.646, test acc5 99.398,time 1380.2 sec\n",
      "epoch 18, loss 0.7834, train_top1 acc 79.243,train_top5 acc 91.791 , test_losses 0.1606,test acc1 95.692, test acc5 99.444,time 1382.2 sec\n",
      "epoch 19, loss 0.7449, train_top1 acc 80.287,train_top5 acc 92.223 , test_losses 0.1509,test acc1 96.295, test acc5 99.398,time 1377.6 sec\n",
      "epoch 20, loss 0.7104, train_top1 acc 81.218,train_top5 acc 92.611 , test_losses 0.1559,test acc1 95.600, test acc5 99.444,time 1377.1 sec\n",
      "epoch 21, loss 0.6792, train_top1 acc 82.063,train_top5 acc 92.962 , test_losses 0.1503,test acc1 96.202, test acc5 99.398,time 1375.3 sec\n",
      "epoch 22, loss 0.6505, train_top1 acc 82.845,train_top5 acc 93.281 , test_losses 0.1383,test acc1 96.387, test acc5 99.398,time 1374.6 sec\n",
      "epoch 23, loss 0.6244, train_top1 acc 83.553,train_top5 acc 93.571 , test_losses 0.1380,test acc1 96.480, test acc5 99.444,time 1374.8 sec\n",
      "epoch 24, loss 0.6005, train_top1 acc 84.196,train_top5 acc 93.838 , test_losses 0.1577,test acc1 95.970, test acc5 99.259,time 1375.0 sec\n",
      "epoch 25, loss 0.5785, train_top1 acc 84.798,train_top5 acc 94.084 , test_losses 0.1469,test acc1 96.109, test acc5 99.398,time 1382.2 sec\n",
      "epoch 26, loss 0.5581, train_top1 acc 85.351,train_top5 acc 94.309 , test_losses 0.1496,test acc1 96.156, test acc5 99.352,time 1387.4 sec\n",
      "epoch 27, loss 0.5392, train_top1 acc 85.862,train_top5 acc 94.518 , test_losses 0.1433,test acc1 96.202, test acc5 99.491,time 1384.8 sec\n",
      "epoch 28, loss 0.5215, train_top1 acc 86.339,train_top5 acc 94.713 , test_losses 0.1409,test acc1 96.526, test acc5 99.491,time 1386.9 sec\n",
      "epoch 29, loss 0.5052, train_top1 acc 86.780,train_top5 acc 94.895 , test_losses 0.1435,test acc1 96.295, test acc5 99.491,time 1386.0 sec\n",
      "epoch 30, loss 0.4900, train_top1 acc 87.191,train_top5 acc 95.064 , test_losses 0.1465,test acc1 96.295, test acc5 99.444,time 1386.1 sec\n"
     ]
    }
   ],
   "source": [
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train1(net3,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train(net0,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def validate(val_loader,model,writer,device,epoch):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #模型进入评估模式\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,(X,y) in enumerate(val_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat,y)\n",
    "            prec1,prec5 = accuracy(y_hat,y,topk=(1,5))\n",
    "            top5.update(prec5.item(),X.size(0))\n",
    "            losses.update(loss.item(),X.size(0))\n",
    "            top1.update(prec1.item(),X.size(0))\n",
    "\n",
    "    test_top1 = top1.avg\n",
    "    test_loss = losses.avg\n",
    "    test_top5 = top5.avg\n",
    "    \n",
    "    if is_main_process():\n",
    "        writer.add_scalar('Test/loss',test_loss,epoch)\n",
    "        writer.add_scalar('Test/top1',test_top1,epoch)\n",
    "        \n",
    "    return test_top1,test_loss,test_top5\n",
    "\n",
    "def train_model(model,lr,train_dataloader,val_dataloader,milestones,batch_size, device, num_epochs):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    print('training on ',device)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    writer = SummaryWriter('log')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.CrossEntropyLoss()#交叉熵损失函数\n",
    "    optimizer = optim.SGD(model.parameters(),lr=lr,momentum=0.9,weight_decay=5e-4)#动量设置为0.9，权重衰减5e-4\n",
    "    #shceduler = optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)\n",
    "    shceduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones,gamma=0.1)#多间隔学习率调整\n",
    "    for epoch in range(num_epochs):\n",
    "        strat = time.time()\n",
    "        model.train()\n",
    "        for i,(X,y) in enumerate(train_dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat,y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            prec1,prec5 = accuracy(y_hat,y,topk=(1,5))\n",
    "            top5.update(prec5.item(),X.size(0))\n",
    "            losses.update(loss.item(),X.size(0))\n",
    "            top1.update(prec1.item(),X.size(0))\n",
    "\n",
    "        train_top1 = top1.avg\n",
    "        train_loss = losses.avg\n",
    "        train_top5 = top5.avg\n",
    "        \n",
    "        end = time.time() - strat\n",
    "        \n",
    "        if is_main_process():\n",
    "            writer.add_scalar('Train/loss',train_loss,epoch)\n",
    "            writer.add_scalar('Train/top1',train_top1,epoch)\n",
    "            writer.add_scalar('Train/lr',optimizer.param_groups[-1]['lr'],epoch)\n",
    "        \n",
    "        shceduler.step()\n",
    "        test_top1,test_loss,test_top5 = validate(val_dataloader,model,writer,device,epoch)\n",
    "        \n",
    "        print('epoch %d,loss %.4f,train_top1 %.1f,train_top5 %.1f,test_loss %.4f,test_top1 %.1f,test_top5 %.1f,time %.1f sec'\n",
    "                    % (epoch + 1, train_loss,train_top1 ,train_top5,test_loss,test_top1,test_top5,end))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1,loss 3.2241,train_top1 24.0,train_top5 49.9,test_loss 2.0140,test_top1 47.3,test_top5 79.6,time 1228.7 sec\n",
      "epoch 2,loss 2.5061,train_top1 37.7,train_top5 65.7,test_loss 2.0011,test_top1 54.8,test_top5 82.8,time 1232.5 sec\n",
      "epoch 3,loss 2.1011,train_top1 46.3,train_top5 73.7,test_loss 1.1556,test_top1 69.3,test_top5 92.3,time 1228.5 sec\n",
      "epoch 4,loss 1.8385,train_top1 52.2,train_top5 78.4,test_loss 1.1716,test_top1 70.2,test_top5 92.5,time 1233.0 sec\n",
      "epoch 5,loss 1.6430,train_top1 56.8,train_top5 81.7,test_loss 0.9888,test_top1 74.7,test_top5 94.3,time 1230.9 sec\n",
      "epoch 6,loss 1.4923,train_top1 60.4,train_top5 84.1,test_loss 0.6981,test_top1 80.6,test_top5 97.4,time 1233.2 sec\n",
      "epoch 7,loss 1.3701,train_top1 63.4,train_top5 85.9,test_loss 0.7054,test_top1 80.3,test_top5 96.3,time 1228.8 sec\n",
      "epoch 8,loss 1.2684,train_top1 65.9,train_top5 87.4,test_loss 0.7038,test_top1 81.7,test_top5 96.0,time 1191.7 sec\n",
      "epoch 9,loss 1.1852,train_top1 68.0,train_top5 88.5,test_loss 0.8032,test_top1 78.7,test_top5 95.5,time 1174.6 sec\n",
      "epoch 10,loss 1.1150,train_top1 69.8,train_top5 89.5,test_loss 0.6545,test_top1 83.8,test_top5 97.0,time 1181.3 sec\n",
      "epoch 11,loss 1.0304,train_top1 72.1,train_top5 90.4,test_loss 0.2254,test_top1 93.6,test_top5 99.4,time 1181.9 sec\n",
      "epoch 12,loss 0.9536,train_top1 74.2,train_top5 91.2,test_loss 0.1831,test_top1 94.7,test_top5 99.3,time 1177.9 sec\n",
      "epoch 13,loss 0.8871,train_top1 76.0,train_top5 91.8,test_loss 0.1767,test_top1 94.8,test_top5 99.5,time 1184.3 sec\n",
      "epoch 14,loss 0.8296,train_top1 77.6,train_top5 92.4,test_loss 0.1741,test_top1 95.1,test_top5 99.3,time 1181.5 sec\n",
      "epoch 15,loss 0.7787,train_top1 79.0,train_top5 92.9,test_loss 0.1468,test_top1 96.1,test_top5 99.5,time 1181.9 sec\n",
      "epoch 16,loss 0.7338,train_top1 80.3,train_top5 93.4,test_loss 0.1379,test_top1 96.4,test_top5 99.5,time 1179.1 sec\n",
      "epoch 17,loss 0.6941,train_top1 81.4,train_top5 93.8,test_loss 0.1439,test_top1 96.2,test_top5 99.5,time 1172.8 sec\n",
      "epoch 18,loss 0.6583,train_top1 82.3,train_top5 94.1,test_loss 0.1413,test_top1 96.0,test_top5 99.6,time 1170.1 sec\n",
      "epoch 19,loss 0.6266,train_top1 83.2,train_top5 94.4,test_loss 0.1307,test_top1 96.3,test_top5 99.7,time 1171.4 sec\n",
      "epoch 20,loss 0.5977,train_top1 84.0,train_top5 94.7,test_loss 0.1414,test_top1 96.2,test_top5 99.5,time 1171.7 sec\n",
      "epoch 21,loss 0.5714,train_top1 84.7,train_top5 94.9,test_loss 0.1407,test_top1 96.2,test_top5 99.6,time 1171.9 sec\n",
      "epoch 22,loss 0.5475,train_top1 85.4,train_top5 95.2,test_loss 0.1318,test_top1 96.5,test_top5 99.5,time 1168.5 sec\n",
      "epoch 23,loss 0.5255,train_top1 86.0,train_top5 95.4,test_loss 0.1375,test_top1 96.1,test_top5 99.6,time 1168.3 sec\n",
      "epoch 24,loss 0.5053,train_top1 86.6,train_top5 95.6,test_loss 0.1352,test_top1 95.9,test_top5 99.6,time 1172.8 sec\n",
      "epoch 25,loss 0.4869,train_top1 87.1,train_top5 95.7,test_loss 0.1206,test_top1 96.3,test_top5 99.7,time 1178.9 sec\n",
      "epoch 26,loss 0.4698,train_top1 87.6,train_top5 95.9,test_loss 0.1388,test_top1 96.1,test_top5 99.5,time 1190.0 sec\n",
      "epoch 27,loss 0.4540,train_top1 88.0,train_top5 96.1,test_loss 0.1180,test_top1 96.3,test_top5 99.8,time 1183.6 sec\n",
      "epoch 28,loss 0.4392,train_top1 88.4,train_top5 96.2,test_loss 0.1353,test_top1 96.0,test_top5 99.6,time 1186.6 sec\n",
      "epoch 29,loss 0.4255,train_top1 88.8,train_top5 96.3,test_loss 0.1354,test_top1 96.5,test_top5 99.6,time 1186.1 sec\n",
      "epoch 30,loss 0.4127,train_top1 89.1,train_top5 96.4,test_loss 0.1395,test_top1 96.4,test_top5 99.7,time 1194.1 sec\n"
     ]
    }
   ],
   "source": [
    "milestones = [10,20,25]#多间隔学习率调整训练周期 \n",
    "train_model(net0,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TseBigNet(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=[1, 2, 2], padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck_T(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_T(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck_T(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck_T(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_T(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck_T(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck_T(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck_T(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_T(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck_T(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck_T(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck_T(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck_T(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck_T(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_T(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck_T(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (big1): MaxPool3d(kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (tse1): TSElayer(\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=8, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1,loss 3.4155,train_top1 20.1,train_top5 43.8,test_loss 2.1313,test_top1 44.5,test_top5 78.0,time 1174.9 sec\n",
      "epoch 2,loss 2.6511,train_top1 34.5,train_top5 61.7,test_loss 1.8088,test_top1 54.8,test_top5 84.6,time 1165.4 sec\n",
      "epoch 3,loss 2.2246,train_top1 43.4,train_top5 70.5,test_loss 1.2892,test_top1 63.8,test_top5 90.6,time 1159.0 sec\n",
      "epoch 4,loss 1.9377,train_top1 50.0,train_top5 76.0,test_loss 0.9653,test_top1 72.4,test_top5 94.9,time 1167.0 sec\n",
      "epoch 5,loss 1.7317,train_top1 54.8,train_top5 79.6,test_loss 0.7765,test_top1 78.1,test_top5 95.5,time 1167.2 sec\n",
      "epoch 6,loss 1.5707,train_top1 58.6,train_top5 82.3,test_loss 0.8609,test_top1 77.1,test_top5 96.3,time 1165.0 sec\n",
      "epoch 7,loss 1.4409,train_top1 61.8,train_top5 84.4,test_loss 1.2556,test_top1 71.7,test_top5 94.0,time 1148.9 sec\n",
      "epoch 8,loss 1.3366,train_top1 64.4,train_top5 86.0,test_loss 0.7025,test_top1 80.8,test_top5 96.3,time 1138.5 sec\n",
      "epoch 9,loss 1.2482,train_top1 66.5,train_top5 87.3,test_loss 0.6221,test_top1 83.9,test_top5 97.1,time 1145.0 sec\n",
      "epoch 10,loss 1.1725,train_top1 68.4,train_top5 88.4,test_loss 0.5915,test_top1 84.5,test_top5 96.8,time 1143.8 sec\n",
      "epoch 11,loss 1.0823,train_top1 70.9,train_top5 89.4,test_loss 0.2377,test_top1 93.3,test_top5 99.1,time 1141.1 sec\n",
      "epoch 12,loss 1.0017,train_top1 73.1,train_top5 90.2,test_loss 0.1980,test_top1 94.5,test_top5 99.3,time 1155.6 sec\n",
      "epoch 13,loss 0.9317,train_top1 75.0,train_top5 91.0,test_loss 0.1952,test_top1 94.4,test_top5 99.3,time 1140.3 sec\n",
      "epoch 14,loss 0.8708,train_top1 76.7,train_top5 91.6,test_loss 0.1761,test_top1 95.5,test_top5 99.2,time 1143.4 sec\n",
      "epoch 15,loss 0.8177,train_top1 78.1,train_top5 92.2,test_loss 0.1680,test_top1 95.2,test_top5 99.2,time 1138.1 sec\n",
      "epoch 16,loss 0.7708,train_top1 79.4,train_top5 92.7,test_loss 0.1720,test_top1 95.2,test_top5 99.4,time 1141.0 sec\n",
      "epoch 17,loss 0.7290,train_top1 80.5,train_top5 93.1,test_loss 0.1617,test_top1 95.6,test_top5 99.3,time 1145.6 sec\n",
      "epoch 18,loss 0.6915,train_top1 81.5,train_top5 93.5,test_loss 0.1490,test_top1 95.8,test_top5 99.6,time 1141.0 sec\n",
      "epoch 19,loss 0.6580,train_top1 82.5,train_top5 93.8,test_loss 0.1511,test_top1 96.0,test_top5 99.3,time 1138.2 sec\n",
      "epoch 20,loss 0.6277,train_top1 83.3,train_top5 94.1,test_loss 0.1520,test_top1 95.8,test_top5 99.3,time 1137.4 sec\n",
      "epoch 21,loss 0.6001,train_top1 84.0,train_top5 94.4,test_loss 0.1407,test_top1 96.2,test_top5 99.4,time 1142.0 sec\n",
      "epoch 22,loss 0.5748,train_top1 84.7,train_top5 94.7,test_loss 0.1515,test_top1 95.9,test_top5 99.5,time 1140.7 sec\n",
      "epoch 23,loss 0.5518,train_top1 85.4,train_top5 94.9,test_loss 0.1402,test_top1 96.2,test_top5 99.6,time 1139.6 sec\n",
      "epoch 24,loss 0.5306,train_top1 86.0,train_top5 95.1,test_loss 0.1403,test_top1 96.4,test_top5 99.4,time 1134.6 sec\n",
      "epoch 25,loss 0.5111,train_top1 86.5,train_top5 95.3,test_loss 0.1357,test_top1 96.4,test_top5 99.7,time 1133.9 sec\n",
      "epoch 26,loss 0.4931,train_top1 87.0,train_top5 95.5,test_loss 0.1378,test_top1 96.0,test_top5 99.6,time 1138.7 sec\n",
      "epoch 27,loss 0.4763,train_top1 87.4,train_top5 95.6,test_loss 0.1434,test_top1 96.1,test_top5 99.5,time 1142.9 sec\n",
      "epoch 28,loss 0.4608,train_top1 87.9,train_top5 95.8,test_loss 0.1317,test_top1 96.3,test_top5 99.5,time 1142.5 sec\n",
      "epoch 29,loss 0.4464,train_top1 88.3,train_top5 95.9,test_loss 0.1419,test_top1 96.0,test_top5 99.6,time 1138.0 sec\n",
      "epoch 30,loss 0.4329,train_top1 88.6,train_top5 96.1,test_loss 0.1449,test_top1 96.0,test_top5 99.2,time 1136.3 sec\n"
     ]
    }
   ],
   "source": [
    "milestones = [10,20,25]#多间隔学习率调整训练周期  \n",
    "train_model(net3,lr,train_dataloader,val_dataloader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import numpy as np\n",
    "import numbers\n",
    "import math\n",
    "import torch\n",
    "\n",
    "class GroupRandomCrop(object):\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "\n",
    "        w, h = img_group[0].size\n",
    "        th, tw = self.size\n",
    "\n",
    "        out_images = list()\n",
    "\n",
    "        x1 = random.randint(0, w - tw)\n",
    "        y1 = random.randint(0, h - th)\n",
    "\n",
    "        for img in img_group:\n",
    "            assert(img.size[0] == w and img.size[1] == h)\n",
    "            if w == tw and h == th:\n",
    "                out_images.append(img)\n",
    "            else:\n",
    "                out_images.append(img.crop((x1, y1, x1 + tw, y1 + th)))\n",
    "\n",
    "        return out_images\n",
    "\n",
    "\n",
    "class GroupCenterCrop(object):\n",
    "    def __init__(self, size):\n",
    "        self.worker = torchvision.transforms.CenterCrop(size)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        return [self.worker(img) for img in img_group]\n",
    "\n",
    "\n",
    "class GroupRandomHorizontalFlip(object):\n",
    "    \"\"\"Randomly horizontally flips the given PIL.Image with a probability of 0.5\n",
    "    \"\"\"\n",
    "    def __init__(self, is_flow=False):\n",
    "        self.is_flow = is_flow\n",
    "\n",
    "    def __call__(self, img_group, is_flow=False):\n",
    "        v = random.random()\n",
    "        if v < 0.5:\n",
    "            ret = [img.transpose(Image.Transpose.FLIP_LEFT_RIGHT) for img in img_group]\n",
    "            if self.is_flow:\n",
    "                for i in range(0, len(ret), 2):\n",
    "                    ret[i] = ImageOps.invert(ret[i])  # invert flow pixel values when flipping\n",
    "            return ret\n",
    "        else:\n",
    "            return img_group\n",
    "\n",
    "\n",
    "class GroupNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        rep_mean = self.mean * (tensor.size()[0]//len(self.mean))\n",
    "        rep_std = self.std * (tensor.size()[0]//len(self.std))\n",
    "\n",
    "        # TODO: make efficient\n",
    "        for t, m, s in zip(tensor, rep_mean, rep_std):\n",
    "            t.sub_(m).div_(s)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class GroupScale(object):\n",
    "    \"\"\" Rescales the input PIL.Image to the given 'size'.\n",
    "    'size' will be the size of the smaller edge.\n",
    "    For example, if height > width, then image will be\n",
    "    rescaled to (size * height / width, size)\n",
    "    size: size of the smaller edge\n",
    "    interpolation: Default: PIL.Image.BILINEAR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.Resampling.BILINEAR):\n",
    "        self.worker = torchvision.transforms.Resize(size, interpolation)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        return [self.worker(img) for img in img_group]\n",
    "\n",
    "\n",
    "class GroupOverSample(object):\n",
    "    def __init__(self, crop_size, scale_size=None):\n",
    "        self.crop_size = crop_size if not isinstance(crop_size, int) else (crop_size, crop_size)\n",
    "\n",
    "        if scale_size is not None:\n",
    "            self.scale_worker = GroupScale(scale_size)\n",
    "        else:\n",
    "            self.scale_worker = None\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "\n",
    "        if self.scale_worker is not None:\n",
    "            img_group = self.scale_worker(img_group)\n",
    "\n",
    "        image_w, image_h = img_group[0].size\n",
    "        crop_w, crop_h = self.crop_size\n",
    "\n",
    "        offsets = GroupMultiScaleCrop.fill_fix_offset(False, image_w, image_h, crop_w, crop_h)\n",
    "        oversample_group = list()\n",
    "        for o_w, o_h in offsets:\n",
    "            normal_group = list()\n",
    "            flip_group = list()\n",
    "            for i, img in enumerate(img_group):\n",
    "                crop = img.crop((o_w, o_h, o_w + crop_w, o_h + crop_h))\n",
    "                normal_group.append(crop)\n",
    "                flip_crop = crop.copy().transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "\n",
    "                if img.mode == 'L' and i % 2 == 0:\n",
    "                    flip_group.append(ImageOps.invert(flip_crop))\n",
    "                else:\n",
    "                    flip_group.append(flip_crop)\n",
    "\n",
    "            oversample_group.extend(normal_group)\n",
    "            oversample_group.extend(flip_group)\n",
    "        return oversample_group\n",
    "\n",
    "\n",
    "class GroupMultiScaleCrop(object):\n",
    "\n",
    "    def __init__(self, input_size, scales=None, max_distort=1, fix_crop=True, more_fix_crop=True):\n",
    "        self.scales = scales if scales is not None else [1, .875, .75, .66]\n",
    "        self.max_distort = max_distort\n",
    "        self.fix_crop = fix_crop\n",
    "        self.more_fix_crop = more_fix_crop\n",
    "        self.input_size = input_size if not isinstance(input_size, int) else [input_size, input_size]\n",
    "        self.interpolation = Image.Resampling.BILINEAR\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "\n",
    "        im_size = img_group[0].size\n",
    "\n",
    "        crop_w, crop_h, offset_w, offset_h = self._sample_crop_size(im_size)\n",
    "        crop_img_group = [img.crop((offset_w, offset_h, offset_w + crop_w, offset_h + crop_h)) for img in img_group]\n",
    "        ret_img_group = [img.resize((self.input_size[0], self.input_size[1]), self.interpolation)\n",
    "                         for img in crop_img_group]\n",
    "        return ret_img_group\n",
    "\n",
    "    def _sample_crop_size(self, im_size):\n",
    "        image_w, image_h = im_size[0], im_size[1]\n",
    "\n",
    "        # find a crop size\n",
    "        base_size = min(image_w, image_h)\n",
    "        crop_sizes = [int(base_size * x) for x in self.scales]\n",
    "        crop_h = [self.input_size[1] if abs(x - self.input_size[1]) < 3 else x for x in crop_sizes]\n",
    "        crop_w = [self.input_size[0] if abs(x - self.input_size[0]) < 3 else x for x in crop_sizes]\n",
    "\n",
    "        pairs = []\n",
    "        for i, h in enumerate(crop_h):\n",
    "            for j, w in enumerate(crop_w):\n",
    "                if abs(i - j) <= self.max_distort:\n",
    "                    pairs.append((w, h))\n",
    "\n",
    "        crop_pair = random.choice(pairs)\n",
    "        if not self.fix_crop:\n",
    "            w_offset = random.randint(0, image_w - crop_pair[0])\n",
    "            h_offset = random.randint(0, image_h - crop_pair[1])\n",
    "        else:\n",
    "            w_offset, h_offset = self._sample_fix_offset(image_w, image_h, crop_pair[0], crop_pair[1])\n",
    "\n",
    "        return crop_pair[0], crop_pair[1], w_offset, h_offset\n",
    "\n",
    "    def _sample_fix_offset(self, image_w, image_h, crop_w, crop_h):\n",
    "        offsets = self.fill_fix_offset(self.more_fix_crop, image_w, image_h, crop_w, crop_h)\n",
    "        return random.choice(offsets)\n",
    "\n",
    "    @staticmethod\n",
    "    def fill_fix_offset(more_fix_crop, image_w, image_h, crop_w, crop_h):\n",
    "        w_step = (image_w - crop_w) // 4\n",
    "        h_step = (image_h - crop_h) // 4\n",
    "\n",
    "        ret = list()\n",
    "        ret.append((0, 0))  # upper left\n",
    "        ret.append((4 * w_step, 0))  # upper right\n",
    "        ret.append((0, 4 * h_step))  # lower left\n",
    "        ret.append((4 * w_step, 4 * h_step))  # lower right\n",
    "        ret.append((2 * w_step, 2 * h_step))  # center\n",
    "\n",
    "        if more_fix_crop:\n",
    "            ret.append((0, 2 * h_step))  # center left\n",
    "            ret.append((4 * w_step, 2 * h_step))  # center right\n",
    "            ret.append((2 * w_step, 4 * h_step))  # lower center\n",
    "            ret.append((2 * w_step, 0 * h_step))  # upper center\n",
    "\n",
    "            ret.append((1 * w_step, 1 * h_step))  # upper left quarter\n",
    "            ret.append((3 * w_step, 1 * h_step))  # upper right quarter\n",
    "            ret.append((1 * w_step, 3 * h_step))  # lower left quarter\n",
    "            ret.append((3 * w_step, 3 * h_step))  # lower righ quarter\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n",
    "class GroupRandomSizedCrop(object):\n",
    "    \"\"\"Random crop the given PIL.Image to a random size of (0.08 to 1.0) of the original size\n",
    "    and and a random aspect ratio of 3/4 to 4/3 of the original aspect ratio\n",
    "    This is popularly used to train the Inception networks\n",
    "    size: size of the smaller edge\n",
    "    interpolation: Default: PIL.Image.BILINEAR\n",
    "    \"\"\"\n",
    "    def __init__(self, size, interpolation=Image.Resampling.BILINEAR):\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        for attempt in range(10):\n",
    "            area = img_group[0].size[0] * img_group[0].size[1]\n",
    "            target_area = random.uniform(0.08, 1.0) * area\n",
    "            aspect_ratio = random.uniform(3. / 4, 4. / 3)\n",
    "\n",
    "            w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                w, h = h, w\n",
    "\n",
    "            if w <= img_group[0].size[0] and h <= img_group[0].size[1]:\n",
    "                x1 = random.randint(0, img_group[0].size[0] - w)\n",
    "                y1 = random.randint(0, img_group[0].size[1] - h)\n",
    "                found = True\n",
    "                break\n",
    "        else:\n",
    "            found = False\n",
    "            x1 = 0\n",
    "            y1 = 0\n",
    "\n",
    "        if found:\n",
    "            out_group = list()\n",
    "            for img in img_group:\n",
    "                img = img.crop((x1, y1, x1 + w, y1 + h))\n",
    "                assert(img.size == (w, h))\n",
    "                out_group.append(img.resize((self.size, self.size), self.interpolation))\n",
    "            return out_group\n",
    "        else:\n",
    "            # Fallback\n",
    "            scale = GroupScale(self.size, interpolation=self.interpolation)\n",
    "            crop = GroupRandomCrop(self.size)\n",
    "            return crop(scale(img_group))\n",
    "\n",
    "\n",
    "class Stack(object):\n",
    "\n",
    "    def __init__(self, roll=False):\n",
    "        self.roll = roll\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        if img_group[0].mode == 'L':\n",
    "            return np.concatenate([np.expand_dims(x, 2) for x in img_group], axis=2)\n",
    "        elif img_group[0].mode == 'RGB':\n",
    "            if self.roll:\n",
    "                return np.concatenate([np.array(x)[:, :, ::-1] for x in img_group], axis=2)\n",
    "            else:\n",
    "                return np.concatenate(img_group, axis=2)\n",
    "\n",
    "\n",
    "class ToTorchFormatTensor(object):\n",
    "    \"\"\" Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range [0, 255]\n",
    "    to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \"\"\"\n",
    "    def __init__(self, div=True):\n",
    "        self.div = div\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        if isinstance(pic, np.ndarray):\n",
    "            # handle numpy array\n",
    "            img = torch.from_numpy(pic).permute(2, 0, 1).contiguous()\n",
    "        else:\n",
    "            # handle PIL Image\n",
    "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "            img = img.view(pic.size[1], pic.size[0], len(pic.mode))\n",
    "            # put it from HWC to CHW format\n",
    "            # yikes, this transpose takes 80% of the loading time/CPU\n",
    "            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "        return img.float().div(255) if self.div else img.float()\n",
    "\n",
    "\n",
    "class IdentityTransform(object):\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "\n",
    "class VideoRecord(object):\n",
    "    def __init__(self, row):\n",
    "        self._data = row\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return self._data[0]\n",
    "\n",
    "    @property\n",
    "    def num_frames(self):\n",
    "        return int(self._data[1])\n",
    "\n",
    "    @property\n",
    "    def label(self):\n",
    "        return int(self._data[2])\n",
    "\n",
    "\n",
    "class TSNDataSet(data.Dataset):\n",
    "    def __init__(self, root_path, list_file,\n",
    "                 num_segments=3, new_length=1, modality='RGB',\n",
    "                 image_tmpl='img_{:05d}.jpg', transform=None,\n",
    "                 force_grayscale=False, random_shift=True, test_mode=False):\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.list_file = list_file\n",
    "        self.num_segments = num_segments\n",
    "        self.new_length = new_length\n",
    "        self.modality = modality\n",
    "        self.image_tmpl = image_tmpl\n",
    "        self.transform = transform\n",
    "        self.random_shift = random_shift\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "        if self.modality == 'RGBDiff':\n",
    "            self.new_length += 1# Diff needs one more image to calculate diff\n",
    "\n",
    "        self._parse_list()\n",
    "\n",
    "    def _load_image(self, directory, idx):\n",
    "        if self.modality == 'RGB' or self.modality == 'RGBDiff':\n",
    "            return [Image.open(os.path.join(self.root_path,directory, self.image_tmpl.format(idx))).convert('RGB')]\n",
    "        elif self.modality == 'Flow':\n",
    "            x_img = Image.open(os.path.join(self.root_path,directory, self.image_tmpl.format('x', idx))).convert('L')\n",
    "            y_img = Image.open(os.path.join(self.root_path,directory, self.image_tmpl.format('y', idx))).convert('L')\n",
    "\n",
    "            return [x_img, y_img]\n",
    "\n",
    "    def _parse_list(self):\n",
    "        self.video_list = [VideoRecord(x.strip().split(' ')) for x in open(self.list_file)]\n",
    "    #获得稀疏采样的索引\n",
    "    def _sample_indices(self, record):\n",
    "        \"\"\"\n",
    "\n",
    "        :param record: VideoRecord\n",
    "        :return: list\n",
    "        \"\"\"\n",
    "\n",
    "        average_duration = (record.num_frames - self.new_length + 1) // self.num_segments\n",
    "        if average_duration > 0:\n",
    "            offsets = np.multiply(list(range(self.num_segments)), average_duration) + randint(average_duration, size=self.num_segments)\n",
    "        elif record.num_frames > self.num_segments:\n",
    "            offsets = np.sort(randint(record.num_frames - self.new_length + 1, size=self.num_segments))\n",
    "        else:\n",
    "            offsets = np.zeros((self.num_segments,))\n",
    "        return offsets + 1\n",
    "\n",
    "    def _get_val_indices(self, record):\n",
    "        if record.num_frames > self.num_segments + self.new_length - 1:\n",
    "            tick = (record.num_frames - self.new_length + 1) / float(self.num_segments)\n",
    "            offsets = np.array([int(tick / 2.0 + tick * x) for x in range(self.num_segments)])\n",
    "        else:\n",
    "            offsets = np.zeros((self.num_segments,))\n",
    "        return offsets + 1\n",
    "\n",
    "    def _get_test_indices(self, record):\n",
    "        tick = (record.num_frames - self.new_length + 1) / float(self.num_segments)\n",
    "        offsets = np.array([int(tick / 2.0 + tick * x) for x in range(self.num_segments)])\n",
    "\n",
    "        return offsets + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        record = self.video_list[index]\n",
    "        if not self.test_mode:\n",
    "            segment_indices = self._sample_indices(record) if self.random_shift else self._get_val_indices(record)\n",
    "        else:\n",
    "            segment_indices = self._get_test_indices(record)\n",
    "\n",
    "        return self.get(record, segment_indices)\n",
    "\n",
    "    def get(self, record, indices):\n",
    "\n",
    "        images = list()\n",
    "        for seg_ind in indices:\n",
    "            p = int(seg_ind)\n",
    "            for i in range(self.new_length):\n",
    "                seg_imgs = self._load_image(record.path, p)\n",
    "                images.extend(seg_imgs)\n",
    "                if p < record.num_frames:\n",
    "                    p += 1\n",
    "\n",
    "        process_data = self.transform(images)\n",
    "        return process_data, record.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_list = '/root/autodl-tmp/home/mmaction2/data/ucf101/ucf101_train_split_1_rawframes.txt'\n",
    "val_list = '/root/autodl-tmp/home/mmaction2/data/ucf101/ucf101_val_split_1_rawframes.txt'\n",
    "modality = 'RGB'\n",
    "num_segments = 16\n",
    "batch_size = 16\n",
    "root_path = '/root/autodl-tmp/home/user-data/ucf101/rawframes/'\n",
    "data_length = 1\n",
    "input_size = 224\n",
    "scale_size = input_size * 256 // 224\n",
    "input_mean = [0.485, 0.456, 0.406]\n",
    "input_std = [0.229, 0.224, 0.225]\n",
    "arch = 'resnet50'\n",
    "train_augmentation = torchvision.transforms.Compose([GroupMultiScaleCrop(input_size, [1, .875, .75, .66]),\n",
    "                                                   GroupRandomHorizontalFlip(is_flow=False)])\n",
    "\n",
    "normalize = GroupNormalize(input_mean, input_std)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    TSNDataSet(root_path, train_list, num_segments=num_segments,\n",
    "               new_length=data_length,\n",
    "               modality=modality,\n",
    "               image_tmpl=\"img_{:05d}.jpg\" ,\n",
    "               transform=torchvision.transforms.Compose([\n",
    "                   train_augmentation,\n",
    "                   Stack(roll=arch == 'BNInception'),\n",
    "                   ToTorchFormatTensor(div=arch != 'BNInception'),\n",
    "                   normalize,\n",
    "               ])),\n",
    "    batch_size=batch_size, shuffle=True,\n",
    "    num_workers=4, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    TSNDataSet(root_path, val_list, num_segments=num_segments,\n",
    "               new_length=data_length,\n",
    "               modality=modality,\n",
    "               image_tmpl=\"img_{:05d}.jpg\" ,\n",
    "               random_shift=False,\n",
    "               transform=torchvision.transforms.Compose([\n",
    "                   GroupScale(int(scale_size)),\n",
    "                   GroupCenterCrop(input_size),\n",
    "                   Stack(roll=arch == 'BNInception'),\n",
    "                   ToTorchFormatTensor(div=arch != 'BNInception'),\n",
    "                   normalize,\n",
    "               ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 4.2808, train acc 0.096, test acc 0.171, time 274.3 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [262]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#加载分割数据集\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgtcnet3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmilestones\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [261]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, train_dataloader, test_dataloader, milestones, batch_size, device, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m     n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     47\u001b[0m     batch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m      \n\u001b[0;32m---> 48\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m shceduler\u001b[38;5;241m.\u001b[39mstep()  \n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [261]\u001b[0m, in \u001b[0;36mevaluate_accuracy\u001b[0;34m(data_iter, net, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(net, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      8\u001b[0m     net\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# 评估模式, 这会关闭dropout\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     acc_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (net(X\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     10\u001b[0m     net\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# 改回训练模式\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# 自定义的模型, 3.13节之后不会用到, 不考虑GPU\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "#milestones = [15,30,45]#多间隔学习率调整训练周期 \n",
    "#milestones = [35,45,55]#多间隔学习率调整\n",
    "milestones = [60,85,95]\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16\n",
    "#加载分割数据集\n",
    "#train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "#val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(gtcnet3,lr,train_loader,val_loader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 4.0414, train acc 0.170, test acc 0.344, time 222.0 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [333]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#加载分割数据集\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmilestones\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [332]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, train_dataloader, test_dataloader, milestones, batch_size, device, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     42\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 44\u001b[0m train_l_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     45\u001b[0m train_acc_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (y_hat\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     46\u001b[0m n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#使用预训练参数的resnet，并且冻结了卷积层参数\n",
    "#milestones = [15,30,45]#多间隔学习率调整训练周期 \n",
    "#milestones = [35,45,55]#多间隔学习率调整\n",
    "milestones = [60,85,95]\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 16\n",
    "#加载分割数据集\n",
    "#train_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'train',preprocess = False),batch_size =batch_size,shuffle=True,num_workers = 0)     \n",
    "#val_dataloader = DataLoader(VideoDataset(dataset = dataset,split = 'val',preprocess = False),batch_size = batch_size,num_workers = 0)\n",
    "\n",
    "train(net,lr,train_loader,val_loader,milestones,batch_size,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "1310a20abca0b10066076679cf8e3489d0dd3f635b8296b90b860fb546d43650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
